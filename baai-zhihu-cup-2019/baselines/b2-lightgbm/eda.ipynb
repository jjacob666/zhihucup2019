{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务说明\n",
    "将一个问题Q推荐给用户U，计算U会回答这个问题Q的概率。（根据问题信息，用户画像，回答信息）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 数据分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 用户数据集和问题数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = '../data'\n",
    "user_info = pd.read_csv(os.path.join(data_path,'member_info_0926.txt'), header=None, sep='\\t')\n",
    "user_info.columns = ['用户id','性别','创作关键词','创作数量等级','创作热度等级','注册类型','注册平台','访问评率','用户二分类特征a','用户二分类特征b','用户二分类特征c','用户二分类特征d','用户二分类特征e','用户多分类特征a','用户多分类特征b','用户多分类特征c','用户多分类特征d','用户多分类特征e','盐值','关注话题','感兴趣话题']\n",
    "for col in user_info.columns:\n",
    "    print(col, len(user_info[col].unique()))\n",
    "\n",
    "question_info = pd.read_csv(os.path.join(data_path, 'question_info_0926.txt'), header=None, sep='\\t')\n",
    "question_info.columns = ['问题id','问题创建时间','问题标题单字编码','问题标题切词编码','问题描述单字编码','问题描述切词编码','问题绑定话题']\n",
    "for col in question_info.columns:\n",
    "    print(col, len(question_info[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的数据分析可以看出，用户数据中有21个特征，其中5个特征（创作关键词、创作数量等级、创作热度等级、注册类型、注册平台）在数据集中只有一个取值，说明这5个特征是完全无用的，可以直接去掉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 数据集合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将这两个数据集和训练集合并，分析两个数据集中的特征是否对预测结果有影响（那些区分度强的特征）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['问题id', '用户id', '邀请创建时间', '是否回答', '性别', '创作关键词', '创作数量等级', '创作热度等级',\n",
      "       '注册类型', '注册平台', '访问评率', '用户二分类特征a', '用户二分类特征b', '用户二分类特征c', '用户二分类特征d',\n",
      "       '用户二分类特征e', '用户多分类特征a', '用户多分类特征b', '用户多分类特征c', '用户多分类特征d', '用户多分类特征e',\n",
      "       '盐值', '关注话题', '感兴趣话题', '问题创建时间', '问题标题单字编码', '问题标题切词编码', '问题描述单字编码',\n",
      "       '问题描述切词编码', '问题绑定话题'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(data_path, 'invite_info_0926.txt'), header=None, sep='\\t')\n",
    "train.columns = ['问题id', '用户id', '邀请创建时间','是否回答']\n",
    "train = pd.merge(train, user_info, how='left', on='用户id')\n",
    "train = pd.merge(train, question_info, how='left', on='问题id')\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.countplot(x='性别', hue='是否回答', data=train)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.性别特征**:性别特征，有三种。其中男女的各自分布比较相似，未知的分布相比较之下，有较大的区别，显然，该特征具有比较好的区分度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0fe9ad4438>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='访问评率',hue='是否回答',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.统计频率特征**: 该特征有五种类别，从下面的柱状图看出，不同的类别具有完全不同分布，是一种区分度很强的特征；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0fec077630>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='用户二分类特征a',hue='是否回答',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.用户二分类特征a**：该特征是二分类特征，从图中可以看出很好的区分度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0feccc6c50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def trans(x):\n",
    "    if x <= 0:\n",
    "        return x\n",
    "    if 1 <= x <= 10:\n",
    "        return 1\n",
    "    if 10 < x <= 100:\n",
    "        return 2\n",
    "    if 100 < x <= 200:\n",
    "        return 3\n",
    "    if 200 < x <= 300:\n",
    "        return 4\n",
    "    if 400 < x <= 500:\n",
    "        return 5\n",
    "    if 500 < x <= 600:\n",
    "        return 6\n",
    "    if x > 600:\n",
    "        return 7\n",
    "train['盐值'] = train['盐值'].apply(lambda x: trans(x))\n",
    "sns.countplot(x='盐值',hue='是否回答',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.盐值**：先对盐值进行分桶，然后查看不同区间盐值的分布情况。下图表示不同区间盐值的用户具有很好的区分度，在处理这个特征，至于是否分桶，如何通过更加详细的数据分析自由发挥，给出的baseline对该特征未作处理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.时间**：数据集中的时间都采用天和小时的格式，D代表天数，H代表小时，这里可以将一个特征转化为两个特征，天和小时。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题关联的topic和用户关注的topic的重叠数量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算周/日趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "#sns.countplot(x='邀请创建时间-day', hue='是否回答', data=data[:train1.shape[0]])\n",
    "# sns.kdeplot(data['盐值'][data['是否回答']==1],color='b')\n",
    "# sns.kdeplot(data['盐值'][data['是否回答']==0],color='r')\n",
    "#x = data[data['是否回答']==1][feat].unique()\n",
    "\n",
    "day_df = data[['问题创建时间-day','邀请创建时间-day','是否回答']]\n",
    "print(day_df.head())\n",
    "day_df['问题创建时间-weekday'] = data['问题创建时间-day'].map(lambda x: x%7)\n",
    "day_df['邀请创建时间-weekday'] = data['邀请创建时间-day'].map(lambda x: x%7)\n",
    "#print(day_df)\n",
    "\n",
    "feat = '邀请创建时间-weekday'\n",
    "\n",
    "series0 = day_df[day_df['是否回答']==0][feat].value_counts().astype(int).sort_index()\n",
    "y0 = series0.values\n",
    "x0 = series0.index\n",
    "#print(series)\n",
    "\n",
    "series1 = day_df[day_df['是否回答']==1][feat].value_counts().astype(int).sort_index()\n",
    "y1 = series1.values\n",
    "x1 = series1.index\n",
    "\n",
    "# y0 = series0.values/(series0.values+series1.values)\n",
    "# y1 = series1.values/(series0.values+series1.values)\n",
    "\n",
    "#plt.plot(x0,y0,color='red')\n",
    "plt.plot(x1,y1,color='blue')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 减少内存占用\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            \n",
    "            if str(col_type)[:5] == 'float':\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10630845 entries, 0 to 1141682\n",
      "Data columns (total 25 columns):\n",
      "关注话题        object\n",
      "性别          object\n",
      "感兴趣话题       object\n",
      "是否回答        float64\n",
      "用户id        object\n",
      "用户二分类特征a    int64\n",
      "用户二分类特征b    int64\n",
      "用户二分类特征c    int64\n",
      "用户二分类特征d    int64\n",
      "用户二分类特征e    int64\n",
      "用户多分类特征a    object\n",
      "用户多分类特征b    object\n",
      "用户多分类特征c    object\n",
      "用户多分类特征d    object\n",
      "用户多分类特征e    object\n",
      "盐值          int64\n",
      "访问评率        object\n",
      "邀请创建时间      object\n",
      "问题id        object\n",
      "问题创建时间      object\n",
      "问题描述切词编码    object\n",
      "问题描述单字编码    object\n",
      "问题标题切词编码    object\n",
      "问题标题单字编码    object\n",
      "问题绑定话题      object\n",
      "dtypes: float64(1), int64(6), object(18)\n",
      "memory usage: 2.1+ GB\n",
      "None\n",
      "Memory usage of dataframe is 2108.78 MB\n",
      "Memory usage after optimization is: 1652.55 MB\n",
      "Decreased by 21.6%\n",
      "Memory usage of dataframe is 1571.45 MB\n",
      "Memory usage after optimization is: 1459.92 MB\n",
      "Decreased by 7.1%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10630845 entries, 0 to 10630844\n",
      "Data columns (total 22 columns):\n",
      "性别               object\n",
      "是否回答             float32\n",
      "用户id             object\n",
      "用户二分类特征a         int8\n",
      "用户二分类特征b         int8\n",
      "用户二分类特征c         int8\n",
      "用户二分类特征d         int8\n",
      "用户二分类特征e         int8\n",
      "用户多分类特征a         object\n",
      "用户多分类特征b         object\n",
      "用户多分类特征c         object\n",
      "用户多分类特征d         object\n",
      "用户多分类特征e         object\n",
      "盐值               int16\n",
      "访问评率             object\n",
      "问题id             object\n",
      "邀请创建时间-day       object\n",
      "邀请创建时间-hour      object\n",
      "问题创建时间-day       object\n",
      "问题创建时间-hour      object\n",
      "用户问题的话题关注重叠数     int8\n",
      "用户问题的话题感兴趣重叠数    float32\n",
      "dtypes: float32(2), int16(1), int8(6), object(13)\n",
      "memory usage: 1.3+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10630845 entries, 0 to 1141682\n",
      "Data columns (total 67 columns):\n",
      "性别               object\n",
      "是否回答             float32\n",
      "用户id             object\n",
      "用户二分类特征a         int8\n",
      "用户二分类特征b         int8\n",
      "用户二分类特征c         int8\n",
      "用户二分类特征d         int8\n",
      "用户二分类特征e         int8\n",
      "用户多分类特征a         object\n",
      "用户多分类特征b         object\n",
      "用户多分类特征c         object\n",
      "用户多分类特征d         object\n",
      "用户多分类特征e         object\n",
      "用户问题的话题关注重叠数     int8\n",
      "用户问题的话题感兴趣重叠数    float32\n",
      "盐值               int16\n",
      "访问评率             object\n",
      "邀请创建时间-day       object\n",
      "邀请创建时间-hour      object\n",
      "问题id             object\n",
      "问题上次回答时间         float64\n",
      "问题关联回答数          float64\n",
      "问题创建时间-day       object\n",
      "问题创建时间-hour      object\n",
      "问题平均举报数          float64\n",
      "问题平均反对数          float64\n",
      "问题平均取赞数          float64\n",
      "问题平均回答字数         float64\n",
      "问题平均回答是否被推荐      float64\n",
      "问题平均回答是否被收入圆桌    float64\n",
      "问题平均回答是否被标优      float64\n",
      "问题平均感谢数          float64\n",
      "问题平均收藏数          float64\n",
      "问题平均是否包含图片       float64\n",
      "问题平均是否包含视频       float64\n",
      "问题平均没有帮助数        float64\n",
      "问题平均点赞数          float64\n",
      "问题平均评论数          float64\n",
      "问题总举报数           float64\n",
      "问题总反对数           float64\n",
      "问题总取赞数           float64\n",
      "问题总回答字数          float64\n",
      "问题总回答是否被推荐       float64\n",
      "问题总回答是否被收入圆桌     float64\n",
      "问题总回答是否被标优       float64\n",
      "问题总感谢数           float64\n",
      "问题总收藏数           float64\n",
      "问题总是否包含图片        float64\n",
      "问题总是否包含视频        float64\n",
      "问题总没有帮助数         float64\n",
      "问题总点赞数           float64\n",
      "问题总评论数           float64\n",
      "问题最大举报数          float64\n",
      "问题最大反对数          float64\n",
      "问题最大取赞数          float64\n",
      "问题最大回答字数         float64\n",
      "问题最大回答是否被推荐      float64\n",
      "问题最大回答是否被收入圆桌    float64\n",
      "问题最大回答是否被标优      float64\n",
      "问题最大感谢数          float64\n",
      "问题最大收藏数          float64\n",
      "问题最大是否包含图片       float64\n",
      "问题最大是否包含视频       float64\n",
      "问题最大没有帮助数        float64\n",
      "问题最大点赞数          float64\n",
      "问题最大评论数          float64\n",
      "问题最近一周回答比例       float64\n",
      "dtypes: float32(2), float64(45), int16(1), int8(6), object(13)\n",
      "memory usage: 4.8+ GB\n",
      "None\n",
      "Memory usage of dataframe is 4947.52 MB\n",
      "Memory usage after optimization is: 3122.62 MB\n",
      "Decreased by 36.9%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10630845 entries, 0 to 1141682\n",
      "Columns: 127 entries, u_a_i_diffday_max to 问题最近一周回答比例\n",
      "dtypes: float32(47), float64(60), int16(1), int8(6), object(13)\n",
      "memory usage: 7.8+ GB\n",
      "None\n",
      "Memory usage of dataframe is 7989.03 MB\n",
      "Memory usage after optimization is: 5555.82 MB\n",
      "Decreased by 30.5%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_path = '../data'\n",
    "\n",
    "# 导入数据\n",
    "user_info = pd.read_csv(os.path.join(data_path, 'member_info_0926.txt'), header=None, sep='\\t')\n",
    "question_info = pd.read_csv(os.path.join(data_path, 'question_info_0926.txt'), header=None, sep='\\t')\n",
    "train1 = pd.read_csv(os.path.join(data_path, 'invite_info_0926.txt'), header=None, sep='\\t')\n",
    "test1 = pd.read_csv(os.path.join(data_path, 'invite_info_evaluate_1_0926.txt'), header=None, sep='\\t')\n",
    "member_question_feat = pd.read_hdf('member_question_feat.h5', key='data')  # 719116 d12\n",
    "question_pre_feat_train = pd.read_hdf('question_answer_train.h5', key='data') \n",
    "user_pre_feat_train =  pd.read_hdf('user_answer_train.h5', key='data')\n",
    "question_pre_feat_val = pd.read_hdf('question_answer_val.h5', key='data') \n",
    "user_pre_feat_val =  pd.read_hdf('user_answer_val.h5', key='data')\n",
    "\n",
    "user_info.columns = ['用户id','性别','创作关键词','创作数量等级','创作热度等级','注册类型','注册平台','访问评率','用户二分类特征a','用户二分类特征b','用户二分类特征c','用户二分类特征d','用户二分类特征e','用户多分类特征a','用户多分类特征b','用户多分类特征c','用户多分类特征d','用户多分类特征e','盐值','关注话题','感兴趣话题']\n",
    "user_info  = user_info.drop(['创作关键词','创作数量等级','创作热度等级','注册类型','注册平台'], axis=1)\n",
    "question_info.columns = ['问题id','问题创建时间','问题标题单字编码','问题标题切词编码','问题描述单字编码','问题描述切词编码','问题绑定话题']\n",
    "\n",
    "train1.columns = ['问题id', '用户id', '邀请创建时间','是否回答']\n",
    "train1 = pd.merge(train1, user_info, how='left', on='用户id')\n",
    "\n",
    "train1 = pd.merge(train1, question_info, how='left', on='问题id')\n",
    "\n",
    "test1.columns = ['问题id', '用户id', '邀请创建时间']\n",
    "test1 = pd.merge(test1, user_info, how='left', on='用户id')\n",
    "test1 = pd.merge(test1, question_info, how='left', on='问题id')\n",
    "\n",
    "# 数据合并\n",
    "data = pd.concat([train1, test1], axis=0, sort=True)\n",
    "\n",
    "print(data.info())\n",
    "# 数据压缩\n",
    "data = reduce_mem_usage(data)\n",
    "\n",
    "# 用于保存提交结果\n",
    "#result_append = data[['问题id', '用户id', '邀请创建时间']][train1.shape[0]:]\n",
    "\n",
    "data['邀请创建时间-day'] = data['邀请创建时间'].apply(lambda x:x.split('-')[0].split('D')[1])\n",
    "data['邀请创建时间-hour'] = data['邀请创建时间'].apply(lambda x:x.split('-')[1].split('H')[1])\n",
    "\n",
    "data['问题创建时间-day'] = data['问题创建时间'].apply(lambda x:x.split('-')[0].split('D')[1])\n",
    "data['问题创建时间-hour'] = data['问题创建时间'].apply(lambda x:x.split('-')[1].split('H')[1])\n",
    "\n",
    "# 删除的特征并非不重要，相反这部分的数据很重要，如何处理这部分特征有很大的发挥空间，本baseline不涉及这些特征。\n",
    "drop_feat = ['问题标题单字编码','问题标题切词编码','问题描述单字编码','问题描述切词编码','问题绑定话题', '关注话题','感兴趣话题','问题创建时间','邀请创建时间']\n",
    "data  = data.drop(drop_feat, axis=1)\n",
    "\n",
    "# 将用户和问题相关的话题重合率计算\n",
    "data = pd.merge(data, member_question_feat, how='left', left_on=['用户id','问题id'], right_on=['author_id','question_id'])\n",
    "# 数据压缩\n",
    "data = reduce_mem_usage(data)\n",
    "drop_feat = ['author_id','question_id']\n",
    "data  = data.drop(drop_feat, axis=1)\n",
    "print(data.info())\n",
    "\n",
    "# 将question_answer特征加入\n",
    "train2 = pd.merge(data[:train1.shape[0]], question_pre_feat_train, how='left', on='问题id' )\n",
    "test2 = pd.merge(data[train1.shape[0]:], question_pre_feat_val, how='left', on='问题id' )\n",
    "data = pd.concat([train2, test2], axis=0, sort=True)\n",
    "\n",
    "print(data.info())\n",
    "# 数据压缩\n",
    "data = reduce_mem_usage(data)\n",
    "\n",
    "# 将user_answer特征加入\n",
    "train3 = pd.merge(data[:train1.shape[0]], user_pre_feat_train, how='left', on='用户id' )\n",
    "test3 = pd.merge(data[train1.shape[0]:], user_pre_feat_val, how='left', on='用户id' )\n",
    "data = pd.concat([train3, test3], axis=0, sort=True)\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "# 数据压缩\n",
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 6123.57 MB\n",
      "Memory usage after optimization is: 5758.59 MB\n",
      "Decreased by 6.0%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10630845 entries, 0 to 10630844\n",
      "Columns: 134 entries, u_a_i_diffday_max to std_interest_values\n",
      "dtypes: float32(111), int16(2), int8(8), object(13)\n",
      "memory usage: 5.6+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "user_topic_features = pd.read_hdf('user_topic_feat.h5', key='data')\n",
    "data = pd.merge(data, user_topic_features, how='left', left_on=['用户id'], right_on=['author_id'])\n",
    "data  = data.drop('author_id', axis=1)\n",
    "data = reduce_mem_usage(data)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u_a_i_diffday_max' 'u_a_i_diffday_mean' 'u_a_i_diffday_min'\n",
      " 'u_a_i_diffday_sum' 'u_a_i_diffhour_max' 'u_a_i_diffhour_mean'\n",
      " 'u_a_i_diffhour_min' 'u_a_i_diffhour_sum' '性别' '是否回答' '用户id'\n",
      " '用户上次回答时间-day' '用户习惯回答时间-hour' '用户二分类特征a' '用户二分类特征b' '用户二分类特征c'\n",
      " '用户二分类特征d' '用户二分类特征e' '用户关联回答数' '用户多分类特征a' '用户多分类特征b' '用户多分类特征c'\n",
      " '用户多分类特征d' '用户多分类特征e' '用户平均举报数' '用户平均反对数' '用户平均取赞数' '用户平均回答字数'\n",
      " '用户平均回答是否被推荐' '用户平均回答是否被收入圆桌' '用户平均回答是否被标优' '用户平均感谢数' '用户平均收藏数'\n",
      " '用户平均是否包含图片' '用户平均是否包含视频' '用户平均没有帮助数' '用户平均点赞数' '用户平均评论数' '用户总举报数'\n",
      " '用户总反对数' '用户总取赞数' '用户总回答字数' '用户总回答是否被推荐' '用户总回答是否被收入圆桌' '用户总回答是否被标优'\n",
      " '用户总感谢数' '用户总收藏数' '用户总是否包含图片' '用户总是否包含视频' '用户总没有帮助数' '用户总点赞数' '用户总评论数'\n",
      " '用户最大举报数' '用户最大反对数' '用户最大取赞数' '用户最大回答字数' '用户最大回答是否被推荐' '用户最大回答是否被收入圆桌'\n",
      " '用户最大回答是否被标优' '用户最大感谢数' '用户最大收藏数' '用户最大是否包含图片' '用户最大是否包含视频' '用户最大没有帮助数'\n",
      " '用户最大点赞数' '用户最大评论数' '用户最近回答数-14天' '用户最近回答数-3天' '用户最近回答数-7天' '用户邀请_count'\n",
      " '用户邀请平均' '用户邀请方差' '用户邀请求和' '用户问题的话题关注重叠数' '用户问题的话题感兴趣重叠数' '盐值' '访问评率'\n",
      " '邀请创建时间-day' '邀请创建时间-hour' '问题id' '问题上次回答时间' '问题关联回答数' '问题创建时间-day'\n",
      " '问题创建时间-hour' '问题平均举报数' '问题平均反对数' '问题平均取赞数' '问题平均回答字数' '问题平均回答是否被推荐'\n",
      " '问题平均回答是否被收入圆桌' '问题平均回答是否被标优' '问题平均感谢数' '问题平均收藏数' '问题平均是否包含图片'\n",
      " '问题平均是否包含视频' '问题平均没有帮助数' '问题平均点赞数' '问题平均评论数' '问题总举报数' '问题总反对数' '问题总取赞数'\n",
      " '问题总回答字数' '问题总回答是否被推荐' '问题总回答是否被收入圆桌' '问题总回答是否被标优' '问题总感谢数' '问题总收藏数'\n",
      " '问题总是否包含图片' '问题总是否包含视频' '问题总没有帮助数' '问题总点赞数' '问题总评论数' '问题最大举报数' '问题最大反对数'\n",
      " '问题最大取赞数' '问题最大回答字数' '问题最大回答是否被推荐' '问题最大回答是否被收入圆桌' '问题最大回答是否被标优'\n",
      " '问题最大感谢数' '问题最大收藏数' '问题最大是否包含图片' '问题最大是否包含视频' '问题最大没有帮助数' '问题最大点赞数'\n",
      " '问题最大评论数' '问题最近一周回答比例' 'num_atten_topic' 'num_interest_topic'\n",
      " 'most_interest_topic' 'min_interest_values' 'max_interest_values'\n",
      " 'mean_interest_values' 'std_interest_values']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编码**：将离散型的特征通过LabelEncoder进行数字编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_feat = ['性别', '访问评率','用户多分类特征a','用户多分类特征b','用户多分类特征c','用户多分类特征d','用户多分类特征e']\n",
    "encoder = LabelEncoder()\n",
    "for feat in class_feat:\n",
    "    encoder.fit(data[feat])\n",
    "    data[feat] = encoder.transform(data[feat])\n",
    "\n",
    "class_feat = ['用户id','问题id',]\n",
    "encoder = LabelEncoder()\n",
    "for feat in class_feat:\n",
    "    data['编码前'+feat] = data[feat]\n",
    "    encoder.fit(data[feat])\n",
    "    data[feat] = encoder.transform(data[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             问题id      编码前问题id\n",
      "0          327358  Q2166419046\n",
      "1          154388  Q1550017551\n",
      "2          972853   Q604029601\n",
      "3          379015  Q2350061229\n",
      "4          405239  Q2443223942\n",
      "5          983078   Q640765464\n",
      "6         1026507   Q795459266\n",
      "7          253947   Q190554387\n",
      "8          268933  Q1958712851\n",
      "9          594767   Q311993584\n",
      "10          29148   Q110462128\n",
      "11         915753  Q4265255633\n",
      "12        1051672   Q885275494\n",
      "13         748219  Q3667003932\n",
      "14         618224  Q3203261036\n",
      "15         110049  Q1392973250\n",
      "16         781496  Q3785192737\n",
      "17         489174  Q2743747344\n",
      "18         223029  Q1795395339\n",
      "19         375831   Q233889623\n",
      "20        1025739   Q792624945\n",
      "21         588335  Q3097516518\n",
      "22         725489  Q3585956324\n",
      "23         278899  Q1993990469\n",
      "24         624674  Q3226256008\n",
      "25         428129  Q2525843774\n",
      "26         887223  Q4163388497\n",
      "27         859262  Q4062946420\n",
      "28         533976  Q2903515283\n",
      "29          23418  Q1083988747\n",
      "...           ...          ...\n",
      "10630815   793898  Q3829602327\n",
      "10630816  1077664   Q978121509\n",
      "10630817   785487  Q3799316241\n",
      "10630818   967953   Q586224890\n",
      "10630819    43899  Q1156535365\n",
      "10630820    24217  Q1086754099\n",
      "10630821   388781   Q238531135\n",
      "10630822   480283  Q2712514748\n",
      "10630823   523969  Q2867766620\n",
      "10630824   993970   Q679243052\n",
      "10630825  1032498   Q816688891\n",
      "10630826  1008314   Q729775785\n",
      "10630827   491142  Q2750642401\n",
      "10630828   477275  Q2702020750\n",
      "10630829   878254  Q4131424015\n",
      "10630830   671291  Q3392634032\n",
      "10630831   918162  Q4274060389\n",
      "10630832   798866  Q3847308625\n",
      "10630833   284382  Q2013872163\n",
      "10630834   806966  Q3876148676\n",
      "10630835   425545  Q2516377406\n",
      "10630836     6887    Q10247829\n",
      "10630837   972607   Q603124625\n",
      "10630838   371903  Q2324697391\n",
      "10630839   730050  Q3602223917\n",
      "10630840    66910  Q1238703523\n",
      "10630841    20657  Q1074024036\n",
      "10630842   695453  Q3478846332\n",
      "10630843  1009533   Q734170704\n",
      "10630844   446321  Q2590286630\n",
      "\n",
      "[10630845 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[['问题id','编码前问题id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**构造计数特征**：对具有很好区分度的特征进行单特征计数（有明显提升）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['邀请创建时间-day','邀请创建时间-hour','问题创建时间-day','问题创建时间-hour']:\n",
    "    data[feat] = data[feat].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['问题创建时间-weekday'] = data['问题创建时间-day'].map(lambda x: x%7)\n",
    "data['邀请创建时间-weekday'] = data['邀请创建时间-day'].map(lambda x: x%7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u_a_i_diffday_max' 'u_a_i_diffday_mean' 'u_a_i_diffday_min'\n",
      " 'u_a_i_diffday_sum' 'u_a_i_diffhour_max' 'u_a_i_diffhour_mean'\n",
      " 'u_a_i_diffhour_min' 'u_a_i_diffhour_sum' '性别' '是否回答' '用户id'\n",
      " '用户上次回答时间-day' '用户习惯回答时间-hour' '用户二分类特征a' '用户二分类特征b' '用户二分类特征c'\n",
      " '用户二分类特征d' '用户二分类特征e' '用户关联回答数' '用户多分类特征a' '用户多分类特征b' '用户多分类特征c'\n",
      " '用户多分类特征d' '用户多分类特征e' '用户平均举报数' '用户平均反对数' '用户平均取赞数' '用户平均回答字数'\n",
      " '用户平均回答是否被推荐' '用户平均回答是否被收入圆桌' '用户平均回答是否被标优' '用户平均感谢数' '用户平均收藏数'\n",
      " '用户平均是否包含图片' '用户平均是否包含视频' '用户平均没有帮助数' '用户平均点赞数' '用户平均评论数' '用户总举报数'\n",
      " '用户总反对数' '用户总取赞数' '用户总回答字数' '用户总回答是否被推荐' '用户总回答是否被收入圆桌' '用户总回答是否被标优'\n",
      " '用户总感谢数' '用户总收藏数' '用户总是否包含图片' '用户总是否包含视频' '用户总没有帮助数' '用户总点赞数' '用户总评论数'\n",
      " '用户最大举报数' '用户最大反对数' '用户最大取赞数' '用户最大回答字数' '用户最大回答是否被推荐' '用户最大回答是否被收入圆桌'\n",
      " '用户最大回答是否被标优' '用户最大感谢数' '用户最大收藏数' '用户最大是否包含图片' '用户最大是否包含视频' '用户最大没有帮助数'\n",
      " '用户最大点赞数' '用户最大评论数' '用户最近回答数-14天' '用户最近回答数-3天' '用户最近回答数-7天' '用户邀请_count'\n",
      " '用户邀请平均' '用户邀请方差' '用户邀请求和' '用户问题的话题关注重叠数' '用户问题的话题感兴趣重叠数' '盐值' '访问评率'\n",
      " '邀请创建时间-day' '邀请创建时间-hour' '问题id' '问题上次回答时间' '问题关联回答数' '问题创建时间-day'\n",
      " '问题创建时间-hour' '问题平均举报数' '问题平均反对数' '问题平均取赞数' '问题平均回答字数' '问题平均回答是否被推荐'\n",
      " '问题平均回答是否被收入圆桌' '问题平均回答是否被标优' '问题平均感谢数' '问题平均收藏数' '问题平均是否包含图片'\n",
      " '问题平均是否包含视频' '问题平均没有帮助数' '问题平均点赞数' '问题平均评论数' '问题总举报数' '问题总反对数' '问题总取赞数'\n",
      " '问题总回答字数' '问题总回答是否被推荐' '问题总回答是否被收入圆桌' '问题总回答是否被标优' '问题总感谢数' '问题总收藏数'\n",
      " '问题总是否包含图片' '问题总是否包含视频' '问题总没有帮助数' '问题总点赞数' '问题总评论数' '问题最大举报数' '问题最大反对数'\n",
      " '问题最大取赞数' '问题最大回答字数' '问题最大回答是否被推荐' '问题最大回答是否被收入圆桌' '问题最大回答是否被标优'\n",
      " '问题最大感谢数' '问题最大收藏数' '问题最大是否包含图片' '问题最大是否包含视频' '问题最大没有帮助数' '问题最大点赞数'\n",
      " '问题最大评论数' '问题最近一周回答比例' 'num_atten_topic' 'num_interest_topic'\n",
      " 'most_interest_topic' 'min_interest_values' 'max_interest_values'\n",
      " 'mean_interest_values' 'std_interest_values' '编码前用户id' '编码前问题id'\n",
      " '问题创建时间-weekday' '邀请创建时间-weekday']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = None\n",
    "#pd.set_option('display.width',100)\n",
    "\n",
    "def creat_count_features(data):\n",
    "    #count_feats = []\n",
    "    for feat in ['用户id','问题id','性别', '访问评率','用户二分类特征a', '用户二分类特征b', '用户二分类特征c', '用户二分类特征d',\n",
    "       '用户二分类特征e','用户多分类特征a','用户多分类特征b','用户多分类特征c','用户多分类特征d','用户多分类特征e','邀请创建时间-hour','问题创建时间-hour',\n",
    "            '问题创建时间-weekday','邀请创建时间-weekday','问题创建时间-day']:\n",
    "        col_name = '{}_count'.format(feat)\n",
    "        #count_feats.append(col_name)\n",
    "        data[col_name] = data[feat].map(data[feat].value_counts().astype(int)) #为每个特征，匹配上其每个值对应到的 该值出现的次数\n",
    "        data.loc[data[col_name] < 2, feat] = -1 #为所有 只出现过一次的特征值 都设置成 -1\n",
    "        data[feat] += 1 # 因为有的特征值本身为0，结合上一步的步骤，让已被设置为-1的值和原来为0的特征值 区分开来，所以上一步才设为-1，这一步统一加1，让所有特征值都保证都>= 0\n",
    "        data[col_name] = data[feat].map(data[feat].value_counts().astype(int))\n",
    "        data[col_name] = (data[col_name] - data[col_name].min()) / (data[col_name].max() - data[col_name].min()) #把所有值正则化一下，保证在0-1区间\n",
    "    \n",
    "    return data#, count_feats\n",
    "\n",
    "data = creat_count_features(data)\n",
    "\n",
    "# train_start = 3807\n",
    "# train_end = 3860\n",
    "# val_start = train_start + 7\n",
    "# val_end = train_end + 7\n",
    "\n",
    "# fortrain1 = creat_count_features(data[data['邀请创建时间-day']>=train_start][data['邀请创建时间-day']<=train_end])\n",
    "# forval1 = creat_count_features(data[data['邀请创建时间-day']>=val_start][data['邀请创建时间-day']<=val_end])\n",
    "\n",
    "# on_feats = [x for x in data.columns.values if x not in count_feats ]\n",
    "\n",
    "# train3 = pd.merge(data[:train1.shape[0]], fortrain1, how='left', on= on_feats )\n",
    "# test3 = pd.merge(data[train1.shape[0]:], forval1, how='left', on= on_feats)\n",
    "# data = pd.concat([train3, test3], axis=0, sort=True)\n",
    "\n",
    "# #print(data.head(30))\n",
    "#     #break\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10630845 entries, 0 to 10630844\n",
      "Columns: 157 entries, u_a_i_diffday_max to 问题创建时间-day_count\n",
      "dtypes: float32(111), float64(19), int16(6), int64(11), int8(8), object(2)\n",
      "memory usage: 7.2+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf('data.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiyangguang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_for_train1 = data[data['邀请创建时间-day']>=3861][data['邀请创建时间-day']<=3867]\n",
    "data_for_test1 = data[train1.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_for_train1.to_hdf('data_for_train.h5', key='data')\n",
    "data_for_test1.to_hdf('data_for_test.h5', key='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 user_answer 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.模型训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "train1 = pd.read_csv(os.path.join(data_path, 'invite_info_0926.txt'), header=None, sep='\\t')\n",
    "test1 = pd.read_csv(os.path.join(data_path, 'invite_info_evaluate_1_0926.txt'), header=None, sep='\\t')\n",
    "data = pd.read_hdf('data.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_train1 = pd.read_hdf('data_for_train.h5', key='data')\n",
    "data_for_test1 = pd.read_hdf('data_for_test.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_u_i_hr_pcrt(answer_info):\n",
    "    t3 = answer_info\n",
    "    t3 = answer_info.groupby('用户id')['邀请创建时间-hour'].agg('value_counts').to_frame()\n",
    "    t3.columns = ['u_i_hr_count']\n",
    "    t3 = t3.reset_index()\n",
    "    answer_info = pd.merge(answer_info, t3, on=['用户id','邀请创建时间-hour'], how='left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415013\n"
     ]
    }
   ],
   "source": [
    "print(len(data_for_train1[data_for_train1['是否回答']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593669\n"
     ]
    }
   ],
   "source": [
    "print(len(data_for_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9489162\n"
     ]
    }
   ],
   "source": [
    "train_len = train1.shape[0]\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10630845 entries, 0 to 10630844\n",
      "Columns: 157 entries, u_a_i_diffday_max to 问题创建时间-day_count\n",
      "dtypes: float32(111), float64(19), int16(6), int64(11), int8(8), object(2)\n",
      "memory usage: 7.1+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_saved = False\n",
    "scores=[]\n",
    "\n",
    "# data1 = data[:train1.shape[0]][data['邀请创建时间-day']<3863][data['邀请创建时间-day']>3837]\n",
    "# data2 = data[:train1.shape[0]][data['邀请创建时间-day']<3868][data['邀请创建时间-day']>3862]\n",
    "\n",
    "# del data1['邀请创建时间-day'],data2['邀请创建时间-day']\n",
    "\n",
    "# y_train1 = data1['是否回答'].values\n",
    "# X_train1 = data1.drop(['是否回答'], axis=1).values\n",
    "\n",
    "\n",
    "# y_valid1 = data2['是否回答'].values\n",
    "# X_valid1 = data2.drop(['是否回答'], axis=1).values\n",
    "\n",
    "\n",
    "\n",
    "#X_train = data[:train1.shape[0]].drop(['是否回答'], axis=1).values\n",
    "#y_train = data[:train1.shape[0]]['是否回答'].values\n",
    "\n",
    "\n",
    "# X_test = data[train1.shape[0]:].drop(['是否回答'], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u_a_i_diffday_max' 'u_a_i_diffday_mean' 'u_a_i_diffday_min'\n",
      " 'u_a_i_diffday_sum' 'u_a_i_diffhour_max' 'u_a_i_diffhour_mean'\n",
      " 'u_a_i_diffhour_min' 'u_a_i_diffhour_sum' '性别' '是否回答' '用户id'\n",
      " '用户上次回答时间-day' '用户习惯回答时间-hour' '用户二分类特征a' '用户二分类特征b' '用户二分类特征c'\n",
      " '用户二分类特征d' '用户二分类特征e' '用户关联回答数' '用户多分类特征a' '用户多分类特征b' '用户多分类特征c'\n",
      " '用户多分类特征d' '用户多分类特征e' '用户平均举报数' '用户平均反对数' '用户平均取赞数' '用户平均回答字数'\n",
      " '用户平均回答是否被推荐' '用户平均回答是否被收入圆桌' '用户平均回答是否被标优' '用户平均感谢数' '用户平均收藏数'\n",
      " '用户平均是否包含图片' '用户平均是否包含视频' '用户平均没有帮助数' '用户平均点赞数' '用户平均评论数' '用户总举报数'\n",
      " '用户总反对数' '用户总取赞数' '用户总回答字数' '用户总回答是否被推荐' '用户总回答是否被收入圆桌' '用户总回答是否被标优'\n",
      " '用户总感谢数' '用户总收藏数' '用户总是否包含图片' '用户总是否包含视频' '用户总没有帮助数' '用户总点赞数' '用户总评论数'\n",
      " '用户最大举报数' '用户最大反对数' '用户最大取赞数' '用户最大回答字数' '用户最大回答是否被推荐' '用户最大回答是否被收入圆桌'\n",
      " '用户最大回答是否被标优' '用户最大感谢数' '用户最大收藏数' '用户最大是否包含图片' '用户最大是否包含视频' '用户最大没有帮助数'\n",
      " '用户最大点赞数' '用户最大评论数' '用户最近回答数-14天' '用户最近回答数-3天' '用户最近回答数-7天' '用户邀请_count'\n",
      " '用户邀请平均' '用户邀请方差' '用户邀请求和' '用户问题的话题关注重叠数' '用户问题的话题感兴趣重叠数' '盐值' '访问评率'\n",
      " '邀请创建时间-day' '邀请创建时间-hour' '问题id' '问题上次回答时间' '问题关联回答数' '问题创建时间-day'\n",
      " '问题创建时间-hour' '问题平均举报数' '问题平均反对数' '问题平均取赞数' '问题平均回答字数' '问题平均回答是否被推荐'\n",
      " '问题平均回答是否被收入圆桌' '问题平均回答是否被标优' '问题平均感谢数' '问题平均收藏数' '问题平均是否包含图片'\n",
      " '问题平均是否包含视频' '问题平均没有帮助数' '问题平均点赞数' '问题平均评论数' '问题总举报数' '问题总反对数' '问题总取赞数'\n",
      " '问题总回答字数' '问题总回答是否被推荐' '问题总回答是否被收入圆桌' '问题总回答是否被标优' '问题总感谢数' '问题总收藏数'\n",
      " '问题总是否包含图片' '问题总是否包含视频' '问题总没有帮助数' '问题总点赞数' '问题总评论数' '问题最大举报数' '问题最大反对数'\n",
      " '问题最大取赞数' '问题最大回答字数' '问题最大回答是否被推荐' '问题最大回答是否被收入圆桌' '问题最大回答是否被标优'\n",
      " '问题最大感谢数' '问题最大收藏数' '问题最大是否包含图片' '问题最大是否包含视频' '问题最大没有帮助数' '问题最大点赞数'\n",
      " '问题最大评论数' '问题最近一周回答比例' 'num_atten_topic' 'num_interest_topic'\n",
      " 'most_interest_topic' 'min_interest_values' 'max_interest_values'\n",
      " 'mean_interest_values' 'std_interest_values' '编码前用户id' '编码前问题id'\n",
      " '问题创建时间-weekday' '邀请创建时间-weekday' '用户id_count' '问题id_count' '性别_count'\n",
      " '访问评率_count' '用户二分类特征a_count' '用户二分类特征b_count' '用户二分类特征c_count'\n",
      " '用户二分类特征d_count' '用户二分类特征e_count' '用户多分类特征a_count' '用户多分类特征b_count'\n",
      " '用户多分类特征c_count' '用户多分类特征d_count' '用户多分类特征e_count' '邀请创建时间-hour_count'\n",
      " '问题创建时间-hour_count' '问题创建时间-weekday_count' '邀请创建时间-weekday_count'\n",
      " '问题创建时间-day_count']\n"
     ]
    }
   ],
   "source": [
    "print(data_for_train1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feat = ['邀请创建时间-day','编码前用户id','编码前问题id']\n",
    "# data  = data.drop(drop_feat, axis=1)\n",
    "data1 = data_for_train1.drop(drop_feat, axis=1)\n",
    "data2 = data_for_test1.drop(drop_feat, axis=1)\n",
    "\n",
    "X_train = data1.drop(['是否回答'], axis=1).values\n",
    "y_train = data1['是否回答'].values\n",
    "\n",
    "X_test = data2.drop(['是否回答'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u_a_i_diffday_max' 'u_a_i_diffday_mean' 'u_a_i_diffday_min'\n",
      " 'u_a_i_diffday_sum' 'u_a_i_diffhour_max' 'u_a_i_diffhour_mean'\n",
      " 'u_a_i_diffhour_min' 'u_a_i_diffhour_sum' '性别' '是否回答' '用户id'\n",
      " '用户上次回答时间-day' '用户习惯回答时间-hour' '用户二分类特征a' '用户二分类特征b' '用户二分类特征c'\n",
      " '用户二分类特征d' '用户二分类特征e' '用户关联回答数' '用户多分类特征a' '用户多分类特征b' '用户多分类特征c'\n",
      " '用户多分类特征d' '用户多分类特征e' '用户平均举报数' '用户平均反对数' '用户平均取赞数' '用户平均回答字数'\n",
      " '用户平均回答是否被推荐' '用户平均回答是否被收入圆桌' '用户平均回答是否被标优' '用户平均感谢数' '用户平均收藏数'\n",
      " '用户平均是否包含图片' '用户平均是否包含视频' '用户平均没有帮助数' '用户平均点赞数' '用户平均评论数' '用户总举报数'\n",
      " '用户总反对数' '用户总取赞数' '用户总回答字数' '用户总回答是否被推荐' '用户总回答是否被收入圆桌' '用户总回答是否被标优'\n",
      " '用户总感谢数' '用户总收藏数' '用户总是否包含图片' '用户总是否包含视频' '用户总没有帮助数' '用户总点赞数' '用户总评论数'\n",
      " '用户最大举报数' '用户最大反对数' '用户最大取赞数' '用户最大回答字数' '用户最大回答是否被推荐' '用户最大回答是否被收入圆桌'\n",
      " '用户最大回答是否被标优' '用户最大感谢数' '用户最大收藏数' '用户最大是否包含图片' '用户最大是否包含视频' '用户最大没有帮助数'\n",
      " '用户最大点赞数' '用户最大评论数' '用户最近回答数-14天' '用户最近回答数-3天' '用户最近回答数-7天' '用户邀请_count'\n",
      " '用户邀请平均' '用户邀请方差' '用户邀请求和' '用户问题的话题关注重叠数' '用户问题的话题感兴趣重叠数' '盐值' '访问评率'\n",
      " '邀请创建时间-hour' '问题id' '问题上次回答时间' '问题关联回答数' '问题创建时间-day' '问题创建时间-hour'\n",
      " '问题平均举报数' '问题平均反对数' '问题平均取赞数' '问题平均回答字数' '问题平均回答是否被推荐' '问题平均回答是否被收入圆桌'\n",
      " '问题平均回答是否被标优' '问题平均感谢数' '问题平均收藏数' '问题平均是否包含图片' '问题平均是否包含视频' '问题平均没有帮助数'\n",
      " '问题平均点赞数' '问题平均评论数' '问题总举报数' '问题总反对数' '问题总取赞数' '问题总回答字数' '问题总回答是否被推荐'\n",
      " '问题总回答是否被收入圆桌' '问题总回答是否被标优' '问题总感谢数' '问题总收藏数' '问题总是否包含图片' '问题总是否包含视频'\n",
      " '问题总没有帮助数' '问题总点赞数' '问题总评论数' '问题最大举报数' '问题最大反对数' '问题最大取赞数' '问题最大回答字数'\n",
      " '问题最大回答是否被推荐' '问题最大回答是否被收入圆桌' '问题最大回答是否被标优' '问题最大感谢数' '问题最大收藏数'\n",
      " '问题最大是否包含图片' '问题最大是否包含视频' '问题最大没有帮助数' '问题最大点赞数' '问题最大评论数' '问题最近一周回答比例'\n",
      " 'num_atten_topic' 'num_interest_topic' 'most_interest_topic'\n",
      " 'min_interest_values' 'max_interest_values' 'mean_interest_values'\n",
      " 'std_interest_values' '问题创建时间-weekday' '邀请创建时间-weekday' '用户id_count'\n",
      " '问题id_count' '性别_count' '访问评率_count' '用户二分类特征a_count' '用户二分类特征b_count'\n",
      " '用户二分类特征c_count' '用户二分类特征d_count' '用户二分类特征e_count' '用户多分类特征a_count'\n",
      " '用户多分类特征b_count' '用户多分类特征c_count' '用户多分类特征d_count' '用户多分类特征e_count'\n",
      " '邀请创建时间-hour_count' '问题创建时间-hour_count' '问题创建时间-weekday_count'\n",
      " '邀请创建时间-weekday_count' '问题创建时间-day_count']\n"
     ]
    }
   ],
   "source": [
    "print(data1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "[1]\ttrain's auc: 0.766402\ttrain's binary_logloss: 0.426082\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\ttrain's auc: 0.777281\ttrain's binary_logloss: 0.415608\n",
      "[3]\ttrain's auc: 0.783107\ttrain's binary_logloss: 0.40713\n",
      "[4]\ttrain's auc: 0.788146\ttrain's binary_logloss: 0.399918\n",
      "[5]\ttrain's auc: 0.789951\ttrain's binary_logloss: 0.394209\n",
      "[6]\ttrain's auc: 0.792275\ttrain's binary_logloss: 0.389234\n",
      "[7]\ttrain's auc: 0.795278\ttrain's binary_logloss: 0.384704\n",
      "[8]\ttrain's auc: 0.797091\ttrain's binary_logloss: 0.380953\n",
      "[9]\ttrain's auc: 0.798111\ttrain's binary_logloss: 0.377674\n",
      "[10]\ttrain's auc: 0.799132\ttrain's binary_logloss: 0.374838\n",
      "[11]\ttrain's auc: 0.800177\ttrain's binary_logloss: 0.372344\n",
      "[12]\ttrain's auc: 0.801238\ttrain's binary_logloss: 0.370002\n",
      "[13]\ttrain's auc: 0.801745\ttrain's binary_logloss: 0.368129\n",
      "[14]\ttrain's auc: 0.802699\ttrain's binary_logloss: 0.366374\n",
      "[15]\ttrain's auc: 0.803656\ttrain's binary_logloss: 0.364698\n",
      "[16]\ttrain's auc: 0.804215\ttrain's binary_logloss: 0.363273\n",
      "[17]\ttrain's auc: 0.805372\ttrain's binary_logloss: 0.361744\n",
      "[18]\ttrain's auc: 0.80595\ttrain's binary_logloss: 0.360568\n",
      "[19]\ttrain's auc: 0.806582\ttrain's binary_logloss: 0.359416\n",
      "[20]\ttrain's auc: 0.807301\ttrain's binary_logloss: 0.358345\n",
      "[21]\ttrain's auc: 0.808099\ttrain's binary_logloss: 0.357376\n",
      "[22]\ttrain's auc: 0.808675\ttrain's binary_logloss: 0.356483\n",
      "[23]\ttrain's auc: 0.809206\ttrain's binary_logloss: 0.35565\n",
      "[24]\ttrain's auc: 0.809991\ttrain's binary_logloss: 0.354759\n",
      "[25]\ttrain's auc: 0.810604\ttrain's binary_logloss: 0.35402\n",
      "[26]\ttrain's auc: 0.811217\ttrain's binary_logloss: 0.353249\n",
      "[27]\ttrain's auc: 0.811666\ttrain's binary_logloss: 0.352629\n",
      "[28]\ttrain's auc: 0.812182\ttrain's binary_logloss: 0.351941\n",
      "[29]\ttrain's auc: 0.812695\ttrain's binary_logloss: 0.351332\n",
      "[30]\ttrain's auc: 0.813208\ttrain's binary_logloss: 0.350795\n",
      "[31]\ttrain's auc: 0.813609\ttrain's binary_logloss: 0.350317\n",
      "[32]\ttrain's auc: 0.814012\ttrain's binary_logloss: 0.349822\n",
      "[33]\ttrain's auc: 0.814389\ttrain's binary_logloss: 0.349361\n",
      "[34]\ttrain's auc: 0.81477\ttrain's binary_logloss: 0.348933\n",
      "[35]\ttrain's auc: 0.815081\ttrain's binary_logloss: 0.348578\n",
      "[36]\ttrain's auc: 0.815471\ttrain's binary_logloss: 0.348177\n",
      "[37]\ttrain's auc: 0.815709\ttrain's binary_logloss: 0.347904\n",
      "[38]\ttrain's auc: 0.816053\ttrain's binary_logloss: 0.347492\n",
      "[39]\ttrain's auc: 0.816398\ttrain's binary_logloss: 0.347134\n",
      "[40]\ttrain's auc: 0.816668\ttrain's binary_logloss: 0.346844\n",
      "[41]\ttrain's auc: 0.816933\ttrain's binary_logloss: 0.346554\n",
      "[42]\ttrain's auc: 0.817159\ttrain's binary_logloss: 0.346291\n",
      "[43]\ttrain's auc: 0.817338\ttrain's binary_logloss: 0.346081\n",
      "[44]\ttrain's auc: 0.817531\ttrain's binary_logloss: 0.345883\n",
      "[45]\ttrain's auc: 0.81774\ttrain's binary_logloss: 0.345644\n",
      "[46]\ttrain's auc: 0.817924\ttrain's binary_logloss: 0.34545\n",
      "[47]\ttrain's auc: 0.818133\ttrain's binary_logloss: 0.345219\n",
      "[48]\ttrain's auc: 0.818323\ttrain's binary_logloss: 0.344999\n",
      "[49]\ttrain's auc: 0.8185\ttrain's binary_logloss: 0.344834\n",
      "[50]\ttrain's auc: 0.818737\ttrain's binary_logloss: 0.344575\n",
      "[51]\ttrain's auc: 0.81895\ttrain's binary_logloss: 0.344387\n",
      "[52]\ttrain's auc: 0.819154\ttrain's binary_logloss: 0.344208\n",
      "[53]\ttrain's auc: 0.819266\ttrain's binary_logloss: 0.344078\n",
      "[54]\ttrain's auc: 0.81937\ttrain's binary_logloss: 0.343959\n",
      "[55]\ttrain's auc: 0.819579\ttrain's binary_logloss: 0.343759\n",
      "[56]\ttrain's auc: 0.819743\ttrain's binary_logloss: 0.343587\n",
      "[57]\ttrain's auc: 0.819977\ttrain's binary_logloss: 0.343388\n",
      "[58]\ttrain's auc: 0.820335\ttrain's binary_logloss: 0.343035\n",
      "[59]\ttrain's auc: 0.820508\ttrain's binary_logloss: 0.342878\n",
      "[60]\ttrain's auc: 0.820706\ttrain's binary_logloss: 0.342694\n",
      "[61]\ttrain's auc: 0.820888\ttrain's binary_logloss: 0.342503\n",
      "[62]\ttrain's auc: 0.821006\ttrain's binary_logloss: 0.342389\n",
      "[63]\ttrain's auc: 0.821096\ttrain's binary_logloss: 0.342301\n",
      "[64]\ttrain's auc: 0.821223\ttrain's binary_logloss: 0.342183\n",
      "[65]\ttrain's auc: 0.821314\ttrain's binary_logloss: 0.342096\n",
      "[66]\ttrain's auc: 0.821576\ttrain's binary_logloss: 0.341851\n",
      "[67]\ttrain's auc: 0.821707\ttrain's binary_logloss: 0.34175\n",
      "[68]\ttrain's auc: 0.821905\ttrain's binary_logloss: 0.341569\n",
      "[69]\ttrain's auc: 0.822062\ttrain's binary_logloss: 0.341421\n",
      "[70]\ttrain's auc: 0.822193\ttrain's binary_logloss: 0.341277\n",
      "[71]\ttrain's auc: 0.822305\ttrain's binary_logloss: 0.341182\n",
      "[72]\ttrain's auc: 0.822425\ttrain's binary_logloss: 0.341054\n",
      "[73]\ttrain's auc: 0.822554\ttrain's binary_logloss: 0.340956\n",
      "[74]\ttrain's auc: 0.822653\ttrain's binary_logloss: 0.340869\n",
      "[75]\ttrain's auc: 0.822787\ttrain's binary_logloss: 0.340742\n",
      "[76]\ttrain's auc: 0.822893\ttrain's binary_logloss: 0.340649\n",
      "[77]\ttrain's auc: 0.823021\ttrain's binary_logloss: 0.340505\n",
      "[78]\ttrain's auc: 0.823194\ttrain's binary_logloss: 0.340368\n",
      "[79]\ttrain's auc: 0.823311\ttrain's binary_logloss: 0.340274\n",
      "[80]\ttrain's auc: 0.823391\ttrain's binary_logloss: 0.340216\n",
      "[81]\ttrain's auc: 0.823455\ttrain's binary_logloss: 0.340148\n",
      "[82]\ttrain's auc: 0.823643\ttrain's binary_logloss: 0.339981\n",
      "[83]\ttrain's auc: 0.823748\ttrain's binary_logloss: 0.339893\n",
      "[84]\ttrain's auc: 0.82382\ttrain's binary_logloss: 0.339829\n",
      "[85]\ttrain's auc: 0.823866\ttrain's binary_logloss: 0.339786\n",
      "[86]\ttrain's auc: 0.82401\ttrain's binary_logloss: 0.33964\n",
      "[87]\ttrain's auc: 0.82416\ttrain's binary_logloss: 0.339524\n",
      "[88]\ttrain's auc: 0.82432\ttrain's binary_logloss: 0.339366\n",
      "[89]\ttrain's auc: 0.82448\ttrain's binary_logloss: 0.339222\n",
      "[90]\ttrain's auc: 0.824588\ttrain's binary_logloss: 0.339131\n",
      "[91]\ttrain's auc: 0.824662\ttrain's binary_logloss: 0.339065\n",
      "[92]\ttrain's auc: 0.824738\ttrain's binary_logloss: 0.338997\n",
      "[93]\ttrain's auc: 0.824841\ttrain's binary_logloss: 0.338877\n",
      "[94]\ttrain's auc: 0.824946\ttrain's binary_logloss: 0.33879\n",
      "[95]\ttrain's auc: 0.825038\ttrain's binary_logloss: 0.33871\n",
      "[96]\ttrain's auc: 0.825137\ttrain's binary_logloss: 0.338588\n",
      "[97]\ttrain's auc: 0.825201\ttrain's binary_logloss: 0.338534\n",
      "[98]\ttrain's auc: 0.825283\ttrain's binary_logloss: 0.33846\n",
      "[99]\ttrain's auc: 0.825366\ttrain's binary_logloss: 0.338391\n",
      "[100]\ttrain's auc: 0.82542\ttrain's binary_logloss: 0.33835\n",
      "[101]\ttrain's auc: 0.825484\ttrain's binary_logloss: 0.338292\n",
      "[102]\ttrain's auc: 0.82557\ttrain's binary_logloss: 0.338216\n",
      "[103]\ttrain's auc: 0.825651\ttrain's binary_logloss: 0.338123\n",
      "[104]\ttrain's auc: 0.825723\ttrain's binary_logloss: 0.338054\n",
      "[105]\ttrain's auc: 0.825813\ttrain's binary_logloss: 0.337982\n",
      "[106]\ttrain's auc: 0.825872\ttrain's binary_logloss: 0.337934\n",
      "[107]\ttrain's auc: 0.825937\ttrain's binary_logloss: 0.33786\n",
      "[108]\ttrain's auc: 0.825969\ttrain's binary_logloss: 0.337835\n",
      "[109]\ttrain's auc: 0.82606\ttrain's binary_logloss: 0.337739\n",
      "[110]\ttrain's auc: 0.826163\ttrain's binary_logloss: 0.337655\n",
      "[111]\ttrain's auc: 0.826239\ttrain's binary_logloss: 0.337584\n",
      "[112]\ttrain's auc: 0.826346\ttrain's binary_logloss: 0.337494\n",
      "[113]\ttrain's auc: 0.826405\ttrain's binary_logloss: 0.337447\n",
      "[114]\ttrain's auc: 0.826474\ttrain's binary_logloss: 0.337391\n",
      "[115]\ttrain's auc: 0.826638\ttrain's binary_logloss: 0.337239\n",
      "[116]\ttrain's auc: 0.826706\ttrain's binary_logloss: 0.337169\n",
      "[117]\ttrain's auc: 0.826785\ttrain's binary_logloss: 0.33711\n",
      "[118]\ttrain's auc: 0.826835\ttrain's binary_logloss: 0.337069\n",
      "[119]\ttrain's auc: 0.826909\ttrain's binary_logloss: 0.337009\n",
      "[120]\ttrain's auc: 0.826948\ttrain's binary_logloss: 0.336981\n",
      "[121]\ttrain's auc: 0.827034\ttrain's binary_logloss: 0.336897\n",
      "[122]\ttrain's auc: 0.827096\ttrain's binary_logloss: 0.33683\n",
      "[123]\ttrain's auc: 0.827162\ttrain's binary_logloss: 0.336781\n",
      "[124]\ttrain's auc: 0.827216\ttrain's binary_logloss: 0.336741\n",
      "[125]\ttrain's auc: 0.827306\ttrain's binary_logloss: 0.336658\n",
      "[126]\ttrain's auc: 0.827349\ttrain's binary_logloss: 0.336623\n",
      "[127]\ttrain's auc: 0.827429\ttrain's binary_logloss: 0.336565\n",
      "[128]\ttrain's auc: 0.827471\ttrain's binary_logloss: 0.336531\n",
      "[129]\ttrain's auc: 0.827511\ttrain's binary_logloss: 0.336494\n",
      "[130]\ttrain's auc: 0.827585\ttrain's binary_logloss: 0.336437\n",
      "[131]\ttrain's auc: 0.827623\ttrain's binary_logloss: 0.336392\n",
      "[132]\ttrain's auc: 0.827685\ttrain's binary_logloss: 0.336344\n",
      "[133]\ttrain's auc: 0.827736\ttrain's binary_logloss: 0.336305\n",
      "[134]\ttrain's auc: 0.827779\ttrain's binary_logloss: 0.336269\n",
      "[135]\ttrain's auc: 0.827827\ttrain's binary_logloss: 0.336228\n",
      "[136]\ttrain's auc: 0.827874\ttrain's binary_logloss: 0.33619\n",
      "[137]\ttrain's auc: 0.827921\ttrain's binary_logloss: 0.336154\n",
      "[138]\ttrain's auc: 0.827985\ttrain's binary_logloss: 0.336083\n",
      "[139]\ttrain's auc: 0.828054\ttrain's binary_logloss: 0.336017\n",
      "[140]\ttrain's auc: 0.828076\ttrain's binary_logloss: 0.335998\n",
      "[141]\ttrain's auc: 0.828107\ttrain's binary_logloss: 0.335978\n",
      "[142]\ttrain's auc: 0.828144\ttrain's binary_logloss: 0.335947\n",
      "[143]\ttrain's auc: 0.828166\ttrain's binary_logloss: 0.33593\n",
      "[144]\ttrain's auc: 0.828257\ttrain's binary_logloss: 0.335831\n",
      "[145]\ttrain's auc: 0.828302\ttrain's binary_logloss: 0.335795\n",
      "[146]\ttrain's auc: 0.828352\ttrain's binary_logloss: 0.335755\n",
      "[147]\ttrain's auc: 0.828378\ttrain's binary_logloss: 0.335726\n",
      "[148]\ttrain's auc: 0.8284\ttrain's binary_logloss: 0.335707\n",
      "[149]\ttrain's auc: 0.828431\ttrain's binary_logloss: 0.335682\n",
      "[150]\ttrain's auc: 0.828459\ttrain's binary_logloss: 0.335656\n",
      "[151]\ttrain's auc: 0.82853\ttrain's binary_logloss: 0.335578\n",
      "[152]\ttrain's auc: 0.828561\ttrain's binary_logloss: 0.335553\n",
      "[153]\ttrain's auc: 0.828607\ttrain's binary_logloss: 0.33552\n",
      "[154]\ttrain's auc: 0.828652\ttrain's binary_logloss: 0.335483\n",
      "[155]\ttrain's auc: 0.828689\ttrain's binary_logloss: 0.335457\n",
      "[156]\ttrain's auc: 0.828719\ttrain's binary_logloss: 0.335435\n",
      "[157]\ttrain's auc: 0.828758\ttrain's binary_logloss: 0.335403\n",
      "[158]\ttrain's auc: 0.828778\ttrain's binary_logloss: 0.335391\n",
      "[159]\ttrain's auc: 0.828803\ttrain's binary_logloss: 0.335372\n",
      "[160]\ttrain's auc: 0.82884\ttrain's binary_logloss: 0.33534\n",
      "[161]\ttrain's auc: 0.828863\ttrain's binary_logloss: 0.335321\n",
      "[162]\ttrain's auc: 0.828925\ttrain's binary_logloss: 0.335251\n",
      "[163]\ttrain's auc: 0.828986\ttrain's binary_logloss: 0.335183\n",
      "[164]\ttrain's auc: 0.829031\ttrain's binary_logloss: 0.335144\n",
      "[165]\ttrain's auc: 0.829088\ttrain's binary_logloss: 0.335087\n",
      "[166]\ttrain's auc: 0.829115\ttrain's binary_logloss: 0.33507\n",
      "[167]\ttrain's auc: 0.829135\ttrain's binary_logloss: 0.335058\n",
      "[168]\ttrain's auc: 0.829163\ttrain's binary_logloss: 0.335038\n",
      "[169]\ttrain's auc: 0.829239\ttrain's binary_logloss: 0.334962\n",
      "[170]\ttrain's auc: 0.829286\ttrain's binary_logloss: 0.334917\n",
      "[171]\ttrain's auc: 0.829303\ttrain's binary_logloss: 0.334894\n",
      "[172]\ttrain's auc: 0.829356\ttrain's binary_logloss: 0.334855\n",
      "[173]\ttrain's auc: 0.829408\ttrain's binary_logloss: 0.334806\n",
      "[174]\ttrain's auc: 0.829501\ttrain's binary_logloss: 0.334725\n",
      "[175]\ttrain's auc: 0.829521\ttrain's binary_logloss: 0.334712\n",
      "[176]\ttrain's auc: 0.829556\ttrain's binary_logloss: 0.334672\n",
      "[177]\ttrain's auc: 0.82959\ttrain's binary_logloss: 0.334645\n",
      "[178]\ttrain's auc: 0.829628\ttrain's binary_logloss: 0.334619\n",
      "[179]\ttrain's auc: 0.829673\ttrain's binary_logloss: 0.334585\n",
      "[180]\ttrain's auc: 0.829697\ttrain's binary_logloss: 0.334562\n",
      "[181]\ttrain's auc: 0.829727\ttrain's binary_logloss: 0.334538\n",
      "[182]\ttrain's auc: 0.829746\ttrain's binary_logloss: 0.334524\n",
      "[183]\ttrain's auc: 0.829784\ttrain's binary_logloss: 0.334494\n",
      "[184]\ttrain's auc: 0.829819\ttrain's binary_logloss: 0.334468\n",
      "[185]\ttrain's auc: 0.829928\ttrain's binary_logloss: 0.334375\n",
      "[186]\ttrain's auc: 0.829934\ttrain's binary_logloss: 0.334368\n",
      "[187]\ttrain's auc: 0.829941\ttrain's binary_logloss: 0.334363\n",
      "[188]\ttrain's auc: 0.829965\ttrain's binary_logloss: 0.334343\n",
      "[189]\ttrain's auc: 0.829988\ttrain's binary_logloss: 0.334323\n",
      "[190]\ttrain's auc: 0.830049\ttrain's binary_logloss: 0.33426\n",
      "[191]\ttrain's auc: 0.830096\ttrain's binary_logloss: 0.334224\n",
      "[192]\ttrain's auc: 0.830113\ttrain's binary_logloss: 0.334205\n",
      "[193]\ttrain's auc: 0.830132\ttrain's binary_logloss: 0.334186\n",
      "[194]\ttrain's auc: 0.830178\ttrain's binary_logloss: 0.334147\n",
      "[195]\ttrain's auc: 0.830198\ttrain's binary_logloss: 0.334129\n",
      "[196]\ttrain's auc: 0.830217\ttrain's binary_logloss: 0.334113\n",
      "[197]\ttrain's auc: 0.830247\ttrain's binary_logloss: 0.334088\n",
      "[198]\ttrain's auc: 0.830264\ttrain's binary_logloss: 0.334074\n",
      "[199]\ttrain's auc: 0.830275\ttrain's binary_logloss: 0.334066\n",
      "[200]\ttrain's auc: 0.830337\ttrain's binary_logloss: 0.334008\n",
      "[201]\ttrain's auc: 0.830355\ttrain's binary_logloss: 0.333996\n",
      "[202]\ttrain's auc: 0.830367\ttrain's binary_logloss: 0.333986\n",
      "[203]\ttrain's auc: 0.830376\ttrain's binary_logloss: 0.33398\n",
      "[204]\ttrain's auc: 0.830395\ttrain's binary_logloss: 0.333966\n",
      "[205]\ttrain's auc: 0.830416\ttrain's binary_logloss: 0.333949\n",
      "[206]\ttrain's auc: 0.830421\ttrain's binary_logloss: 0.333945\n",
      "[207]\ttrain's auc: 0.830457\ttrain's binary_logloss: 0.33391\n",
      "[208]\ttrain's auc: 0.830481\ttrain's binary_logloss: 0.333891\n",
      "[209]\ttrain's auc: 0.830502\ttrain's binary_logloss: 0.333873\n",
      "[210]\ttrain's auc: 0.830516\ttrain's binary_logloss: 0.333859\n",
      "[211]\ttrain's auc: 0.83054\ttrain's binary_logloss: 0.333841\n",
      "[212]\ttrain's auc: 0.830572\ttrain's binary_logloss: 0.333823\n",
      "[213]\ttrain's auc: 0.830589\ttrain's binary_logloss: 0.33381\n",
      "[214]\ttrain's auc: 0.830607\ttrain's binary_logloss: 0.333798\n",
      "[215]\ttrain's auc: 0.830631\ttrain's binary_logloss: 0.33378\n",
      "[216]\ttrain's auc: 0.830668\ttrain's binary_logloss: 0.333727\n",
      "[217]\ttrain's auc: 0.830686\ttrain's binary_logloss: 0.333715\n",
      "[218]\ttrain's auc: 0.830727\ttrain's binary_logloss: 0.333683\n",
      "[219]\ttrain's auc: 0.830754\ttrain's binary_logloss: 0.333656\n",
      "[220]\ttrain's auc: 0.830761\ttrain's binary_logloss: 0.33365\n",
      "[221]\ttrain's auc: 0.830781\ttrain's binary_logloss: 0.333633\n",
      "[222]\ttrain's auc: 0.830795\ttrain's binary_logloss: 0.333624\n",
      "[223]\ttrain's auc: 0.830813\ttrain's binary_logloss: 0.333612\n",
      "[224]\ttrain's auc: 0.830853\ttrain's binary_logloss: 0.333565\n",
      "[225]\ttrain's auc: 0.830878\ttrain's binary_logloss: 0.333544\n",
      "[226]\ttrain's auc: 0.830895\ttrain's binary_logloss: 0.33353\n",
      "[227]\ttrain's auc: 0.830914\ttrain's binary_logloss: 0.333519\n",
      "[228]\ttrain's auc: 0.830925\ttrain's binary_logloss: 0.333509\n",
      "[229]\ttrain's auc: 0.830968\ttrain's binary_logloss: 0.333476\n",
      "[230]\ttrain's auc: 0.830999\ttrain's binary_logloss: 0.333451\n",
      "[231]\ttrain's auc: 0.831035\ttrain's binary_logloss: 0.333414\n",
      "[232]\ttrain's auc: 0.831066\ttrain's binary_logloss: 0.333384\n",
      "[233]\ttrain's auc: 0.831073\ttrain's binary_logloss: 0.333372\n",
      "[234]\ttrain's auc: 0.831099\ttrain's binary_logloss: 0.333351\n",
      "[235]\ttrain's auc: 0.831114\ttrain's binary_logloss: 0.33334\n",
      "[236]\ttrain's auc: 0.83113\ttrain's binary_logloss: 0.333327\n",
      "[237]\ttrain's auc: 0.831137\ttrain's binary_logloss: 0.333322\n",
      "[238]\ttrain's auc: 0.831168\ttrain's binary_logloss: 0.333297\n",
      "[239]\ttrain's auc: 0.831199\ttrain's binary_logloss: 0.333268\n",
      "[240]\ttrain's auc: 0.831207\ttrain's binary_logloss: 0.333261\n",
      "[241]\ttrain's auc: 0.831214\ttrain's binary_logloss: 0.333255\n",
      "[242]\ttrain's auc: 0.831225\ttrain's binary_logloss: 0.333248\n",
      "[243]\ttrain's auc: 0.831236\ttrain's binary_logloss: 0.333239\n",
      "[244]\ttrain's auc: 0.831251\ttrain's binary_logloss: 0.33323\n",
      "[245]\ttrain's auc: 0.831292\ttrain's binary_logloss: 0.333203\n",
      "[246]\ttrain's auc: 0.831336\ttrain's binary_logloss: 0.333167\n",
      "[247]\ttrain's auc: 0.83134\ttrain's binary_logloss: 0.333165\n",
      "[248]\ttrain's auc: 0.831345\ttrain's binary_logloss: 0.333161\n",
      "[249]\ttrain's auc: 0.831375\ttrain's binary_logloss: 0.333138\n",
      "[250]\ttrain's auc: 0.831403\ttrain's binary_logloss: 0.333121\n",
      "[251]\ttrain's auc: 0.831407\ttrain's binary_logloss: 0.333117\n",
      "[252]\ttrain's auc: 0.831423\ttrain's binary_logloss: 0.333108\n",
      "[253]\ttrain's auc: 0.831454\ttrain's binary_logloss: 0.333087\n",
      "[254]\ttrain's auc: 0.831475\ttrain's binary_logloss: 0.333072\n",
      "[255]\ttrain's auc: 0.831494\ttrain's binary_logloss: 0.333053\n",
      "[256]\ttrain's auc: 0.831506\ttrain's binary_logloss: 0.333042\n",
      "[257]\ttrain's auc: 0.831511\ttrain's binary_logloss: 0.333039\n",
      "[258]\ttrain's auc: 0.831519\ttrain's binary_logloss: 0.333035\n",
      "[259]\ttrain's auc: 0.831535\ttrain's binary_logloss: 0.333022\n",
      "[260]\ttrain's auc: 0.831545\ttrain's binary_logloss: 0.333015\n",
      "[261]\ttrain's auc: 0.831556\ttrain's binary_logloss: 0.333008\n",
      "[262]\ttrain's auc: 0.83157\ttrain's binary_logloss: 0.332995\n",
      "[263]\ttrain's auc: 0.83157\ttrain's binary_logloss: 0.332995\n",
      "[264]\ttrain's auc: 0.831587\ttrain's binary_logloss: 0.332984\n",
      "[265]\ttrain's auc: 0.831594\ttrain's binary_logloss: 0.332978\n",
      "[266]\ttrain's auc: 0.83164\ttrain's binary_logloss: 0.33294\n",
      "[267]\ttrain's auc: 0.831669\ttrain's binary_logloss: 0.332915\n",
      "[268]\ttrain's auc: 0.831695\ttrain's binary_logloss: 0.332894\n",
      "[269]\ttrain's auc: 0.831704\ttrain's binary_logloss: 0.332887\n",
      "[270]\ttrain's auc: 0.831722\ttrain's binary_logloss: 0.332874\n",
      "[271]\ttrain's auc: 0.831736\ttrain's binary_logloss: 0.332866\n",
      "[272]\ttrain's auc: 0.831747\ttrain's binary_logloss: 0.332857\n",
      "[273]\ttrain's auc: 0.831784\ttrain's binary_logloss: 0.332829\n",
      "[274]\ttrain's auc: 0.831792\ttrain's binary_logloss: 0.33282\n",
      "[275]\ttrain's auc: 0.831803\ttrain's binary_logloss: 0.332812\n",
      "[276]\ttrain's auc: 0.831843\ttrain's binary_logloss: 0.332782\n",
      "[277]\ttrain's auc: 0.831861\ttrain's binary_logloss: 0.332768\n",
      "[278]\ttrain's auc: 0.831878\ttrain's binary_logloss: 0.332751\n",
      "[279]\ttrain's auc: 0.831887\ttrain's binary_logloss: 0.332747\n",
      "[280]\ttrain's auc: 0.831905\ttrain's binary_logloss: 0.332734\n",
      "[281]\ttrain's auc: 0.831915\ttrain's binary_logloss: 0.332724\n",
      "[282]\ttrain's auc: 0.831922\ttrain's binary_logloss: 0.332712\n",
      "[283]\ttrain's auc: 0.831945\ttrain's binary_logloss: 0.3327\n",
      "[284]\ttrain's auc: 0.831959\ttrain's binary_logloss: 0.332687\n",
      "[285]\ttrain's auc: 0.831973\ttrain's binary_logloss: 0.332676\n",
      "[286]\ttrain's auc: 0.83202\ttrain's binary_logloss: 0.332614\n",
      "[287]\ttrain's auc: 0.832023\ttrain's binary_logloss: 0.33261\n",
      "[288]\ttrain's auc: 0.832058\ttrain's binary_logloss: 0.332575\n",
      "[289]\ttrain's auc: 0.832094\ttrain's binary_logloss: 0.332548\n",
      "[290]\ttrain's auc: 0.832118\ttrain's binary_logloss: 0.332528\n",
      "[291]\ttrain's auc: 0.832124\ttrain's binary_logloss: 0.332523\n",
      "[292]\ttrain's auc: 0.832143\ttrain's binary_logloss: 0.332506\n",
      "[293]\ttrain's auc: 0.832179\ttrain's binary_logloss: 0.332471\n",
      "[294]\ttrain's auc: 0.832182\ttrain's binary_logloss: 0.332468\n",
      "[295]\ttrain's auc: 0.832193\ttrain's binary_logloss: 0.332459\n",
      "[296]\ttrain's auc: 0.832198\ttrain's binary_logloss: 0.332455\n",
      "[297]\ttrain's auc: 0.832209\ttrain's binary_logloss: 0.332447\n",
      "[298]\ttrain's auc: 0.83223\ttrain's binary_logloss: 0.332436\n",
      "[299]\ttrain's auc: 0.832232\ttrain's binary_logloss: 0.332434\n",
      "[300]\ttrain's auc: 0.832243\ttrain's binary_logloss: 0.332426\n",
      "[301]\ttrain's auc: 0.832254\ttrain's binary_logloss: 0.332418\n",
      "[302]\ttrain's auc: 0.832266\ttrain's binary_logloss: 0.332408\n",
      "[303]\ttrain's auc: 0.832282\ttrain's binary_logloss: 0.332396\n",
      "[304]\ttrain's auc: 0.832299\ttrain's binary_logloss: 0.332384\n",
      "[305]\ttrain's auc: 0.832333\ttrain's binary_logloss: 0.332349\n",
      "[306]\ttrain's auc: 0.832362\ttrain's binary_logloss: 0.332315\n",
      "[307]\ttrain's auc: 0.832376\ttrain's binary_logloss: 0.332305\n",
      "[308]\ttrain's auc: 0.832384\ttrain's binary_logloss: 0.332297\n",
      "[309]\ttrain's auc: 0.832388\ttrain's binary_logloss: 0.332291\n",
      "[310]\ttrain's auc: 0.832422\ttrain's binary_logloss: 0.332265\n",
      "[311]\ttrain's auc: 0.832439\ttrain's binary_logloss: 0.332251\n",
      "[312]\ttrain's auc: 0.832451\ttrain's binary_logloss: 0.33224\n",
      "[313]\ttrain's auc: 0.832464\ttrain's binary_logloss: 0.332228\n",
      "[314]\ttrain's auc: 0.83248\ttrain's binary_logloss: 0.332218\n",
      "[315]\ttrain's auc: 0.832482\ttrain's binary_logloss: 0.332217\n",
      "[316]\ttrain's auc: 0.832488\ttrain's binary_logloss: 0.33221\n",
      "[317]\ttrain's auc: 0.8325\ttrain's binary_logloss: 0.332201\n",
      "[318]\ttrain's auc: 0.832504\ttrain's binary_logloss: 0.332198\n",
      "[319]\ttrain's auc: 0.832516\ttrain's binary_logloss: 0.332183\n",
      "[320]\ttrain's auc: 0.832524\ttrain's binary_logloss: 0.332173\n",
      "[321]\ttrain's auc: 0.832542\ttrain's binary_logloss: 0.33216\n",
      "[322]\ttrain's auc: 0.832543\ttrain's binary_logloss: 0.332156\n",
      "[323]\ttrain's auc: 0.832571\ttrain's binary_logloss: 0.332137\n",
      "[324]\ttrain's auc: 0.832624\ttrain's binary_logloss: 0.332097\n",
      "[325]\ttrain's auc: 0.832632\ttrain's binary_logloss: 0.33209\n",
      "[326]\ttrain's auc: 0.832656\ttrain's binary_logloss: 0.332047\n",
      "[327]\ttrain's auc: 0.832682\ttrain's binary_logloss: 0.332018\n",
      "[328]\ttrain's auc: 0.832693\ttrain's binary_logloss: 0.332009\n",
      "[329]\ttrain's auc: 0.832719\ttrain's binary_logloss: 0.331987\n",
      "[330]\ttrain's auc: 0.832737\ttrain's binary_logloss: 0.331975\n",
      "[331]\ttrain's auc: 0.832752\ttrain's binary_logloss: 0.331965\n",
      "[332]\ttrain's auc: 0.832776\ttrain's binary_logloss: 0.331947\n",
      "[333]\ttrain's auc: 0.832789\ttrain's binary_logloss: 0.331936\n",
      "[334]\ttrain's auc: 0.832819\ttrain's binary_logloss: 0.331909\n",
      "[335]\ttrain's auc: 0.83285\ttrain's binary_logloss: 0.331889\n",
      "[336]\ttrain's auc: 0.832861\ttrain's binary_logloss: 0.331881\n",
      "[337]\ttrain's auc: 0.832868\ttrain's binary_logloss: 0.331876\n",
      "[338]\ttrain's auc: 0.832875\ttrain's binary_logloss: 0.331869\n",
      "[339]\ttrain's auc: 0.832881\ttrain's binary_logloss: 0.331863\n",
      "[340]\ttrain's auc: 0.832887\ttrain's binary_logloss: 0.331859\n",
      "[341]\ttrain's auc: 0.832888\ttrain's binary_logloss: 0.331858\n",
      "[342]\ttrain's auc: 0.832899\ttrain's binary_logloss: 0.331848\n",
      "[343]\ttrain's auc: 0.832906\ttrain's binary_logloss: 0.331843\n",
      "[344]\ttrain's auc: 0.832937\ttrain's binary_logloss: 0.331815\n",
      "[345]\ttrain's auc: 0.832952\ttrain's binary_logloss: 0.331799\n",
      "[346]\ttrain's auc: 0.832957\ttrain's binary_logloss: 0.331793\n",
      "[347]\ttrain's auc: 0.832984\ttrain's binary_logloss: 0.331769\n",
      "[348]\ttrain's auc: 0.833001\ttrain's binary_logloss: 0.331755\n",
      "[349]\ttrain's auc: 0.833019\ttrain's binary_logloss: 0.331741\n",
      "[350]\ttrain's auc: 0.833088\ttrain's binary_logloss: 0.331665\n",
      "[351]\ttrain's auc: 0.833092\ttrain's binary_logloss: 0.331662\n",
      "[352]\ttrain's auc: 0.833103\ttrain's binary_logloss: 0.331655\n",
      "[353]\ttrain's auc: 0.833104\ttrain's binary_logloss: 0.331653\n",
      "[354]\ttrain's auc: 0.833118\ttrain's binary_logloss: 0.331642\n",
      "[355]\ttrain's auc: 0.83313\ttrain's binary_logloss: 0.33163\n",
      "[356]\ttrain's auc: 0.833142\ttrain's binary_logloss: 0.331621\n",
      "[357]\ttrain's auc: 0.83315\ttrain's binary_logloss: 0.331614\n",
      "[358]\ttrain's auc: 0.833158\ttrain's binary_logloss: 0.331608\n",
      "[359]\ttrain's auc: 0.833163\ttrain's binary_logloss: 0.331603\n",
      "[360]\ttrain's auc: 0.833169\ttrain's binary_logloss: 0.331598\n",
      "[361]\ttrain's auc: 0.83319\ttrain's binary_logloss: 0.331585\n",
      "[362]\ttrain's auc: 0.833203\ttrain's binary_logloss: 0.331574\n",
      "[363]\ttrain's auc: 0.833229\ttrain's binary_logloss: 0.331552\n",
      "[364]\ttrain's auc: 0.833235\ttrain's binary_logloss: 0.331548\n",
      "[365]\ttrain's auc: 0.833245\ttrain's binary_logloss: 0.331541\n",
      "[366]\ttrain's auc: 0.83327\ttrain's binary_logloss: 0.331522\n",
      "[367]\ttrain's auc: 0.833284\ttrain's binary_logloss: 0.331512\n",
      "[368]\ttrain's auc: 0.833293\ttrain's binary_logloss: 0.331502\n",
      "[369]\ttrain's auc: 0.833321\ttrain's binary_logloss: 0.331484\n",
      "[370]\ttrain's auc: 0.833329\ttrain's binary_logloss: 0.331478\n",
      "[371]\ttrain's auc: 0.83333\ttrain's binary_logloss: 0.331478\n",
      "[372]\ttrain's auc: 0.83335\ttrain's binary_logloss: 0.331461\n",
      "[373]\ttrain's auc: 0.833393\ttrain's binary_logloss: 0.331424\n",
      "[374]\ttrain's auc: 0.833407\ttrain's binary_logloss: 0.33141\n",
      "[375]\ttrain's auc: 0.833413\ttrain's binary_logloss: 0.331406\n",
      "[376]\ttrain's auc: 0.833431\ttrain's binary_logloss: 0.331394\n",
      "[377]\ttrain's auc: 0.833439\ttrain's binary_logloss: 0.331388\n",
      "[378]\ttrain's auc: 0.83346\ttrain's binary_logloss: 0.33137\n",
      "[379]\ttrain's auc: 0.833492\ttrain's binary_logloss: 0.33135\n",
      "[380]\ttrain's auc: 0.833534\ttrain's binary_logloss: 0.331307\n",
      "[381]\ttrain's auc: 0.833541\ttrain's binary_logloss: 0.331302\n",
      "[382]\ttrain's auc: 0.833549\ttrain's binary_logloss: 0.331295\n",
      "[383]\ttrain's auc: 0.83356\ttrain's binary_logloss: 0.331286\n",
      "[384]\ttrain's auc: 0.833603\ttrain's binary_logloss: 0.331236\n",
      "[385]\ttrain's auc: 0.833628\ttrain's binary_logloss: 0.331216\n",
      "[386]\ttrain's auc: 0.833635\ttrain's binary_logloss: 0.33121\n",
      "[387]\ttrain's auc: 0.833652\ttrain's binary_logloss: 0.331197\n",
      "[388]\ttrain's auc: 0.833653\ttrain's binary_logloss: 0.331195\n",
      "[389]\ttrain's auc: 0.83366\ttrain's binary_logloss: 0.331189\n",
      "[390]\ttrain's auc: 0.833662\ttrain's binary_logloss: 0.331187\n",
      "[391]\ttrain's auc: 0.833675\ttrain's binary_logloss: 0.331177\n",
      "[392]\ttrain's auc: 0.833686\ttrain's binary_logloss: 0.331169\n",
      "[393]\ttrain's auc: 0.833692\ttrain's binary_logloss: 0.331164\n",
      "[394]\ttrain's auc: 0.833711\ttrain's binary_logloss: 0.331127\n",
      "[395]\ttrain's auc: 0.833728\ttrain's binary_logloss: 0.331114\n",
      "[396]\ttrain's auc: 0.833741\ttrain's binary_logloss: 0.331105\n",
      "[397]\ttrain's auc: 0.833755\ttrain's binary_logloss: 0.331093\n",
      "[398]\ttrain's auc: 0.833765\ttrain's binary_logloss: 0.331084\n",
      "[399]\ttrain's auc: 0.833778\ttrain's binary_logloss: 0.331073\n",
      "[400]\ttrain's auc: 0.833785\ttrain's binary_logloss: 0.331068\n",
      "[401]\ttrain's auc: 0.833799\ttrain's binary_logloss: 0.331055\n",
      "[402]\ttrain's auc: 0.83381\ttrain's binary_logloss: 0.331048\n",
      "[403]\ttrain's auc: 0.833832\ttrain's binary_logloss: 0.331026\n",
      "[404]\ttrain's auc: 0.833843\ttrain's binary_logloss: 0.331017\n",
      "[405]\ttrain's auc: 0.833846\ttrain's binary_logloss: 0.331016\n",
      "[406]\ttrain's auc: 0.833856\ttrain's binary_logloss: 0.331009\n",
      "[407]\ttrain's auc: 0.833873\ttrain's binary_logloss: 0.330996\n",
      "[408]\ttrain's auc: 0.833881\ttrain's binary_logloss: 0.330989\n",
      "[409]\ttrain's auc: 0.833892\ttrain's binary_logloss: 0.330979\n",
      "[410]\ttrain's auc: 0.833899\ttrain's binary_logloss: 0.330974\n",
      "[411]\ttrain's auc: 0.833901\ttrain's binary_logloss: 0.330972\n",
      "[412]\ttrain's auc: 0.833909\ttrain's binary_logloss: 0.330964\n",
      "[413]\ttrain's auc: 0.833925\ttrain's binary_logloss: 0.330955\n",
      "[414]\ttrain's auc: 0.833937\ttrain's binary_logloss: 0.330946\n",
      "[415]\ttrain's auc: 0.833972\ttrain's binary_logloss: 0.330924\n",
      "[416]\ttrain's auc: 0.833994\ttrain's binary_logloss: 0.330884\n",
      "[417]\ttrain's auc: 0.834005\ttrain's binary_logloss: 0.330877\n",
      "[418]\ttrain's auc: 0.834009\ttrain's binary_logloss: 0.330874\n",
      "[419]\ttrain's auc: 0.83401\ttrain's binary_logloss: 0.330871\n",
      "[420]\ttrain's auc: 0.834015\ttrain's binary_logloss: 0.330868\n",
      "[421]\ttrain's auc: 0.834042\ttrain's binary_logloss: 0.330847\n",
      "[422]\ttrain's auc: 0.834061\ttrain's binary_logloss: 0.330832\n",
      "[423]\ttrain's auc: 0.834077\ttrain's binary_logloss: 0.330819\n",
      "[424]\ttrain's auc: 0.834095\ttrain's binary_logloss: 0.330802\n",
      "[425]\ttrain's auc: 0.834115\ttrain's binary_logloss: 0.330786\n",
      "[426]\ttrain's auc: 0.834124\ttrain's binary_logloss: 0.330781\n",
      "[427]\ttrain's auc: 0.83413\ttrain's binary_logloss: 0.330777\n",
      "[428]\ttrain's auc: 0.834141\ttrain's binary_logloss: 0.330769\n",
      "[429]\ttrain's auc: 0.834173\ttrain's binary_logloss: 0.330727\n",
      "[430]\ttrain's auc: 0.834197\ttrain's binary_logloss: 0.33071\n",
      "[431]\ttrain's auc: 0.834208\ttrain's binary_logloss: 0.3307\n",
      "[432]\ttrain's auc: 0.834234\ttrain's binary_logloss: 0.330677\n",
      "[433]\ttrain's auc: 0.834255\ttrain's binary_logloss: 0.330658\n",
      "[434]\ttrain's auc: 0.834258\ttrain's binary_logloss: 0.330654\n",
      "[435]\ttrain's auc: 0.834264\ttrain's binary_logloss: 0.330649\n",
      "[436]\ttrain's auc: 0.834295\ttrain's binary_logloss: 0.330608\n",
      "[437]\ttrain's auc: 0.834306\ttrain's binary_logloss: 0.330599\n",
      "[438]\ttrain's auc: 0.834324\ttrain's binary_logloss: 0.330584\n",
      "[439]\ttrain's auc: 0.834329\ttrain's binary_logloss: 0.33058\n",
      "[440]\ttrain's auc: 0.834335\ttrain's binary_logloss: 0.330576\n",
      "[441]\ttrain's auc: 0.834355\ttrain's binary_logloss: 0.330563\n",
      "[442]\ttrain's auc: 0.834358\ttrain's binary_logloss: 0.330562\n",
      "[443]\ttrain's auc: 0.834378\ttrain's binary_logloss: 0.330548\n",
      "[444]\ttrain's auc: 0.834389\ttrain's binary_logloss: 0.33054\n",
      "[445]\ttrain's auc: 0.834388\ttrain's binary_logloss: 0.330541\n",
      "[446]\ttrain's auc: 0.83439\ttrain's binary_logloss: 0.33054\n",
      "[447]\ttrain's auc: 0.83439\ttrain's binary_logloss: 0.33054\n",
      "[448]\ttrain's auc: 0.834397\ttrain's binary_logloss: 0.330535\n",
      "[449]\ttrain's auc: 0.834408\ttrain's binary_logloss: 0.330527\n",
      "[450]\ttrain's auc: 0.834441\ttrain's binary_logloss: 0.330504\n",
      "[451]\ttrain's auc: 0.834456\ttrain's binary_logloss: 0.330493\n",
      "[452]\ttrain's auc: 0.834474\ttrain's binary_logloss: 0.330476\n",
      "[453]\ttrain's auc: 0.834483\ttrain's binary_logloss: 0.330469\n",
      "[454]\ttrain's auc: 0.834492\ttrain's binary_logloss: 0.330463\n",
      "[455]\ttrain's auc: 0.834502\ttrain's binary_logloss: 0.330455\n",
      "[456]\ttrain's auc: 0.834503\ttrain's binary_logloss: 0.330454\n",
      "[457]\ttrain's auc: 0.834505\ttrain's binary_logloss: 0.330451\n",
      "[458]\ttrain's auc: 0.834514\ttrain's binary_logloss: 0.330445\n",
      "[459]\ttrain's auc: 0.834545\ttrain's binary_logloss: 0.330413\n",
      "[460]\ttrain's auc: 0.834556\ttrain's binary_logloss: 0.330406\n",
      "[461]\ttrain's auc: 0.834585\ttrain's binary_logloss: 0.33038\n",
      "[462]\ttrain's auc: 0.834588\ttrain's binary_logloss: 0.330377\n",
      "[463]\ttrain's auc: 0.834601\ttrain's binary_logloss: 0.330364\n",
      "[464]\ttrain's auc: 0.83462\ttrain's binary_logloss: 0.330346\n",
      "[465]\ttrain's auc: 0.83463\ttrain's binary_logloss: 0.330322\n",
      "[466]\ttrain's auc: 0.834635\ttrain's binary_logloss: 0.330319\n",
      "[467]\ttrain's auc: 0.834645\ttrain's binary_logloss: 0.330312\n",
      "[468]\ttrain's auc: 0.834651\ttrain's binary_logloss: 0.330307\n",
      "[469]\ttrain's auc: 0.834661\ttrain's binary_logloss: 0.330298\n",
      "[470]\ttrain's auc: 0.834673\ttrain's binary_logloss: 0.330289\n",
      "[471]\ttrain's auc: 0.83468\ttrain's binary_logloss: 0.330282\n",
      "[472]\ttrain's auc: 0.834686\ttrain's binary_logloss: 0.330276\n",
      "[473]\ttrain's auc: 0.834691\ttrain's binary_logloss: 0.330273\n",
      "[474]\ttrain's auc: 0.834707\ttrain's binary_logloss: 0.330258\n",
      "[475]\ttrain's auc: 0.834722\ttrain's binary_logloss: 0.330244\n",
      "[476]\ttrain's auc: 0.834726\ttrain's binary_logloss: 0.33024\n",
      "[477]\ttrain's auc: 0.834735\ttrain's binary_logloss: 0.330233\n",
      "[478]\ttrain's auc: 0.834747\ttrain's binary_logloss: 0.330224\n",
      "[479]\ttrain's auc: 0.834756\ttrain's binary_logloss: 0.330217\n",
      "[480]\ttrain's auc: 0.83479\ttrain's binary_logloss: 0.330184\n",
      "[481]\ttrain's auc: 0.834796\ttrain's binary_logloss: 0.330181\n",
      "[482]\ttrain's auc: 0.834828\ttrain's binary_logloss: 0.330158\n",
      "[483]\ttrain's auc: 0.834851\ttrain's binary_logloss: 0.330137\n",
      "[484]\ttrain's auc: 0.834872\ttrain's binary_logloss: 0.330122\n",
      "[485]\ttrain's auc: 0.834868\ttrain's binary_logloss: 0.330124\n",
      "[486]\ttrain's auc: 0.834873\ttrain's binary_logloss: 0.33012\n",
      "[487]\ttrain's auc: 0.834871\ttrain's binary_logloss: 0.330119\n",
      "[488]\ttrain's auc: 0.834891\ttrain's binary_logloss: 0.330104\n",
      "[489]\ttrain's auc: 0.834903\ttrain's binary_logloss: 0.330093\n",
      "[490]\ttrain's auc: 0.834912\ttrain's binary_logloss: 0.330083\n",
      "[491]\ttrain's auc: 0.834923\ttrain's binary_logloss: 0.330074\n",
      "[492]\ttrain's auc: 0.834922\ttrain's binary_logloss: 0.330074\n",
      "[493]\ttrain's auc: 0.834944\ttrain's binary_logloss: 0.330057\n",
      "[494]\ttrain's auc: 0.834952\ttrain's binary_logloss: 0.33005\n",
      "[495]\ttrain's auc: 0.834974\ttrain's binary_logloss: 0.330032\n",
      "[496]\ttrain's auc: 0.834974\ttrain's binary_logloss: 0.330032\n",
      "[497]\ttrain's auc: 0.834986\ttrain's binary_logloss: 0.330022\n",
      "[498]\ttrain's auc: 0.834997\ttrain's binary_logloss: 0.330015\n",
      "[499]\ttrain's auc: 0.835005\ttrain's binary_logloss: 0.330009\n",
      "[500]\ttrain's auc: 0.835016\ttrain's binary_logloss: 0.330002\n",
      "[501]\ttrain's auc: 0.835023\ttrain's binary_logloss: 0.329995\n",
      "[502]\ttrain's auc: 0.835033\ttrain's binary_logloss: 0.329986\n",
      "[503]\ttrain's auc: 0.835044\ttrain's binary_logloss: 0.329979\n",
      "[504]\ttrain's auc: 0.835056\ttrain's binary_logloss: 0.329971\n",
      "[505]\ttrain's auc: 0.835056\ttrain's binary_logloss: 0.32997\n",
      "[506]\ttrain's auc: 0.835063\ttrain's binary_logloss: 0.329965\n",
      "[507]\ttrain's auc: 0.835068\ttrain's binary_logloss: 0.329962\n",
      "[508]\ttrain's auc: 0.83507\ttrain's binary_logloss: 0.329961\n",
      "[509]\ttrain's auc: 0.83509\ttrain's binary_logloss: 0.329946\n",
      "[510]\ttrain's auc: 0.835103\ttrain's binary_logloss: 0.329937\n",
      "[511]\ttrain's auc: 0.835109\ttrain's binary_logloss: 0.329932\n",
      "[512]\ttrain's auc: 0.835116\ttrain's binary_logloss: 0.329926\n",
      "[513]\ttrain's auc: 0.835115\ttrain's binary_logloss: 0.329926\n",
      "[514]\ttrain's auc: 0.835135\ttrain's binary_logloss: 0.32991\n",
      "[515]\ttrain's auc: 0.835185\ttrain's binary_logloss: 0.32987\n",
      "[516]\ttrain's auc: 0.835193\ttrain's binary_logloss: 0.329864\n",
      "[517]\ttrain's auc: 0.835206\ttrain's binary_logloss: 0.329854\n",
      "[518]\ttrain's auc: 0.83521\ttrain's binary_logloss: 0.329851\n",
      "[519]\ttrain's auc: 0.835229\ttrain's binary_logloss: 0.329833\n",
      "[520]\ttrain's auc: 0.835231\ttrain's binary_logloss: 0.329831\n",
      "[521]\ttrain's auc: 0.835233\ttrain's binary_logloss: 0.329829\n",
      "[522]\ttrain's auc: 0.835252\ttrain's binary_logloss: 0.329817\n",
      "[523]\ttrain's auc: 0.835254\ttrain's binary_logloss: 0.329815\n",
      "[524]\ttrain's auc: 0.835257\ttrain's binary_logloss: 0.329812\n",
      "[525]\ttrain's auc: 0.835261\ttrain's binary_logloss: 0.32981\n",
      "[526]\ttrain's auc: 0.835263\ttrain's binary_logloss: 0.329809\n",
      "[527]\ttrain's auc: 0.835267\ttrain's binary_logloss: 0.329807\n",
      "[528]\ttrain's auc: 0.835273\ttrain's binary_logloss: 0.3298\n",
      "[529]\ttrain's auc: 0.835282\ttrain's binary_logloss: 0.329794\n",
      "[530]\ttrain's auc: 0.835299\ttrain's binary_logloss: 0.329777\n",
      "[531]\ttrain's auc: 0.835307\ttrain's binary_logloss: 0.329769\n",
      "[532]\ttrain's auc: 0.835311\ttrain's binary_logloss: 0.329764\n",
      "[533]\ttrain's auc: 0.835324\ttrain's binary_logloss: 0.329754\n",
      "[534]\ttrain's auc: 0.835328\ttrain's binary_logloss: 0.329752\n",
      "[535]\ttrain's auc: 0.835334\ttrain's binary_logloss: 0.329744\n",
      "[536]\ttrain's auc: 0.835369\ttrain's binary_logloss: 0.329709\n",
      "[537]\ttrain's auc: 0.835367\ttrain's binary_logloss: 0.329708\n",
      "[538]\ttrain's auc: 0.835377\ttrain's binary_logloss: 0.329701\n",
      "[539]\ttrain's auc: 0.835383\ttrain's binary_logloss: 0.329697\n",
      "[540]\ttrain's auc: 0.835387\ttrain's binary_logloss: 0.329692\n",
      "[541]\ttrain's auc: 0.835401\ttrain's binary_logloss: 0.329682\n",
      "[542]\ttrain's auc: 0.835409\ttrain's binary_logloss: 0.329676\n",
      "[543]\ttrain's auc: 0.835427\ttrain's binary_logloss: 0.329661\n",
      "[544]\ttrain's auc: 0.835431\ttrain's binary_logloss: 0.329658\n",
      "[545]\ttrain's auc: 0.835447\ttrain's binary_logloss: 0.329644\n",
      "[546]\ttrain's auc: 0.835459\ttrain's binary_logloss: 0.329634\n",
      "[547]\ttrain's auc: 0.835466\ttrain's binary_logloss: 0.329629\n",
      "[548]\ttrain's auc: 0.835474\ttrain's binary_logloss: 0.329625\n",
      "[549]\ttrain's auc: 0.835482\ttrain's binary_logloss: 0.329618\n",
      "[550]\ttrain's auc: 0.835505\ttrain's binary_logloss: 0.329591\n",
      "[551]\ttrain's auc: 0.835513\ttrain's binary_logloss: 0.329584\n",
      "[552]\ttrain's auc: 0.83552\ttrain's binary_logloss: 0.32958\n",
      "[553]\ttrain's auc: 0.83552\ttrain's binary_logloss: 0.329577\n",
      "[554]\ttrain's auc: 0.835521\ttrain's binary_logloss: 0.329576\n",
      "[555]\ttrain's auc: 0.835531\ttrain's binary_logloss: 0.329561\n",
      "[556]\ttrain's auc: 0.835539\ttrain's binary_logloss: 0.329553\n",
      "[557]\ttrain's auc: 0.835553\ttrain's binary_logloss: 0.329542\n",
      "[558]\ttrain's auc: 0.835557\ttrain's binary_logloss: 0.32954\n",
      "[559]\ttrain's auc: 0.835562\ttrain's binary_logloss: 0.329534\n",
      "[560]\ttrain's auc: 0.835572\ttrain's binary_logloss: 0.329525\n",
      "[561]\ttrain's auc: 0.835569\ttrain's binary_logloss: 0.329529\n",
      "[562]\ttrain's auc: 0.835584\ttrain's binary_logloss: 0.32952\n",
      "[563]\ttrain's auc: 0.835597\ttrain's binary_logloss: 0.329508\n",
      "[564]\ttrain's auc: 0.835601\ttrain's binary_logloss: 0.329504\n",
      "[565]\ttrain's auc: 0.83562\ttrain's binary_logloss: 0.329489\n",
      "[566]\ttrain's auc: 0.835629\ttrain's binary_logloss: 0.329483\n",
      "[567]\ttrain's auc: 0.835633\ttrain's binary_logloss: 0.329479\n",
      "[568]\ttrain's auc: 0.83565\ttrain's binary_logloss: 0.329466\n",
      "[569]\ttrain's auc: 0.835653\ttrain's binary_logloss: 0.329463\n",
      "[570]\ttrain's auc: 0.835669\ttrain's binary_logloss: 0.329454\n",
      "[571]\ttrain's auc: 0.835679\ttrain's binary_logloss: 0.329446\n",
      "[572]\ttrain's auc: 0.835684\ttrain's binary_logloss: 0.329441\n",
      "[573]\ttrain's auc: 0.835695\ttrain's binary_logloss: 0.329431\n",
      "[574]\ttrain's auc: 0.835704\ttrain's binary_logloss: 0.329422\n",
      "[575]\ttrain's auc: 0.835709\ttrain's binary_logloss: 0.329418\n",
      "[576]\ttrain's auc: 0.835714\ttrain's binary_logloss: 0.329414\n",
      "[577]\ttrain's auc: 0.835713\ttrain's binary_logloss: 0.329414\n",
      "[578]\ttrain's auc: 0.835718\ttrain's binary_logloss: 0.329408\n",
      "[579]\ttrain's auc: 0.835745\ttrain's binary_logloss: 0.329383\n",
      "[580]\ttrain's auc: 0.835747\ttrain's binary_logloss: 0.32938\n",
      "[581]\ttrain's auc: 0.835754\ttrain's binary_logloss: 0.329374\n",
      "[582]\ttrain's auc: 0.835769\ttrain's binary_logloss: 0.329358\n",
      "[583]\ttrain's auc: 0.83577\ttrain's binary_logloss: 0.329357\n",
      "[584]\ttrain's auc: 0.835791\ttrain's binary_logloss: 0.329338\n",
      "[585]\ttrain's auc: 0.835798\ttrain's binary_logloss: 0.329333\n",
      "[586]\ttrain's auc: 0.835812\ttrain's binary_logloss: 0.329324\n",
      "[587]\ttrain's auc: 0.83582\ttrain's binary_logloss: 0.329319\n",
      "[588]\ttrain's auc: 0.835822\ttrain's binary_logloss: 0.329317\n",
      "[589]\ttrain's auc: 0.835822\ttrain's binary_logloss: 0.329316\n",
      "[590]\ttrain's auc: 0.835825\ttrain's binary_logloss: 0.329313\n",
      "[591]\ttrain's auc: 0.835832\ttrain's binary_logloss: 0.329307\n",
      "[592]\ttrain's auc: 0.835838\ttrain's binary_logloss: 0.329304\n",
      "[593]\ttrain's auc: 0.835839\ttrain's binary_logloss: 0.329303\n",
      "[594]\ttrain's auc: 0.835836\ttrain's binary_logloss: 0.329305\n",
      "[595]\ttrain's auc: 0.835838\ttrain's binary_logloss: 0.329304\n",
      "[596]\ttrain's auc: 0.835849\ttrain's binary_logloss: 0.329287\n",
      "[597]\ttrain's auc: 0.835869\ttrain's binary_logloss: 0.329273\n",
      "[598]\ttrain's auc: 0.835891\ttrain's binary_logloss: 0.329255\n",
      "[599]\ttrain's auc: 0.835907\ttrain's binary_logloss: 0.329245\n",
      "[600]\ttrain's auc: 0.835919\ttrain's binary_logloss: 0.329234\n",
      "[601]\ttrain's auc: 0.835921\ttrain's binary_logloss: 0.329232\n",
      "[602]\ttrain's auc: 0.835926\ttrain's binary_logloss: 0.329228\n",
      "[603]\ttrain's auc: 0.835941\ttrain's binary_logloss: 0.329218\n",
      "[604]\ttrain's auc: 0.835942\ttrain's binary_logloss: 0.329216\n",
      "[605]\ttrain's auc: 0.835943\ttrain's binary_logloss: 0.329214\n",
      "[606]\ttrain's auc: 0.83598\ttrain's binary_logloss: 0.329178\n",
      "[607]\ttrain's auc: 0.835994\ttrain's binary_logloss: 0.329168\n",
      "[608]\ttrain's auc: 0.835993\ttrain's binary_logloss: 0.329168\n",
      "[609]\ttrain's auc: 0.836\ttrain's binary_logloss: 0.329159\n",
      "[610]\ttrain's auc: 0.836005\ttrain's binary_logloss: 0.329155\n",
      "[611]\ttrain's auc: 0.836003\ttrain's binary_logloss: 0.329156\n",
      "[612]\ttrain's auc: 0.836005\ttrain's binary_logloss: 0.329155\n",
      "[613]\ttrain's auc: 0.836003\ttrain's binary_logloss: 0.329156\n",
      "[614]\ttrain's auc: 0.836011\ttrain's binary_logloss: 0.329151\n",
      "[615]\ttrain's auc: 0.836017\ttrain's binary_logloss: 0.329144\n",
      "[616]\ttrain's auc: 0.836023\ttrain's binary_logloss: 0.329137\n",
      "[617]\ttrain's auc: 0.836041\ttrain's binary_logloss: 0.329122\n",
      "[618]\ttrain's auc: 0.836069\ttrain's binary_logloss: 0.329096\n",
      "[619]\ttrain's auc: 0.836081\ttrain's binary_logloss: 0.329087\n",
      "[620]\ttrain's auc: 0.836081\ttrain's binary_logloss: 0.329087\n",
      "[621]\ttrain's auc: 0.836089\ttrain's binary_logloss: 0.329081\n",
      "[622]\ttrain's auc: 0.83609\ttrain's binary_logloss: 0.32908\n",
      "[623]\ttrain's auc: 0.836091\ttrain's binary_logloss: 0.329079\n",
      "[624]\ttrain's auc: 0.83611\ttrain's binary_logloss: 0.329057\n",
      "[625]\ttrain's auc: 0.83611\ttrain's binary_logloss: 0.329056\n",
      "[626]\ttrain's auc: 0.836135\ttrain's binary_logloss: 0.329037\n",
      "[627]\ttrain's auc: 0.836143\ttrain's binary_logloss: 0.329031\n",
      "[628]\ttrain's auc: 0.836167\ttrain's binary_logloss: 0.329009\n",
      "[629]\ttrain's auc: 0.836179\ttrain's binary_logloss: 0.329\n",
      "[630]\ttrain's auc: 0.836183\ttrain's binary_logloss: 0.328997\n",
      "[631]\ttrain's auc: 0.8362\ttrain's binary_logloss: 0.328985\n",
      "[632]\ttrain's auc: 0.836202\ttrain's binary_logloss: 0.328983\n",
      "[633]\ttrain's auc: 0.836211\ttrain's binary_logloss: 0.328976\n",
      "[634]\ttrain's auc: 0.836208\ttrain's binary_logloss: 0.328978\n",
      "[635]\ttrain's auc: 0.836208\ttrain's binary_logloss: 0.328977\n",
      "[636]\ttrain's auc: 0.836209\ttrain's binary_logloss: 0.328975\n",
      "[637]\ttrain's auc: 0.836209\ttrain's binary_logloss: 0.328974\n",
      "[638]\ttrain's auc: 0.836214\ttrain's binary_logloss: 0.32897\n",
      "[639]\ttrain's auc: 0.836225\ttrain's binary_logloss: 0.328962\n",
      "[640]\ttrain's auc: 0.836227\ttrain's binary_logloss: 0.328961\n",
      "[641]\ttrain's auc: 0.836229\ttrain's binary_logloss: 0.32896\n",
      "[642]\ttrain's auc: 0.83623\ttrain's binary_logloss: 0.32896\n",
      "[643]\ttrain's auc: 0.836236\ttrain's binary_logloss: 0.328956\n",
      "[644]\ttrain's auc: 0.836245\ttrain's binary_logloss: 0.32895\n",
      "[645]\ttrain's auc: 0.836261\ttrain's binary_logloss: 0.328938\n",
      "[646]\ttrain's auc: 0.836294\ttrain's binary_logloss: 0.328914\n",
      "[647]\ttrain's auc: 0.836321\ttrain's binary_logloss: 0.328877\n",
      "[648]\ttrain's auc: 0.836328\ttrain's binary_logloss: 0.328871\n",
      "[649]\ttrain's auc: 0.836333\ttrain's binary_logloss: 0.328866\n",
      "[650]\ttrain's auc: 0.836347\ttrain's binary_logloss: 0.328855\n",
      "[651]\ttrain's auc: 0.836345\ttrain's binary_logloss: 0.328855\n",
      "[652]\ttrain's auc: 0.836352\ttrain's binary_logloss: 0.32885\n",
      "[653]\ttrain's auc: 0.83635\ttrain's binary_logloss: 0.32885\n",
      "[654]\ttrain's auc: 0.836351\ttrain's binary_logloss: 0.328849\n",
      "[655]\ttrain's auc: 0.836354\ttrain's binary_logloss: 0.328845\n",
      "[656]\ttrain's auc: 0.836363\ttrain's binary_logloss: 0.328838\n",
      "[657]\ttrain's auc: 0.836378\ttrain's binary_logloss: 0.328825\n",
      "[658]\ttrain's auc: 0.836401\ttrain's binary_logloss: 0.32881\n",
      "[659]\ttrain's auc: 0.836405\ttrain's binary_logloss: 0.328804\n",
      "[660]\ttrain's auc: 0.83641\ttrain's binary_logloss: 0.3288\n",
      "[661]\ttrain's auc: 0.83641\ttrain's binary_logloss: 0.3288\n",
      "[662]\ttrain's auc: 0.83642\ttrain's binary_logloss: 0.328792\n",
      "[663]\ttrain's auc: 0.836427\ttrain's binary_logloss: 0.328788\n",
      "[664]\ttrain's auc: 0.836428\ttrain's binary_logloss: 0.328787\n",
      "[665]\ttrain's auc: 0.836444\ttrain's binary_logloss: 0.328777\n",
      "[666]\ttrain's auc: 0.836457\ttrain's binary_logloss: 0.328766\n",
      "[667]\ttrain's auc: 0.836465\ttrain's binary_logloss: 0.328758\n",
      "[668]\ttrain's auc: 0.836471\ttrain's binary_logloss: 0.328752\n",
      "[669]\ttrain's auc: 0.836485\ttrain's binary_logloss: 0.328742\n",
      "[670]\ttrain's auc: 0.836489\ttrain's binary_logloss: 0.328736\n",
      "[671]\ttrain's auc: 0.836486\ttrain's binary_logloss: 0.328737\n",
      "[672]\ttrain's auc: 0.836487\ttrain's binary_logloss: 0.328736\n",
      "[673]\ttrain's auc: 0.836489\ttrain's binary_logloss: 0.328734\n",
      "[674]\ttrain's auc: 0.836492\ttrain's binary_logloss: 0.328732\n",
      "[675]\ttrain's auc: 0.836491\ttrain's binary_logloss: 0.328734\n",
      "[676]\ttrain's auc: 0.836507\ttrain's binary_logloss: 0.328722\n",
      "[677]\ttrain's auc: 0.836512\ttrain's binary_logloss: 0.328718\n",
      "[678]\ttrain's auc: 0.836511\ttrain's binary_logloss: 0.328718\n",
      "[679]\ttrain's auc: 0.836514\ttrain's binary_logloss: 0.328715\n",
      "[680]\ttrain's auc: 0.836519\ttrain's binary_logloss: 0.328712\n",
      "[681]\ttrain's auc: 0.836519\ttrain's binary_logloss: 0.328712\n",
      "[682]\ttrain's auc: 0.836519\ttrain's binary_logloss: 0.328711\n",
      "[683]\ttrain's auc: 0.836525\ttrain's binary_logloss: 0.328707\n",
      "[684]\ttrain's auc: 0.836526\ttrain's binary_logloss: 0.328706\n",
      "[685]\ttrain's auc: 0.836525\ttrain's binary_logloss: 0.328707\n",
      "[686]\ttrain's auc: 0.836525\ttrain's binary_logloss: 0.328706\n",
      "[687]\ttrain's auc: 0.83653\ttrain's binary_logloss: 0.328704\n",
      "[688]\ttrain's auc: 0.836544\ttrain's binary_logloss: 0.328694\n",
      "[689]\ttrain's auc: 0.836569\ttrain's binary_logloss: 0.328677\n",
      "[690]\ttrain's auc: 0.83658\ttrain's binary_logloss: 0.328664\n",
      "[691]\ttrain's auc: 0.836585\ttrain's binary_logloss: 0.328658\n",
      "[692]\ttrain's auc: 0.836583\ttrain's binary_logloss: 0.328659\n",
      "[693]\ttrain's auc: 0.836593\ttrain's binary_logloss: 0.328653\n",
      "[694]\ttrain's auc: 0.836603\ttrain's binary_logloss: 0.328643\n",
      "[695]\ttrain's auc: 0.836631\ttrain's binary_logloss: 0.328622\n",
      "[696]\ttrain's auc: 0.836649\ttrain's binary_logloss: 0.328609\n",
      "[697]\ttrain's auc: 0.836664\ttrain's binary_logloss: 0.328599\n",
      "[698]\ttrain's auc: 0.836678\ttrain's binary_logloss: 0.328588\n",
      "[699]\ttrain's auc: 0.836693\ttrain's binary_logloss: 0.328577\n",
      "[700]\ttrain's auc: 0.836701\ttrain's binary_logloss: 0.32857\n",
      "[701]\ttrain's auc: 0.836734\ttrain's binary_logloss: 0.328547\n",
      "[702]\ttrain's auc: 0.836777\ttrain's binary_logloss: 0.328476\n",
      "[703]\ttrain's auc: 0.836782\ttrain's binary_logloss: 0.328472\n",
      "[704]\ttrain's auc: 0.836782\ttrain's binary_logloss: 0.328472\n",
      "[705]\ttrain's auc: 0.836787\ttrain's binary_logloss: 0.328466\n",
      "[706]\ttrain's auc: 0.836795\ttrain's binary_logloss: 0.32846\n",
      "[707]\ttrain's auc: 0.83683\ttrain's binary_logloss: 0.328436\n",
      "[708]\ttrain's auc: 0.836857\ttrain's binary_logloss: 0.328419\n",
      "[709]\ttrain's auc: 0.836856\ttrain's binary_logloss: 0.32842\n",
      "[710]\ttrain's auc: 0.836852\ttrain's binary_logloss: 0.328422\n",
      "[711]\ttrain's auc: 0.836877\ttrain's binary_logloss: 0.328402\n",
      "[712]\ttrain's auc: 0.836884\ttrain's binary_logloss: 0.328396\n",
      "[713]\ttrain's auc: 0.836888\ttrain's binary_logloss: 0.328392\n",
      "[714]\ttrain's auc: 0.836894\ttrain's binary_logloss: 0.328388\n",
      "[715]\ttrain's auc: 0.836892\ttrain's binary_logloss: 0.32839\n",
      "[716]\ttrain's auc: 0.836895\ttrain's binary_logloss: 0.328386\n",
      "[717]\ttrain's auc: 0.836902\ttrain's binary_logloss: 0.328382\n",
      "[718]\ttrain's auc: 0.836902\ttrain's binary_logloss: 0.328381\n",
      "[719]\ttrain's auc: 0.83691\ttrain's binary_logloss: 0.328375\n",
      "[720]\ttrain's auc: 0.836917\ttrain's binary_logloss: 0.328369\n",
      "[721]\ttrain's auc: 0.836924\ttrain's binary_logloss: 0.328364\n",
      "[722]\ttrain's auc: 0.836931\ttrain's binary_logloss: 0.328361\n",
      "[723]\ttrain's auc: 0.83693\ttrain's binary_logloss: 0.328361\n",
      "[724]\ttrain's auc: 0.83693\ttrain's binary_logloss: 0.328361\n",
      "[725]\ttrain's auc: 0.836929\ttrain's binary_logloss: 0.328362\n",
      "[726]\ttrain's auc: 0.836935\ttrain's binary_logloss: 0.328359\n",
      "[727]\ttrain's auc: 0.836933\ttrain's binary_logloss: 0.328359\n",
      "[728]\ttrain's auc: 0.836943\ttrain's binary_logloss: 0.328353\n",
      "[729]\ttrain's auc: 0.836947\ttrain's binary_logloss: 0.32835\n",
      "[730]\ttrain's auc: 0.836954\ttrain's binary_logloss: 0.328343\n",
      "[731]\ttrain's auc: 0.836996\ttrain's binary_logloss: 0.328289\n",
      "[732]\ttrain's auc: 0.837003\ttrain's binary_logloss: 0.328283\n",
      "[733]\ttrain's auc: 0.837016\ttrain's binary_logloss: 0.328274\n",
      "[734]\ttrain's auc: 0.837025\ttrain's binary_logloss: 0.328268\n",
      "[735]\ttrain's auc: 0.83705\ttrain's binary_logloss: 0.328249\n",
      "[736]\ttrain's auc: 0.837114\ttrain's binary_logloss: 0.328189\n",
      "[737]\ttrain's auc: 0.837116\ttrain's binary_logloss: 0.328186\n",
      "[738]\ttrain's auc: 0.837119\ttrain's binary_logloss: 0.328185\n",
      "[739]\ttrain's auc: 0.837118\ttrain's binary_logloss: 0.328185\n",
      "[740]\ttrain's auc: 0.837128\ttrain's binary_logloss: 0.328178\n",
      "[741]\ttrain's auc: 0.837134\ttrain's binary_logloss: 0.328175\n",
      "[742]\ttrain's auc: 0.837142\ttrain's binary_logloss: 0.328169\n",
      "[743]\ttrain's auc: 0.837154\ttrain's binary_logloss: 0.32816\n",
      "[744]\ttrain's auc: 0.837164\ttrain's binary_logloss: 0.328153\n",
      "[745]\ttrain's auc: 0.837166\ttrain's binary_logloss: 0.328151\n",
      "[746]\ttrain's auc: 0.837169\ttrain's binary_logloss: 0.328149\n",
      "[747]\ttrain's auc: 0.837167\ttrain's binary_logloss: 0.328151\n",
      "[748]\ttrain's auc: 0.837171\ttrain's binary_logloss: 0.328148\n",
      "[749]\ttrain's auc: 0.837176\ttrain's binary_logloss: 0.328144\n",
      "[750]\ttrain's auc: 0.837184\ttrain's binary_logloss: 0.328133\n",
      "[751]\ttrain's auc: 0.837184\ttrain's binary_logloss: 0.328134\n",
      "[752]\ttrain's auc: 0.83719\ttrain's binary_logloss: 0.328126\n",
      "[753]\ttrain's auc: 0.837203\ttrain's binary_logloss: 0.328115\n",
      "[754]\ttrain's auc: 0.837209\ttrain's binary_logloss: 0.328112\n",
      "[755]\ttrain's auc: 0.837215\ttrain's binary_logloss: 0.328106\n",
      "[756]\ttrain's auc: 0.837218\ttrain's binary_logloss: 0.328104\n",
      "[757]\ttrain's auc: 0.837225\ttrain's binary_logloss: 0.328099\n",
      "[758]\ttrain's auc: 0.837225\ttrain's binary_logloss: 0.328098\n",
      "[759]\ttrain's auc: 0.837257\ttrain's binary_logloss: 0.328068\n",
      "[760]\ttrain's auc: 0.837323\ttrain's binary_logloss: 0.327992\n",
      "[761]\ttrain's auc: 0.837328\ttrain's binary_logloss: 0.327987\n",
      "[762]\ttrain's auc: 0.83733\ttrain's binary_logloss: 0.327985\n",
      "[763]\ttrain's auc: 0.837339\ttrain's binary_logloss: 0.327975\n",
      "[764]\ttrain's auc: 0.837345\ttrain's binary_logloss: 0.32797\n",
      "[765]\ttrain's auc: 0.837365\ttrain's binary_logloss: 0.327956\n",
      "[766]\ttrain's auc: 0.837371\ttrain's binary_logloss: 0.327951\n",
      "[767]\ttrain's auc: 0.837389\ttrain's binary_logloss: 0.327938\n",
      "[768]\ttrain's auc: 0.837391\ttrain's binary_logloss: 0.327937\n",
      "[769]\ttrain's auc: 0.837392\ttrain's binary_logloss: 0.327936\n",
      "[770]\ttrain's auc: 0.837397\ttrain's binary_logloss: 0.327932\n",
      "[771]\ttrain's auc: 0.837404\ttrain's binary_logloss: 0.327927\n",
      "[772]\ttrain's auc: 0.837405\ttrain's binary_logloss: 0.327927\n",
      "[773]\ttrain's auc: 0.837409\ttrain's binary_logloss: 0.327922\n",
      "[774]\ttrain's auc: 0.837413\ttrain's binary_logloss: 0.327918\n",
      "[775]\ttrain's auc: 0.837424\ttrain's binary_logloss: 0.327909\n",
      "[776]\ttrain's auc: 0.837439\ttrain's binary_logloss: 0.327897\n",
      "[777]\ttrain's auc: 0.837442\ttrain's binary_logloss: 0.327895\n",
      "[778]\ttrain's auc: 0.837442\ttrain's binary_logloss: 0.327895\n",
      "[779]\ttrain's auc: 0.837442\ttrain's binary_logloss: 0.327894\n",
      "[780]\ttrain's auc: 0.837447\ttrain's binary_logloss: 0.327889\n",
      "[781]\ttrain's auc: 0.837449\ttrain's binary_logloss: 0.327889\n",
      "[782]\ttrain's auc: 0.837447\ttrain's binary_logloss: 0.32789\n",
      "[783]\ttrain's auc: 0.837449\ttrain's binary_logloss: 0.32789\n",
      "[784]\ttrain's auc: 0.837452\ttrain's binary_logloss: 0.327888\n",
      "[785]\ttrain's auc: 0.837456\ttrain's binary_logloss: 0.327883\n",
      "[786]\ttrain's auc: 0.837454\ttrain's binary_logloss: 0.327885\n",
      "[787]\ttrain's auc: 0.837455\ttrain's binary_logloss: 0.327884\n",
      "[788]\ttrain's auc: 0.837466\ttrain's binary_logloss: 0.327875\n",
      "[789]\ttrain's auc: 0.837471\ttrain's binary_logloss: 0.327871\n",
      "[790]\ttrain's auc: 0.837488\ttrain's binary_logloss: 0.327862\n",
      "[791]\ttrain's auc: 0.837496\ttrain's binary_logloss: 0.327856\n",
      "[792]\ttrain's auc: 0.837501\ttrain's binary_logloss: 0.327851\n",
      "[793]\ttrain's auc: 0.837512\ttrain's binary_logloss: 0.327842\n",
      "[794]\ttrain's auc: 0.837517\ttrain's binary_logloss: 0.327838\n",
      "[795]\ttrain's auc: 0.837518\ttrain's binary_logloss: 0.327836\n",
      "[796]\ttrain's auc: 0.837532\ttrain's binary_logloss: 0.327826\n",
      "[797]\ttrain's auc: 0.837538\ttrain's binary_logloss: 0.327822\n",
      "[798]\ttrain's auc: 0.837551\ttrain's binary_logloss: 0.32781\n",
      "[799]\ttrain's auc: 0.837551\ttrain's binary_logloss: 0.32781\n",
      "[800]\ttrain's auc: 0.837555\ttrain's binary_logloss: 0.327806\n",
      "[801]\ttrain's auc: 0.837567\ttrain's binary_logloss: 0.327794\n",
      "[802]\ttrain's auc: 0.837568\ttrain's binary_logloss: 0.327794\n",
      "[803]\ttrain's auc: 0.837581\ttrain's binary_logloss: 0.327776\n",
      "[804]\ttrain's auc: 0.837593\ttrain's binary_logloss: 0.327768\n",
      "[805]\ttrain's auc: 0.837594\ttrain's binary_logloss: 0.327765\n",
      "[806]\ttrain's auc: 0.837597\ttrain's binary_logloss: 0.327764\n",
      "[807]\ttrain's auc: 0.8376\ttrain's binary_logloss: 0.32776\n",
      "[808]\ttrain's auc: 0.837599\ttrain's binary_logloss: 0.32776\n",
      "[809]\ttrain's auc: 0.837599\ttrain's binary_logloss: 0.327759\n",
      "[810]\ttrain's auc: 0.837598\ttrain's binary_logloss: 0.32776\n",
      "[811]\ttrain's auc: 0.837602\ttrain's binary_logloss: 0.327757\n",
      "[812]\ttrain's auc: 0.837606\ttrain's binary_logloss: 0.327754\n",
      "[813]\ttrain's auc: 0.837608\ttrain's binary_logloss: 0.327754\n",
      "[814]\ttrain's auc: 0.837609\ttrain's binary_logloss: 0.327753\n",
      "[815]\ttrain's auc: 0.837621\ttrain's binary_logloss: 0.327744\n",
      "[816]\ttrain's auc: 0.83763\ttrain's binary_logloss: 0.327736\n",
      "[817]\ttrain's auc: 0.837633\ttrain's binary_logloss: 0.327733\n",
      "[818]\ttrain's auc: 0.837648\ttrain's binary_logloss: 0.327721\n",
      "[819]\ttrain's auc: 0.837651\ttrain's binary_logloss: 0.32772\n",
      "[820]\ttrain's auc: 0.837663\ttrain's binary_logloss: 0.327711\n",
      "[821]\ttrain's auc: 0.837668\ttrain's binary_logloss: 0.327707\n",
      "[822]\ttrain's auc: 0.837679\ttrain's binary_logloss: 0.327698\n",
      "[823]\ttrain's auc: 0.837679\ttrain's binary_logloss: 0.327697\n",
      "[824]\ttrain's auc: 0.837685\ttrain's binary_logloss: 0.327692\n",
      "[825]\ttrain's auc: 0.837684\ttrain's binary_logloss: 0.327693\n",
      "[826]\ttrain's auc: 0.837683\ttrain's binary_logloss: 0.327691\n",
      "[827]\ttrain's auc: 0.837688\ttrain's binary_logloss: 0.327685\n",
      "[828]\ttrain's auc: 0.837691\ttrain's binary_logloss: 0.327682\n",
      "[829]\ttrain's auc: 0.837694\ttrain's binary_logloss: 0.327678\n",
      "[830]\ttrain's auc: 0.837711\ttrain's binary_logloss: 0.327666\n",
      "[831]\ttrain's auc: 0.837721\ttrain's binary_logloss: 0.327658\n",
      "[832]\ttrain's auc: 0.837731\ttrain's binary_logloss: 0.32765\n",
      "[833]\ttrain's auc: 0.837732\ttrain's binary_logloss: 0.327648\n",
      "[834]\ttrain's auc: 0.837731\ttrain's binary_logloss: 0.32765\n",
      "[835]\ttrain's auc: 0.837734\ttrain's binary_logloss: 0.327648\n",
      "[836]\ttrain's auc: 0.837735\ttrain's binary_logloss: 0.327647\n",
      "[837]\ttrain's auc: 0.837735\ttrain's binary_logloss: 0.327647\n",
      "[838]\ttrain's auc: 0.837742\ttrain's binary_logloss: 0.327641\n",
      "[839]\ttrain's auc: 0.837746\ttrain's binary_logloss: 0.327639\n",
      "[840]\ttrain's auc: 0.837748\ttrain's binary_logloss: 0.327636\n",
      "[841]\ttrain's auc: 0.837765\ttrain's binary_logloss: 0.327624\n",
      "[842]\ttrain's auc: 0.837773\ttrain's binary_logloss: 0.327619\n",
      "[843]\ttrain's auc: 0.83778\ttrain's binary_logloss: 0.327611\n",
      "[844]\ttrain's auc: 0.837792\ttrain's binary_logloss: 0.327603\n",
      "[845]\ttrain's auc: 0.837796\ttrain's binary_logloss: 0.327599\n",
      "[846]\ttrain's auc: 0.8378\ttrain's binary_logloss: 0.327596\n",
      "[847]\ttrain's auc: 0.837806\ttrain's binary_logloss: 0.327591\n",
      "[848]\ttrain's auc: 0.837806\ttrain's binary_logloss: 0.32759\n",
      "[849]\ttrain's auc: 0.83781\ttrain's binary_logloss: 0.327588\n",
      "[850]\ttrain's auc: 0.837822\ttrain's binary_logloss: 0.327579\n",
      "[851]\ttrain's auc: 0.837828\ttrain's binary_logloss: 0.327574\n",
      "[852]\ttrain's auc: 0.837837\ttrain's binary_logloss: 0.327568\n",
      "[853]\ttrain's auc: 0.837838\ttrain's binary_logloss: 0.327569\n",
      "[854]\ttrain's auc: 0.837846\ttrain's binary_logloss: 0.327562\n",
      "[855]\ttrain's auc: 0.837857\ttrain's binary_logloss: 0.327554\n",
      "[856]\ttrain's auc: 0.83786\ttrain's binary_logloss: 0.327554\n",
      "[857]\ttrain's auc: 0.837905\ttrain's binary_logloss: 0.32751\n",
      "[858]\ttrain's auc: 0.837931\ttrain's binary_logloss: 0.327485\n",
      "[859]\ttrain's auc: 0.837945\ttrain's binary_logloss: 0.327474\n",
      "[860]\ttrain's auc: 0.837952\ttrain's binary_logloss: 0.327468\n",
      "[861]\ttrain's auc: 0.837955\ttrain's binary_logloss: 0.327464\n",
      "[862]\ttrain's auc: 0.837955\ttrain's binary_logloss: 0.327464\n",
      "[863]\ttrain's auc: 0.837956\ttrain's binary_logloss: 0.327464\n",
      "[864]\ttrain's auc: 0.837971\ttrain's binary_logloss: 0.327452\n",
      "[865]\ttrain's auc: 0.837971\ttrain's binary_logloss: 0.327452\n",
      "[866]\ttrain's auc: 0.837986\ttrain's binary_logloss: 0.327442\n",
      "[867]\ttrain's auc: 0.838001\ttrain's binary_logloss: 0.32743\n",
      "[868]\ttrain's auc: 0.838031\ttrain's binary_logloss: 0.327405\n",
      "[869]\ttrain's auc: 0.838044\ttrain's binary_logloss: 0.327397\n",
      "[870]\ttrain's auc: 0.838053\ttrain's binary_logloss: 0.327389\n",
      "[871]\ttrain's auc: 0.838053\ttrain's binary_logloss: 0.327388\n",
      "[872]\ttrain's auc: 0.838061\ttrain's binary_logloss: 0.32738\n",
      "[873]\ttrain's auc: 0.83807\ttrain's binary_logloss: 0.327374\n",
      "[874]\ttrain's auc: 0.838072\ttrain's binary_logloss: 0.327372\n",
      "[875]\ttrain's auc: 0.838079\ttrain's binary_logloss: 0.327368\n",
      "[876]\ttrain's auc: 0.83808\ttrain's binary_logloss: 0.327368\n",
      "[877]\ttrain's auc: 0.838081\ttrain's binary_logloss: 0.327368\n",
      "[878]\ttrain's auc: 0.83809\ttrain's binary_logloss: 0.327362\n",
      "[879]\ttrain's auc: 0.838096\ttrain's binary_logloss: 0.327359\n",
      "[880]\ttrain's auc: 0.8381\ttrain's binary_logloss: 0.327356\n",
      "[881]\ttrain's auc: 0.838106\ttrain's binary_logloss: 0.327346\n",
      "[882]\ttrain's auc: 0.83811\ttrain's binary_logloss: 0.327343\n",
      "[883]\ttrain's auc: 0.838113\ttrain's binary_logloss: 0.327339\n",
      "[884]\ttrain's auc: 0.838118\ttrain's binary_logloss: 0.327336\n",
      "[885]\ttrain's auc: 0.838123\ttrain's binary_logloss: 0.327333\n",
      "[886]\ttrain's auc: 0.838132\ttrain's binary_logloss: 0.327326\n",
      "[887]\ttrain's auc: 0.838135\ttrain's binary_logloss: 0.327324\n",
      "[888]\ttrain's auc: 0.838142\ttrain's binary_logloss: 0.327318\n",
      "[889]\ttrain's auc: 0.838142\ttrain's binary_logloss: 0.327318\n",
      "[890]\ttrain's auc: 0.838145\ttrain's binary_logloss: 0.327317\n",
      "[891]\ttrain's auc: 0.838145\ttrain's binary_logloss: 0.327316\n",
      "[892]\ttrain's auc: 0.838157\ttrain's binary_logloss: 0.327305\n",
      "[893]\ttrain's auc: 0.838158\ttrain's binary_logloss: 0.327304\n",
      "[894]\ttrain's auc: 0.838158\ttrain's binary_logloss: 0.327303\n",
      "[895]\ttrain's auc: 0.838155\ttrain's binary_logloss: 0.327305\n",
      "[896]\ttrain's auc: 0.838155\ttrain's binary_logloss: 0.327305\n",
      "[897]\ttrain's auc: 0.838154\ttrain's binary_logloss: 0.327307\n",
      "[898]\ttrain's auc: 0.838155\ttrain's binary_logloss: 0.327305\n",
      "[899]\ttrain's auc: 0.838161\ttrain's binary_logloss: 0.3273\n",
      "[900]\ttrain's auc: 0.838178\ttrain's binary_logloss: 0.327288\n",
      "[901]\ttrain's auc: 0.838194\ttrain's binary_logloss: 0.327276\n",
      "[902]\ttrain's auc: 0.838198\ttrain's binary_logloss: 0.327272\n",
      "[903]\ttrain's auc: 0.838221\ttrain's binary_logloss: 0.327247\n",
      "[904]\ttrain's auc: 0.838218\ttrain's binary_logloss: 0.327249\n",
      "[905]\ttrain's auc: 0.838222\ttrain's binary_logloss: 0.327246\n",
      "[906]\ttrain's auc: 0.838261\ttrain's binary_logloss: 0.327209\n",
      "[907]\ttrain's auc: 0.838258\ttrain's binary_logloss: 0.327212\n",
      "[908]\ttrain's auc: 0.838263\ttrain's binary_logloss: 0.327207\n",
      "[909]\ttrain's auc: 0.838265\ttrain's binary_logloss: 0.327203\n",
      "[910]\ttrain's auc: 0.838277\ttrain's binary_logloss: 0.327194\n",
      "[911]\ttrain's auc: 0.838278\ttrain's binary_logloss: 0.327193\n",
      "[912]\ttrain's auc: 0.838284\ttrain's binary_logloss: 0.327187\n",
      "[913]\ttrain's auc: 0.838286\ttrain's binary_logloss: 0.327185\n",
      "[914]\ttrain's auc: 0.838295\ttrain's binary_logloss: 0.327178\n",
      "[915]\ttrain's auc: 0.8383\ttrain's binary_logloss: 0.327175\n",
      "[916]\ttrain's auc: 0.838303\ttrain's binary_logloss: 0.327171\n",
      "[917]\ttrain's auc: 0.838313\ttrain's binary_logloss: 0.327162\n",
      "[918]\ttrain's auc: 0.838313\ttrain's binary_logloss: 0.327162\n",
      "[919]\ttrain's auc: 0.838311\ttrain's binary_logloss: 0.327163\n",
      "[920]\ttrain's auc: 0.838319\ttrain's binary_logloss: 0.327156\n",
      "[921]\ttrain's auc: 0.838318\ttrain's binary_logloss: 0.327157\n",
      "[922]\ttrain's auc: 0.838319\ttrain's binary_logloss: 0.327155\n",
      "[923]\ttrain's auc: 0.83833\ttrain's binary_logloss: 0.327148\n",
      "[924]\ttrain's auc: 0.838329\ttrain's binary_logloss: 0.327148\n",
      "[925]\ttrain's auc: 0.838339\ttrain's binary_logloss: 0.32714\n",
      "[926]\ttrain's auc: 0.838343\ttrain's binary_logloss: 0.327136\n",
      "[927]\ttrain's auc: 0.838343\ttrain's binary_logloss: 0.327135\n",
      "[928]\ttrain's auc: 0.838343\ttrain's binary_logloss: 0.327134\n",
      "[929]\ttrain's auc: 0.838352\ttrain's binary_logloss: 0.32713\n",
      "[930]\ttrain's auc: 0.838357\ttrain's binary_logloss: 0.327127\n",
      "[931]\ttrain's auc: 0.83837\ttrain's binary_logloss: 0.327117\n",
      "[932]\ttrain's auc: 0.838379\ttrain's binary_logloss: 0.32711\n",
      "[933]\ttrain's auc: 0.838391\ttrain's binary_logloss: 0.327102\n",
      "[934]\ttrain's auc: 0.838404\ttrain's binary_logloss: 0.327094\n",
      "[935]\ttrain's auc: 0.838415\ttrain's binary_logloss: 0.327083\n",
      "[936]\ttrain's auc: 0.838414\ttrain's binary_logloss: 0.327085\n",
      "[937]\ttrain's auc: 0.83842\ttrain's binary_logloss: 0.327081\n",
      "[938]\ttrain's auc: 0.838422\ttrain's binary_logloss: 0.32708\n",
      "[939]\ttrain's auc: 0.838419\ttrain's binary_logloss: 0.327081\n",
      "[940]\ttrain's auc: 0.838417\ttrain's binary_logloss: 0.327083\n",
      "[941]\ttrain's auc: 0.838424\ttrain's binary_logloss: 0.327079\n",
      "[942]\ttrain's auc: 0.838444\ttrain's binary_logloss: 0.327057\n",
      "[943]\ttrain's auc: 0.838454\ttrain's binary_logloss: 0.327049\n",
      "[944]\ttrain's auc: 0.838459\ttrain's binary_logloss: 0.327045\n",
      "[945]\ttrain's auc: 0.838458\ttrain's binary_logloss: 0.327045\n",
      "[946]\ttrain's auc: 0.838475\ttrain's binary_logloss: 0.327032\n",
      "[947]\ttrain's auc: 0.838505\ttrain's binary_logloss: 0.327008\n",
      "[948]\ttrain's auc: 0.838509\ttrain's binary_logloss: 0.327005\n",
      "[949]\ttrain's auc: 0.838511\ttrain's binary_logloss: 0.327003\n",
      "[950]\ttrain's auc: 0.838509\ttrain's binary_logloss: 0.327004\n",
      "[951]\ttrain's auc: 0.838508\ttrain's binary_logloss: 0.327005\n",
      "[952]\ttrain's auc: 0.838518\ttrain's binary_logloss: 0.326997\n",
      "[953]\ttrain's auc: 0.83852\ttrain's binary_logloss: 0.326994\n",
      "[954]\ttrain's auc: 0.838521\ttrain's binary_logloss: 0.326993\n",
      "[955]\ttrain's auc: 0.838523\ttrain's binary_logloss: 0.326991\n",
      "[956]\ttrain's auc: 0.838525\ttrain's binary_logloss: 0.326989\n",
      "[957]\ttrain's auc: 0.838525\ttrain's binary_logloss: 0.326989\n",
      "[958]\ttrain's auc: 0.838529\ttrain's binary_logloss: 0.326986\n",
      "[959]\ttrain's auc: 0.838545\ttrain's binary_logloss: 0.326971\n",
      "[960]\ttrain's auc: 0.838549\ttrain's binary_logloss: 0.326969\n",
      "[961]\ttrain's auc: 0.838556\ttrain's binary_logloss: 0.326964\n",
      "[962]\ttrain's auc: 0.83856\ttrain's binary_logloss: 0.326961\n",
      "[963]\ttrain's auc: 0.83856\ttrain's binary_logloss: 0.326961\n",
      "[964]\ttrain's auc: 0.838562\ttrain's binary_logloss: 0.326959\n",
      "[965]\ttrain's auc: 0.838563\ttrain's binary_logloss: 0.326958\n",
      "[966]\ttrain's auc: 0.838576\ttrain's binary_logloss: 0.32695\n",
      "[967]\ttrain's auc: 0.838611\ttrain's binary_logloss: 0.326926\n",
      "[968]\ttrain's auc: 0.838611\ttrain's binary_logloss: 0.326926\n",
      "[969]\ttrain's auc: 0.83862\ttrain's binary_logloss: 0.326919\n",
      "[970]\ttrain's auc: 0.838625\ttrain's binary_logloss: 0.326915\n",
      "[971]\ttrain's auc: 0.838627\ttrain's binary_logloss: 0.326913\n",
      "[972]\ttrain's auc: 0.838641\ttrain's binary_logloss: 0.326904\n",
      "[973]\ttrain's auc: 0.838638\ttrain's binary_logloss: 0.326906\n",
      "[974]\ttrain's auc: 0.838647\ttrain's binary_logloss: 0.326898\n",
      "[975]\ttrain's auc: 0.838658\ttrain's binary_logloss: 0.32689\n",
      "[976]\ttrain's auc: 0.838659\ttrain's binary_logloss: 0.326888\n",
      "[977]\ttrain's auc: 0.838656\ttrain's binary_logloss: 0.32689\n",
      "[978]\ttrain's auc: 0.838658\ttrain's binary_logloss: 0.326889\n",
      "[979]\ttrain's auc: 0.838666\ttrain's binary_logloss: 0.326883\n",
      "[980]\ttrain's auc: 0.838665\ttrain's binary_logloss: 0.326884\n",
      "[981]\ttrain's auc: 0.838666\ttrain's binary_logloss: 0.326883\n",
      "[982]\ttrain's auc: 0.83867\ttrain's binary_logloss: 0.32688\n",
      "[983]\ttrain's auc: 0.838681\ttrain's binary_logloss: 0.326873\n",
      "[984]\ttrain's auc: 0.838684\ttrain's binary_logloss: 0.326871\n",
      "[985]\ttrain's auc: 0.838683\ttrain's binary_logloss: 0.32687\n",
      "[986]\ttrain's auc: 0.838685\ttrain's binary_logloss: 0.326869\n",
      "[987]\ttrain's auc: 0.838684\ttrain's binary_logloss: 0.32687\n",
      "[988]\ttrain's auc: 0.838684\ttrain's binary_logloss: 0.326869\n",
      "[989]\ttrain's auc: 0.838682\ttrain's binary_logloss: 0.326871\n",
      "[990]\ttrain's auc: 0.838707\ttrain's binary_logloss: 0.326839\n",
      "[991]\ttrain's auc: 0.838711\ttrain's binary_logloss: 0.326836\n",
      "[992]\ttrain's auc: 0.838712\ttrain's binary_logloss: 0.326835\n",
      "[993]\ttrain's auc: 0.838708\ttrain's binary_logloss: 0.326837\n",
      "[994]\ttrain's auc: 0.838708\ttrain's binary_logloss: 0.326836\n",
      "[995]\ttrain's auc: 0.838709\ttrain's binary_logloss: 0.326834\n",
      "[996]\ttrain's auc: 0.838709\ttrain's binary_logloss: 0.326834\n",
      "[997]\ttrain's auc: 0.838716\ttrain's binary_logloss: 0.326828\n",
      "[998]\ttrain's auc: 0.83872\ttrain's binary_logloss: 0.326826\n",
      "[999]\ttrain's auc: 0.838729\ttrain's binary_logloss: 0.326818\n",
      "[1000]\ttrain's auc: 0.838734\ttrain's binary_logloss: 0.326816\n",
      "[1001]\ttrain's auc: 0.838733\ttrain's binary_logloss: 0.326816\n",
      "[1002]\ttrain's auc: 0.838731\ttrain's binary_logloss: 0.326817\n",
      "[1003]\ttrain's auc: 0.838738\ttrain's binary_logloss: 0.326813\n",
      "[1004]\ttrain's auc: 0.838737\ttrain's binary_logloss: 0.326812\n",
      "[1005]\ttrain's auc: 0.83874\ttrain's binary_logloss: 0.32681\n",
      "[1006]\ttrain's auc: 0.838741\ttrain's binary_logloss: 0.326809\n",
      "[1007]\ttrain's auc: 0.838754\ttrain's binary_logloss: 0.326799\n",
      "[1008]\ttrain's auc: 0.838751\ttrain's binary_logloss: 0.3268\n",
      "[1009]\ttrain's auc: 0.838753\ttrain's binary_logloss: 0.326796\n",
      "[1010]\ttrain's auc: 0.838762\ttrain's binary_logloss: 0.326788\n",
      "[1011]\ttrain's auc: 0.838768\ttrain's binary_logloss: 0.326783\n",
      "[1012]\ttrain's auc: 0.838778\ttrain's binary_logloss: 0.326775\n",
      "[1013]\ttrain's auc: 0.838777\ttrain's binary_logloss: 0.326776\n",
      "[1014]\ttrain's auc: 0.838801\ttrain's binary_logloss: 0.326753\n",
      "[1015]\ttrain's auc: 0.838804\ttrain's binary_logloss: 0.326751\n",
      "[1016]\ttrain's auc: 0.838809\ttrain's binary_logloss: 0.326747\n",
      "[1017]\ttrain's auc: 0.838814\ttrain's binary_logloss: 0.326742\n",
      "[1018]\ttrain's auc: 0.838827\ttrain's binary_logloss: 0.32673\n",
      "[1019]\ttrain's auc: 0.83883\ttrain's binary_logloss: 0.326728\n",
      "[1020]\ttrain's auc: 0.838839\ttrain's binary_logloss: 0.326722\n",
      "[1021]\ttrain's auc: 0.838842\ttrain's binary_logloss: 0.32672\n",
      "[1022]\ttrain's auc: 0.838848\ttrain's binary_logloss: 0.326716\n",
      "[1023]\ttrain's auc: 0.83885\ttrain's binary_logloss: 0.326713\n",
      "[1024]\ttrain's auc: 0.838851\ttrain's binary_logloss: 0.326713\n",
      "[1025]\ttrain's auc: 0.838851\ttrain's binary_logloss: 0.326712\n",
      "[1026]\ttrain's auc: 0.838852\ttrain's binary_logloss: 0.32671\n",
      "[1027]\ttrain's auc: 0.838861\ttrain's binary_logloss: 0.326704\n",
      "[1028]\ttrain's auc: 0.838869\ttrain's binary_logloss: 0.326699\n",
      "[1029]\ttrain's auc: 0.838869\ttrain's binary_logloss: 0.326698\n",
      "[1030]\ttrain's auc: 0.838868\ttrain's binary_logloss: 0.326698\n",
      "[1031]\ttrain's auc: 0.838871\ttrain's binary_logloss: 0.326695\n",
      "[1032]\ttrain's auc: 0.83888\ttrain's binary_logloss: 0.326688\n",
      "[1033]\ttrain's auc: 0.838887\ttrain's binary_logloss: 0.326683\n",
      "[1034]\ttrain's auc: 0.838888\ttrain's binary_logloss: 0.326681\n",
      "[1035]\ttrain's auc: 0.838899\ttrain's binary_logloss: 0.326673\n",
      "[1036]\ttrain's auc: 0.838918\ttrain's binary_logloss: 0.326658\n",
      "[1037]\ttrain's auc: 0.838922\ttrain's binary_logloss: 0.326655\n",
      "[1038]\ttrain's auc: 0.838928\ttrain's binary_logloss: 0.326651\n",
      "[1039]\ttrain's auc: 0.838957\ttrain's binary_logloss: 0.326624\n",
      "[1040]\ttrain's auc: 0.838968\ttrain's binary_logloss: 0.326617\n",
      "[1041]\ttrain's auc: 0.838979\ttrain's binary_logloss: 0.326608\n",
      "[1042]\ttrain's auc: 0.838985\ttrain's binary_logloss: 0.326602\n",
      "[1043]\ttrain's auc: 0.839006\ttrain's binary_logloss: 0.326587\n",
      "[1044]\ttrain's auc: 0.839008\ttrain's binary_logloss: 0.326584\n",
      "[1045]\ttrain's auc: 0.83901\ttrain's binary_logloss: 0.326582\n",
      "[1046]\ttrain's auc: 0.839014\ttrain's binary_logloss: 0.326578\n",
      "[1047]\ttrain's auc: 0.839019\ttrain's binary_logloss: 0.326572\n",
      "[1048]\ttrain's auc: 0.839021\ttrain's binary_logloss: 0.326571\n",
      "[1049]\ttrain's auc: 0.839021\ttrain's binary_logloss: 0.326571\n",
      "[1050]\ttrain's auc: 0.839019\ttrain's binary_logloss: 0.326573\n",
      "[1051]\ttrain's auc: 0.839024\ttrain's binary_logloss: 0.326568\n",
      "[1052]\ttrain's auc: 0.839026\ttrain's binary_logloss: 0.326565\n",
      "[1053]\ttrain's auc: 0.839042\ttrain's binary_logloss: 0.326553\n",
      "[1054]\ttrain's auc: 0.839043\ttrain's binary_logloss: 0.326551\n",
      "[1055]\ttrain's auc: 0.839056\ttrain's binary_logloss: 0.326539\n",
      "[1056]\ttrain's auc: 0.83906\ttrain's binary_logloss: 0.326535\n",
      "[1057]\ttrain's auc: 0.839061\ttrain's binary_logloss: 0.326534\n",
      "[1058]\ttrain's auc: 0.839073\ttrain's binary_logloss: 0.326524\n",
      "[1059]\ttrain's auc: 0.839073\ttrain's binary_logloss: 0.326525\n",
      "[1060]\ttrain's auc: 0.839074\ttrain's binary_logloss: 0.326524\n",
      "[1061]\ttrain's auc: 0.839078\ttrain's binary_logloss: 0.326521\n",
      "[1062]\ttrain's auc: 0.839084\ttrain's binary_logloss: 0.326517\n",
      "[1063]\ttrain's auc: 0.839084\ttrain's binary_logloss: 0.326515\n",
      "[1064]\ttrain's auc: 0.839093\ttrain's binary_logloss: 0.326504\n",
      "[1065]\ttrain's auc: 0.839106\ttrain's binary_logloss: 0.326495\n",
      "[1066]\ttrain's auc: 0.839108\ttrain's binary_logloss: 0.326493\n",
      "[1067]\ttrain's auc: 0.839107\ttrain's binary_logloss: 0.326493\n",
      "[1068]\ttrain's auc: 0.839108\ttrain's binary_logloss: 0.326492\n",
      "[1069]\ttrain's auc: 0.839108\ttrain's binary_logloss: 0.326492\n",
      "[1070]\ttrain's auc: 0.83911\ttrain's binary_logloss: 0.32649\n",
      "[1071]\ttrain's auc: 0.839111\ttrain's binary_logloss: 0.326488\n",
      "[1072]\ttrain's auc: 0.839138\ttrain's binary_logloss: 0.326466\n",
      "[1073]\ttrain's auc: 0.839141\ttrain's binary_logloss: 0.326463\n",
      "[1074]\ttrain's auc: 0.83916\ttrain's binary_logloss: 0.32645\n",
      "[1075]\ttrain's auc: 0.839166\ttrain's binary_logloss: 0.326447\n",
      "[1076]\ttrain's auc: 0.839176\ttrain's binary_logloss: 0.326439\n",
      "[1077]\ttrain's auc: 0.839179\ttrain's binary_logloss: 0.326437\n",
      "[1078]\ttrain's auc: 0.839183\ttrain's binary_logloss: 0.326435\n",
      "[1079]\ttrain's auc: 0.839185\ttrain's binary_logloss: 0.326432\n",
      "[1080]\ttrain's auc: 0.839189\ttrain's binary_logloss: 0.326427\n",
      "[1081]\ttrain's auc: 0.839199\ttrain's binary_logloss: 0.32642\n",
      "[1082]\ttrain's auc: 0.839198\ttrain's binary_logloss: 0.326421\n",
      "[1083]\ttrain's auc: 0.839198\ttrain's binary_logloss: 0.326421\n",
      "[1084]\ttrain's auc: 0.839203\ttrain's binary_logloss: 0.326416\n",
      "[1085]\ttrain's auc: 0.839213\ttrain's binary_logloss: 0.326409\n",
      "[1086]\ttrain's auc: 0.839224\ttrain's binary_logloss: 0.326401\n",
      "[1087]\ttrain's auc: 0.839224\ttrain's binary_logloss: 0.3264\n",
      "[1088]\ttrain's auc: 0.839231\ttrain's binary_logloss: 0.326395\n",
      "[1089]\ttrain's auc: 0.83924\ttrain's binary_logloss: 0.326386\n",
      "[1090]\ttrain's auc: 0.839241\ttrain's binary_logloss: 0.326384\n",
      "[1091]\ttrain's auc: 0.839244\ttrain's binary_logloss: 0.326382\n",
      "[1092]\ttrain's auc: 0.839249\ttrain's binary_logloss: 0.326378\n",
      "[1093]\ttrain's auc: 0.839248\ttrain's binary_logloss: 0.326379\n",
      "[1094]\ttrain's auc: 0.839249\ttrain's binary_logloss: 0.326379\n",
      "[1095]\ttrain's auc: 0.839251\ttrain's binary_logloss: 0.326375\n",
      "[1096]\ttrain's auc: 0.839249\ttrain's binary_logloss: 0.326376\n",
      "[1097]\ttrain's auc: 0.83925\ttrain's binary_logloss: 0.326375\n",
      "[1098]\ttrain's auc: 0.839259\ttrain's binary_logloss: 0.326369\n",
      "[1099]\ttrain's auc: 0.839259\ttrain's binary_logloss: 0.326368\n",
      "[1100]\ttrain's auc: 0.83926\ttrain's binary_logloss: 0.326367\n",
      "[1101]\ttrain's auc: 0.83926\ttrain's binary_logloss: 0.326367\n",
      "[1102]\ttrain's auc: 0.839258\ttrain's binary_logloss: 0.326368\n",
      "[1103]\ttrain's auc: 0.839257\ttrain's binary_logloss: 0.326369\n",
      "[1104]\ttrain's auc: 0.839265\ttrain's binary_logloss: 0.326364\n",
      "[1105]\ttrain's auc: 0.839266\ttrain's binary_logloss: 0.326361\n",
      "[1106]\ttrain's auc: 0.839264\ttrain's binary_logloss: 0.326361\n",
      "[1107]\ttrain's auc: 0.839273\ttrain's binary_logloss: 0.326355\n",
      "[1108]\ttrain's auc: 0.839292\ttrain's binary_logloss: 0.326337\n",
      "[1109]\ttrain's auc: 0.839298\ttrain's binary_logloss: 0.326333\n",
      "[1110]\ttrain's auc: 0.839297\ttrain's binary_logloss: 0.326333\n",
      "[1111]\ttrain's auc: 0.839298\ttrain's binary_logloss: 0.326332\n",
      "[1112]\ttrain's auc: 0.839299\ttrain's binary_logloss: 0.326332\n",
      "[1113]\ttrain's auc: 0.839299\ttrain's binary_logloss: 0.326331\n",
      "[1114]\ttrain's auc: 0.8393\ttrain's binary_logloss: 0.326329\n",
      "[1115]\ttrain's auc: 0.8393\ttrain's binary_logloss: 0.326329\n",
      "[1116]\ttrain's auc: 0.839303\ttrain's binary_logloss: 0.326328\n",
      "[1117]\ttrain's auc: 0.839306\ttrain's binary_logloss: 0.326327\n",
      "[1118]\ttrain's auc: 0.839307\ttrain's binary_logloss: 0.326327\n",
      "[1119]\ttrain's auc: 0.839314\ttrain's binary_logloss: 0.326321\n",
      "[1120]\ttrain's auc: 0.839314\ttrain's binary_logloss: 0.326321\n",
      "[1121]\ttrain's auc: 0.839318\ttrain's binary_logloss: 0.326319\n",
      "[1122]\ttrain's auc: 0.839319\ttrain's binary_logloss: 0.326319\n",
      "[1123]\ttrain's auc: 0.839318\ttrain's binary_logloss: 0.32632\n",
      "[1124]\ttrain's auc: 0.839325\ttrain's binary_logloss: 0.326315\n",
      "[1125]\ttrain's auc: 0.839329\ttrain's binary_logloss: 0.326311\n",
      "[1126]\ttrain's auc: 0.839332\ttrain's binary_logloss: 0.326307\n",
      "[1127]\ttrain's auc: 0.83934\ttrain's binary_logloss: 0.326301\n",
      "[1128]\ttrain's auc: 0.839342\ttrain's binary_logloss: 0.326299\n",
      "[1129]\ttrain's auc: 0.839344\ttrain's binary_logloss: 0.326296\n",
      "[1130]\ttrain's auc: 0.839349\ttrain's binary_logloss: 0.326293\n",
      "[1131]\ttrain's auc: 0.839351\ttrain's binary_logloss: 0.326291\n",
      "[1132]\ttrain's auc: 0.83935\ttrain's binary_logloss: 0.326292\n",
      "[1133]\ttrain's auc: 0.839353\ttrain's binary_logloss: 0.326288\n",
      "[1134]\ttrain's auc: 0.83936\ttrain's binary_logloss: 0.326283\n",
      "[1135]\ttrain's auc: 0.839363\ttrain's binary_logloss: 0.326277\n",
      "[1136]\ttrain's auc: 0.839364\ttrain's binary_logloss: 0.326277\n",
      "[1137]\ttrain's auc: 0.839367\ttrain's binary_logloss: 0.326276\n",
      "[1138]\ttrain's auc: 0.839366\ttrain's binary_logloss: 0.326276\n",
      "[1139]\ttrain's auc: 0.839366\ttrain's binary_logloss: 0.326277\n",
      "[1140]\ttrain's auc: 0.839379\ttrain's binary_logloss: 0.326269\n",
      "[1141]\ttrain's auc: 0.839384\ttrain's binary_logloss: 0.326266\n",
      "[1142]\ttrain's auc: 0.839386\ttrain's binary_logloss: 0.326264\n",
      "[1143]\ttrain's auc: 0.839387\ttrain's binary_logloss: 0.326263\n",
      "[1144]\ttrain's auc: 0.839393\ttrain's binary_logloss: 0.326259\n",
      "[1145]\ttrain's auc: 0.839391\ttrain's binary_logloss: 0.32626\n",
      "[1146]\ttrain's auc: 0.839406\ttrain's binary_logloss: 0.326246\n",
      "[1147]\ttrain's auc: 0.839409\ttrain's binary_logloss: 0.326243\n",
      "[1148]\ttrain's auc: 0.839419\ttrain's binary_logloss: 0.326228\n",
      "[1149]\ttrain's auc: 0.839434\ttrain's binary_logloss: 0.326218\n",
      "[1150]\ttrain's auc: 0.839436\ttrain's binary_logloss: 0.326217\n",
      "[1151]\ttrain's auc: 0.839434\ttrain's binary_logloss: 0.326218\n",
      "[1152]\ttrain's auc: 0.839433\ttrain's binary_logloss: 0.326218\n",
      "[1153]\ttrain's auc: 0.839444\ttrain's binary_logloss: 0.326209\n",
      "[1154]\ttrain's auc: 0.83945\ttrain's binary_logloss: 0.326205\n",
      "[1155]\ttrain's auc: 0.83946\ttrain's binary_logloss: 0.326184\n",
      "[1156]\ttrain's auc: 0.839461\ttrain's binary_logloss: 0.326181\n",
      "[1157]\ttrain's auc: 0.839464\ttrain's binary_logloss: 0.326179\n",
      "[1158]\ttrain's auc: 0.839469\ttrain's binary_logloss: 0.326176\n",
      "[1159]\ttrain's auc: 0.839469\ttrain's binary_logloss: 0.326175\n",
      "[1160]\ttrain's auc: 0.83947\ttrain's binary_logloss: 0.326173\n",
      "[1161]\ttrain's auc: 0.839488\ttrain's binary_logloss: 0.326161\n",
      "[1162]\ttrain's auc: 0.839489\ttrain's binary_logloss: 0.326159\n",
      "[1163]\ttrain's auc: 0.839497\ttrain's binary_logloss: 0.326152\n",
      "[1164]\ttrain's auc: 0.839493\ttrain's binary_logloss: 0.326156\n",
      "[1165]\ttrain's auc: 0.839495\ttrain's binary_logloss: 0.326152\n",
      "[1166]\ttrain's auc: 0.839492\ttrain's binary_logloss: 0.326154\n",
      "[1167]\ttrain's auc: 0.839493\ttrain's binary_logloss: 0.326152\n",
      "[1168]\ttrain's auc: 0.839503\ttrain's binary_logloss: 0.326144\n",
      "[1169]\ttrain's auc: 0.839509\ttrain's binary_logloss: 0.326141\n",
      "[1170]\ttrain's auc: 0.83952\ttrain's binary_logloss: 0.326133\n",
      "[1171]\ttrain's auc: 0.839521\ttrain's binary_logloss: 0.326131\n",
      "[1172]\ttrain's auc: 0.839519\ttrain's binary_logloss: 0.326131\n",
      "[1173]\ttrain's auc: 0.839523\ttrain's binary_logloss: 0.326127\n",
      "[1174]\ttrain's auc: 0.839522\ttrain's binary_logloss: 0.326127\n",
      "[1175]\ttrain's auc: 0.839528\ttrain's binary_logloss: 0.326123\n",
      "[1176]\ttrain's auc: 0.839537\ttrain's binary_logloss: 0.326117\n",
      "[1177]\ttrain's auc: 0.839546\ttrain's binary_logloss: 0.326111\n",
      "[1178]\ttrain's auc: 0.83955\ttrain's binary_logloss: 0.326108\n",
      "[1179]\ttrain's auc: 0.839554\ttrain's binary_logloss: 0.326106\n",
      "[1180]\ttrain's auc: 0.839554\ttrain's binary_logloss: 0.326106\n",
      "[1181]\ttrain's auc: 0.839554\ttrain's binary_logloss: 0.326105\n",
      "[1182]\ttrain's auc: 0.83956\ttrain's binary_logloss: 0.326102\n",
      "[1183]\ttrain's auc: 0.839567\ttrain's binary_logloss: 0.326098\n",
      "[1184]\ttrain's auc: 0.839567\ttrain's binary_logloss: 0.326096\n",
      "[1185]\ttrain's auc: 0.839583\ttrain's binary_logloss: 0.326087\n",
      "[1186]\ttrain's auc: 0.8396\ttrain's binary_logloss: 0.326074\n",
      "[1187]\ttrain's auc: 0.8396\ttrain's binary_logloss: 0.326073\n",
      "[1188]\ttrain's auc: 0.839603\ttrain's binary_logloss: 0.326072\n",
      "[1189]\ttrain's auc: 0.839602\ttrain's binary_logloss: 0.326073\n",
      "[1190]\ttrain's auc: 0.839604\ttrain's binary_logloss: 0.326071\n",
      "[1191]\ttrain's auc: 0.839611\ttrain's binary_logloss: 0.326065\n",
      "[1192]\ttrain's auc: 0.839617\ttrain's binary_logloss: 0.326061\n",
      "[1193]\ttrain's auc: 0.839647\ttrain's binary_logloss: 0.32603\n",
      "[1194]\ttrain's auc: 0.839645\ttrain's binary_logloss: 0.326031\n",
      "[1195]\ttrain's auc: 0.839647\ttrain's binary_logloss: 0.32603\n",
      "[1196]\ttrain's auc: 0.839648\ttrain's binary_logloss: 0.326031\n",
      "[1197]\ttrain's auc: 0.839654\ttrain's binary_logloss: 0.326026\n",
      "[1198]\ttrain's auc: 0.839654\ttrain's binary_logloss: 0.326026\n",
      "[1199]\ttrain's auc: 0.839667\ttrain's binary_logloss: 0.326018\n",
      "[1200]\ttrain's auc: 0.839671\ttrain's binary_logloss: 0.326014\n",
      "[1201]\ttrain's auc: 0.839674\ttrain's binary_logloss: 0.326013\n",
      "[1202]\ttrain's auc: 0.83968\ttrain's binary_logloss: 0.326006\n",
      "[1203]\ttrain's auc: 0.839682\ttrain's binary_logloss: 0.326004\n",
      "[1204]\ttrain's auc: 0.839686\ttrain's binary_logloss: 0.326\n",
      "[1205]\ttrain's auc: 0.839689\ttrain's binary_logloss: 0.326\n",
      "[1206]\ttrain's auc: 0.839689\ttrain's binary_logloss: 0.326\n",
      "[1207]\ttrain's auc: 0.83969\ttrain's binary_logloss: 0.326\n",
      "[1208]\ttrain's auc: 0.83969\ttrain's binary_logloss: 0.326\n",
      "[1209]\ttrain's auc: 0.839692\ttrain's binary_logloss: 0.325997\n",
      "[1210]\ttrain's auc: 0.839701\ttrain's binary_logloss: 0.325989\n",
      "[1211]\ttrain's auc: 0.839707\ttrain's binary_logloss: 0.325984\n",
      "[1212]\ttrain's auc: 0.839712\ttrain's binary_logloss: 0.325981\n",
      "[1213]\ttrain's auc: 0.839716\ttrain's binary_logloss: 0.325977\n",
      "[1214]\ttrain's auc: 0.839715\ttrain's binary_logloss: 0.325977\n",
      "[1215]\ttrain's auc: 0.839728\ttrain's binary_logloss: 0.325969\n",
      "[1216]\ttrain's auc: 0.839733\ttrain's binary_logloss: 0.325964\n",
      "[1217]\ttrain's auc: 0.839744\ttrain's binary_logloss: 0.325958\n",
      "[1218]\ttrain's auc: 0.839748\ttrain's binary_logloss: 0.325954\n",
      "[1219]\ttrain's auc: 0.83975\ttrain's binary_logloss: 0.325952\n",
      "[1220]\ttrain's auc: 0.839759\ttrain's binary_logloss: 0.325945\n",
      "[1221]\ttrain's auc: 0.839771\ttrain's binary_logloss: 0.325932\n",
      "[1222]\ttrain's auc: 0.839773\ttrain's binary_logloss: 0.325929\n",
      "[1223]\ttrain's auc: 0.83978\ttrain's binary_logloss: 0.325923\n",
      "[1224]\ttrain's auc: 0.839782\ttrain's binary_logloss: 0.32592\n",
      "[1225]\ttrain's auc: 0.839787\ttrain's binary_logloss: 0.325916\n",
      "[1226]\ttrain's auc: 0.839807\ttrain's binary_logloss: 0.325901\n",
      "[1227]\ttrain's auc: 0.839811\ttrain's binary_logloss: 0.325896\n",
      "[1228]\ttrain's auc: 0.839817\ttrain's binary_logloss: 0.325892\n",
      "[1229]\ttrain's auc: 0.839821\ttrain's binary_logloss: 0.325888\n",
      "[1230]\ttrain's auc: 0.839823\ttrain's binary_logloss: 0.325887\n",
      "[1231]\ttrain's auc: 0.839837\ttrain's binary_logloss: 0.325876\n",
      "[1232]\ttrain's auc: 0.83984\ttrain's binary_logloss: 0.325873\n",
      "[1233]\ttrain's auc: 0.839842\ttrain's binary_logloss: 0.325871\n",
      "[1234]\ttrain's auc: 0.839843\ttrain's binary_logloss: 0.32587\n",
      "[1235]\ttrain's auc: 0.83986\ttrain's binary_logloss: 0.325856\n",
      "[1236]\ttrain's auc: 0.839869\ttrain's binary_logloss: 0.325846\n",
      "[1237]\ttrain's auc: 0.839869\ttrain's binary_logloss: 0.325845\n",
      "[1238]\ttrain's auc: 0.839869\ttrain's binary_logloss: 0.325844\n",
      "[1239]\ttrain's auc: 0.839869\ttrain's binary_logloss: 0.325844\n",
      "[1240]\ttrain's auc: 0.83987\ttrain's binary_logloss: 0.325844\n",
      "[1241]\ttrain's auc: 0.839872\ttrain's binary_logloss: 0.325842\n",
      "[1242]\ttrain's auc: 0.839884\ttrain's binary_logloss: 0.325834\n",
      "[1243]\ttrain's auc: 0.839885\ttrain's binary_logloss: 0.325834\n",
      "[1244]\ttrain's auc: 0.839889\ttrain's binary_logloss: 0.32583\n",
      "[1245]\ttrain's auc: 0.839891\ttrain's binary_logloss: 0.32583\n",
      "[1246]\ttrain's auc: 0.839891\ttrain's binary_logloss: 0.32583\n",
      "[1247]\ttrain's auc: 0.839897\ttrain's binary_logloss: 0.325825\n",
      "[1248]\ttrain's auc: 0.839902\ttrain's binary_logloss: 0.325821\n",
      "[1249]\ttrain's auc: 0.839903\ttrain's binary_logloss: 0.32582\n",
      "[1250]\ttrain's auc: 0.839903\ttrain's binary_logloss: 0.325819\n",
      "[1251]\ttrain's auc: 0.839916\ttrain's binary_logloss: 0.325812\n",
      "[1252]\ttrain's auc: 0.839916\ttrain's binary_logloss: 0.325812\n",
      "[1253]\ttrain's auc: 0.839918\ttrain's binary_logloss: 0.32581\n",
      "[1254]\ttrain's auc: 0.839922\ttrain's binary_logloss: 0.325807\n",
      "[1255]\ttrain's auc: 0.839924\ttrain's binary_logloss: 0.325807\n",
      "[1256]\ttrain's auc: 0.839924\ttrain's binary_logloss: 0.325806\n",
      "[1257]\ttrain's auc: 0.839931\ttrain's binary_logloss: 0.325798\n",
      "[1258]\ttrain's auc: 0.839929\ttrain's binary_logloss: 0.325798\n",
      "[1259]\ttrain's auc: 0.839936\ttrain's binary_logloss: 0.325793\n",
      "[1260]\ttrain's auc: 0.839935\ttrain's binary_logloss: 0.325793\n",
      "[1261]\ttrain's auc: 0.839945\ttrain's binary_logloss: 0.325783\n",
      "[1262]\ttrain's auc: 0.839949\ttrain's binary_logloss: 0.325781\n",
      "[1263]\ttrain's auc: 0.839948\ttrain's binary_logloss: 0.325781\n",
      "[1264]\ttrain's auc: 0.839955\ttrain's binary_logloss: 0.325777\n",
      "[1265]\ttrain's auc: 0.839956\ttrain's binary_logloss: 0.325776\n",
      "[1266]\ttrain's auc: 0.839957\ttrain's binary_logloss: 0.325775\n",
      "[1267]\ttrain's auc: 0.839959\ttrain's binary_logloss: 0.325774\n",
      "[1268]\ttrain's auc: 0.839959\ttrain's binary_logloss: 0.325773\n",
      "[1269]\ttrain's auc: 0.839964\ttrain's binary_logloss: 0.325771\n",
      "[1270]\ttrain's auc: 0.839967\ttrain's binary_logloss: 0.325768\n",
      "[1271]\ttrain's auc: 0.839967\ttrain's binary_logloss: 0.325767\n",
      "[1272]\ttrain's auc: 0.839967\ttrain's binary_logloss: 0.325768\n",
      "[1273]\ttrain's auc: 0.839968\ttrain's binary_logloss: 0.325767\n",
      "[1274]\ttrain's auc: 0.839967\ttrain's binary_logloss: 0.325768\n",
      "[1275]\ttrain's auc: 0.839969\ttrain's binary_logloss: 0.325766\n",
      "[1276]\ttrain's auc: 0.839967\ttrain's binary_logloss: 0.325766\n",
      "[1277]\ttrain's auc: 0.839976\ttrain's binary_logloss: 0.32576\n",
      "[1278]\ttrain's auc: 0.839978\ttrain's binary_logloss: 0.325758\n",
      "[1279]\ttrain's auc: 0.839978\ttrain's binary_logloss: 0.325757\n",
      "[1280]\ttrain's auc: 0.839976\ttrain's binary_logloss: 0.325759\n",
      "[1281]\ttrain's auc: 0.839976\ttrain's binary_logloss: 0.325758\n",
      "[1282]\ttrain's auc: 0.83998\ttrain's binary_logloss: 0.325754\n",
      "[1283]\ttrain's auc: 0.839983\ttrain's binary_logloss: 0.325751\n",
      "[1284]\ttrain's auc: 0.839984\ttrain's binary_logloss: 0.325751\n",
      "[1285]\ttrain's auc: 0.839985\ttrain's binary_logloss: 0.32575\n",
      "[1286]\ttrain's auc: 0.839988\ttrain's binary_logloss: 0.325748\n",
      "[1287]\ttrain's auc: 0.839992\ttrain's binary_logloss: 0.325746\n",
      "[1288]\ttrain's auc: 0.839993\ttrain's binary_logloss: 0.325745\n",
      "[1289]\ttrain's auc: 0.839998\ttrain's binary_logloss: 0.325742\n",
      "[1290]\ttrain's auc: 0.840002\ttrain's binary_logloss: 0.325738\n",
      "[1291]\ttrain's auc: 0.840004\ttrain's binary_logloss: 0.325737\n",
      "[1292]\ttrain's auc: 0.840007\ttrain's binary_logloss: 0.325737\n",
      "[1293]\ttrain's auc: 0.840006\ttrain's binary_logloss: 0.325737\n",
      "[1294]\ttrain's auc: 0.840004\ttrain's binary_logloss: 0.325739\n",
      "[1295]\ttrain's auc: 0.840005\ttrain's binary_logloss: 0.325739\n",
      "[1296]\ttrain's auc: 0.840007\ttrain's binary_logloss: 0.325738\n",
      "[1297]\ttrain's auc: 0.840016\ttrain's binary_logloss: 0.325732\n",
      "[1298]\ttrain's auc: 0.840018\ttrain's binary_logloss: 0.325731\n",
      "[1299]\ttrain's auc: 0.840015\ttrain's binary_logloss: 0.325733\n",
      "[1300]\ttrain's auc: 0.840016\ttrain's binary_logloss: 0.325732\n",
      "[1301]\ttrain's auc: 0.840022\ttrain's binary_logloss: 0.325728\n",
      "[1302]\ttrain's auc: 0.840024\ttrain's binary_logloss: 0.325726\n",
      "[1303]\ttrain's auc: 0.840032\ttrain's binary_logloss: 0.32572\n",
      "[1304]\ttrain's auc: 0.840032\ttrain's binary_logloss: 0.32572\n",
      "[1305]\ttrain's auc: 0.84004\ttrain's binary_logloss: 0.325715\n",
      "[1306]\ttrain's auc: 0.840044\ttrain's binary_logloss: 0.325712\n",
      "[1307]\ttrain's auc: 0.840046\ttrain's binary_logloss: 0.325709\n",
      "[1308]\ttrain's auc: 0.840047\ttrain's binary_logloss: 0.325708\n",
      "[1309]\ttrain's auc: 0.840045\ttrain's binary_logloss: 0.32571\n",
      "[1310]\ttrain's auc: 0.840048\ttrain's binary_logloss: 0.325708\n",
      "[1311]\ttrain's auc: 0.840058\ttrain's binary_logloss: 0.3257\n",
      "[1312]\ttrain's auc: 0.840064\ttrain's binary_logloss: 0.325696\n",
      "[1313]\ttrain's auc: 0.840065\ttrain's binary_logloss: 0.325694\n",
      "[1314]\ttrain's auc: 0.840067\ttrain's binary_logloss: 0.325694\n",
      "[1315]\ttrain's auc: 0.840069\ttrain's binary_logloss: 0.325691\n",
      "[1316]\ttrain's auc: 0.840069\ttrain's binary_logloss: 0.325692\n",
      "[1317]\ttrain's auc: 0.840065\ttrain's binary_logloss: 0.325694\n",
      "[1318]\ttrain's auc: 0.840065\ttrain's binary_logloss: 0.325694\n",
      "[1319]\ttrain's auc: 0.840072\ttrain's binary_logloss: 0.32569\n",
      "[1320]\ttrain's auc: 0.840071\ttrain's binary_logloss: 0.32569\n",
      "[1321]\ttrain's auc: 0.840077\ttrain's binary_logloss: 0.325687\n",
      "[1322]\ttrain's auc: 0.84008\ttrain's binary_logloss: 0.325685\n",
      "[1323]\ttrain's auc: 0.840081\ttrain's binary_logloss: 0.325685\n",
      "[1324]\ttrain's auc: 0.840087\ttrain's binary_logloss: 0.325681\n",
      "[1325]\ttrain's auc: 0.840096\ttrain's binary_logloss: 0.325673\n",
      "[1326]\ttrain's auc: 0.840102\ttrain's binary_logloss: 0.325668\n",
      "[1327]\ttrain's auc: 0.840129\ttrain's binary_logloss: 0.325643\n",
      "[1328]\ttrain's auc: 0.840136\ttrain's binary_logloss: 0.325636\n",
      "[1329]\ttrain's auc: 0.840139\ttrain's binary_logloss: 0.325633\n",
      "[1330]\ttrain's auc: 0.840149\ttrain's binary_logloss: 0.325625\n",
      "[1331]\ttrain's auc: 0.840147\ttrain's binary_logloss: 0.325626\n",
      "[1332]\ttrain's auc: 0.840148\ttrain's binary_logloss: 0.325625\n",
      "[1333]\ttrain's auc: 0.840162\ttrain's binary_logloss: 0.325614\n",
      "[1334]\ttrain's auc: 0.840161\ttrain's binary_logloss: 0.325615\n",
      "[1335]\ttrain's auc: 0.840161\ttrain's binary_logloss: 0.325615\n",
      "[1336]\ttrain's auc: 0.840168\ttrain's binary_logloss: 0.32561\n",
      "[1337]\ttrain's auc: 0.840172\ttrain's binary_logloss: 0.325607\n",
      "[1338]\ttrain's auc: 0.840174\ttrain's binary_logloss: 0.325606\n",
      "[1339]\ttrain's auc: 0.840173\ttrain's binary_logloss: 0.325606\n",
      "[1340]\ttrain's auc: 0.840171\ttrain's binary_logloss: 0.325606\n",
      "[1341]\ttrain's auc: 0.84017\ttrain's binary_logloss: 0.325607\n",
      "[1342]\ttrain's auc: 0.840169\ttrain's binary_logloss: 0.325608\n",
      "[1343]\ttrain's auc: 0.84018\ttrain's binary_logloss: 0.325601\n",
      "[1344]\ttrain's auc: 0.840183\ttrain's binary_logloss: 0.3256\n",
      "[1345]\ttrain's auc: 0.840192\ttrain's binary_logloss: 0.325591\n",
      "[1346]\ttrain's auc: 0.840198\ttrain's binary_logloss: 0.325586\n",
      "[1347]\ttrain's auc: 0.840205\ttrain's binary_logloss: 0.325581\n",
      "[1348]\ttrain's auc: 0.840211\ttrain's binary_logloss: 0.325576\n",
      "[1349]\ttrain's auc: 0.840213\ttrain's binary_logloss: 0.325575\n",
      "[1350]\ttrain's auc: 0.840216\ttrain's binary_logloss: 0.325571\n",
      "[1351]\ttrain's auc: 0.840231\ttrain's binary_logloss: 0.325559\n",
      "[1352]\ttrain's auc: 0.840246\ttrain's binary_logloss: 0.325549\n",
      "[1353]\ttrain's auc: 0.840251\ttrain's binary_logloss: 0.325543\n",
      "[1354]\ttrain's auc: 0.840252\ttrain's binary_logloss: 0.325542\n",
      "[1355]\ttrain's auc: 0.840254\ttrain's binary_logloss: 0.325538\n",
      "[1356]\ttrain's auc: 0.840255\ttrain's binary_logloss: 0.325537\n",
      "[1357]\ttrain's auc: 0.840259\ttrain's binary_logloss: 0.325535\n",
      "[1358]\ttrain's auc: 0.84026\ttrain's binary_logloss: 0.325534\n",
      "[1359]\ttrain's auc: 0.840268\ttrain's binary_logloss: 0.325528\n",
      "[1360]\ttrain's auc: 0.840268\ttrain's binary_logloss: 0.325527\n",
      "[1361]\ttrain's auc: 0.840274\ttrain's binary_logloss: 0.325523\n",
      "[1362]\ttrain's auc: 0.840278\ttrain's binary_logloss: 0.325521\n",
      "[1363]\ttrain's auc: 0.840278\ttrain's binary_logloss: 0.325522\n",
      "[1364]\ttrain's auc: 0.840275\ttrain's binary_logloss: 0.325523\n",
      "[1365]\ttrain's auc: 0.840273\ttrain's binary_logloss: 0.325524\n",
      "[1366]\ttrain's auc: 0.840275\ttrain's binary_logloss: 0.325522\n",
      "[1367]\ttrain's auc: 0.840278\ttrain's binary_logloss: 0.325518\n",
      "[1368]\ttrain's auc: 0.840278\ttrain's binary_logloss: 0.325518\n",
      "[1369]\ttrain's auc: 0.840284\ttrain's binary_logloss: 0.325512\n",
      "[1370]\ttrain's auc: 0.840284\ttrain's binary_logloss: 0.325511\n",
      "[1371]\ttrain's auc: 0.840285\ttrain's binary_logloss: 0.325512\n",
      "[1372]\ttrain's auc: 0.840287\ttrain's binary_logloss: 0.32551\n",
      "[1373]\ttrain's auc: 0.840288\ttrain's binary_logloss: 0.325509\n",
      "[1374]\ttrain's auc: 0.840287\ttrain's binary_logloss: 0.32551\n",
      "[1375]\ttrain's auc: 0.840292\ttrain's binary_logloss: 0.325506\n",
      "[1376]\ttrain's auc: 0.840297\ttrain's binary_logloss: 0.325502\n",
      "[1377]\ttrain's auc: 0.840296\ttrain's binary_logloss: 0.325503\n",
      "[1378]\ttrain's auc: 0.840298\ttrain's binary_logloss: 0.325502\n",
      "[1379]\ttrain's auc: 0.840298\ttrain's binary_logloss: 0.325501\n",
      "[1380]\ttrain's auc: 0.840299\ttrain's binary_logloss: 0.325499\n",
      "[1381]\ttrain's auc: 0.840299\ttrain's binary_logloss: 0.325499\n",
      "[1382]\ttrain's auc: 0.840301\ttrain's binary_logloss: 0.325497\n",
      "[1383]\ttrain's auc: 0.840302\ttrain's binary_logloss: 0.325497\n",
      "[1384]\ttrain's auc: 0.840302\ttrain's binary_logloss: 0.325498\n",
      "[1385]\ttrain's auc: 0.840304\ttrain's binary_logloss: 0.325495\n",
      "[1386]\ttrain's auc: 0.840302\ttrain's binary_logloss: 0.325496\n",
      "[1387]\ttrain's auc: 0.840307\ttrain's binary_logloss: 0.325494\n",
      "[1388]\ttrain's auc: 0.840308\ttrain's binary_logloss: 0.325492\n",
      "[1389]\ttrain's auc: 0.840305\ttrain's binary_logloss: 0.325494\n",
      "[1390]\ttrain's auc: 0.840307\ttrain's binary_logloss: 0.325491\n",
      "[1391]\ttrain's auc: 0.840307\ttrain's binary_logloss: 0.325492\n",
      "[1392]\ttrain's auc: 0.840317\ttrain's binary_logloss: 0.325484\n",
      "[1393]\ttrain's auc: 0.840328\ttrain's binary_logloss: 0.325475\n",
      "[1394]\ttrain's auc: 0.840329\ttrain's binary_logloss: 0.325475\n",
      "[1395]\ttrain's auc: 0.840332\ttrain's binary_logloss: 0.325473\n",
      "[1396]\ttrain's auc: 0.840334\ttrain's binary_logloss: 0.325472\n",
      "[1397]\ttrain's auc: 0.840338\ttrain's binary_logloss: 0.325468\n",
      "[1398]\ttrain's auc: 0.840343\ttrain's binary_logloss: 0.325465\n",
      "[1399]\ttrain's auc: 0.840357\ttrain's binary_logloss: 0.325455\n",
      "[1400]\ttrain's auc: 0.840355\ttrain's binary_logloss: 0.325457\n",
      "[1401]\ttrain's auc: 0.840363\ttrain's binary_logloss: 0.32545\n",
      "[1402]\ttrain's auc: 0.840374\ttrain's binary_logloss: 0.325443\n",
      "[1403]\ttrain's auc: 0.840391\ttrain's binary_logloss: 0.325429\n",
      "[1404]\ttrain's auc: 0.840392\ttrain's binary_logloss: 0.325429\n",
      "[1405]\ttrain's auc: 0.84039\ttrain's binary_logloss: 0.325429\n",
      "[1406]\ttrain's auc: 0.840396\ttrain's binary_logloss: 0.325425\n",
      "[1407]\ttrain's auc: 0.840396\ttrain's binary_logloss: 0.325423\n",
      "[1408]\ttrain's auc: 0.840398\ttrain's binary_logloss: 0.325422\n",
      "[1409]\ttrain's auc: 0.840401\ttrain's binary_logloss: 0.325421\n",
      "[1410]\ttrain's auc: 0.8404\ttrain's binary_logloss: 0.325421\n",
      "[1411]\ttrain's auc: 0.8404\ttrain's binary_logloss: 0.325421\n",
      "[1412]\ttrain's auc: 0.8404\ttrain's binary_logloss: 0.32542\n",
      "[1413]\ttrain's auc: 0.840399\ttrain's binary_logloss: 0.325421\n",
      "[1414]\ttrain's auc: 0.8404\ttrain's binary_logloss: 0.325421\n",
      "[1415]\ttrain's auc: 0.840398\ttrain's binary_logloss: 0.325421\n",
      "[1416]\ttrain's auc: 0.840402\ttrain's binary_logloss: 0.325417\n",
      "[1417]\ttrain's auc: 0.840408\ttrain's binary_logloss: 0.325413\n",
      "[1418]\ttrain's auc: 0.840405\ttrain's binary_logloss: 0.325414\n",
      "[1419]\ttrain's auc: 0.840405\ttrain's binary_logloss: 0.325414\n",
      "[1420]\ttrain's auc: 0.840408\ttrain's binary_logloss: 0.325413\n",
      "[1421]\ttrain's auc: 0.840408\ttrain's binary_logloss: 0.325413\n",
      "[1422]\ttrain's auc: 0.840407\ttrain's binary_logloss: 0.325414\n",
      "[1423]\ttrain's auc: 0.840403\ttrain's binary_logloss: 0.325416\n",
      "[1424]\ttrain's auc: 0.840402\ttrain's binary_logloss: 0.325417\n",
      "[1425]\ttrain's auc: 0.840406\ttrain's binary_logloss: 0.325414\n",
      "[1426]\ttrain's auc: 0.840406\ttrain's binary_logloss: 0.325414\n",
      "[1427]\ttrain's auc: 0.84041\ttrain's binary_logloss: 0.325411\n",
      "[1428]\ttrain's auc: 0.84042\ttrain's binary_logloss: 0.325403\n",
      "[1429]\ttrain's auc: 0.840426\ttrain's binary_logloss: 0.325395\n",
      "[1430]\ttrain's auc: 0.840436\ttrain's binary_logloss: 0.325387\n",
      "[1431]\ttrain's auc: 0.840439\ttrain's binary_logloss: 0.325384\n",
      "[1432]\ttrain's auc: 0.840439\ttrain's binary_logloss: 0.325385\n",
      "[1433]\ttrain's auc: 0.840436\ttrain's binary_logloss: 0.325386\n",
      "[1434]\ttrain's auc: 0.840446\ttrain's binary_logloss: 0.325378\n",
      "[1435]\ttrain's auc: 0.840455\ttrain's binary_logloss: 0.325371\n",
      "[1436]\ttrain's auc: 0.840457\ttrain's binary_logloss: 0.325369\n",
      "[1437]\ttrain's auc: 0.840463\ttrain's binary_logloss: 0.325365\n",
      "[1438]\ttrain's auc: 0.840471\ttrain's binary_logloss: 0.325361\n",
      "[1439]\ttrain's auc: 0.840478\ttrain's binary_logloss: 0.325356\n",
      "[1440]\ttrain's auc: 0.840478\ttrain's binary_logloss: 0.325356\n",
      "[1441]\ttrain's auc: 0.840487\ttrain's binary_logloss: 0.325345\n",
      "[1442]\ttrain's auc: 0.840491\ttrain's binary_logloss: 0.32534\n",
      "[1443]\ttrain's auc: 0.840499\ttrain's binary_logloss: 0.325334\n",
      "[1444]\ttrain's auc: 0.840506\ttrain's binary_logloss: 0.325329\n",
      "[1445]\ttrain's auc: 0.840504\ttrain's binary_logloss: 0.325331\n",
      "[1446]\ttrain's auc: 0.840513\ttrain's binary_logloss: 0.325323\n",
      "[1447]\ttrain's auc: 0.840507\ttrain's binary_logloss: 0.325326\n",
      "[1448]\ttrain's auc: 0.840514\ttrain's binary_logloss: 0.325319\n",
      "[1449]\ttrain's auc: 0.840523\ttrain's binary_logloss: 0.325313\n",
      "[1450]\ttrain's auc: 0.840523\ttrain's binary_logloss: 0.325314\n",
      "[1451]\ttrain's auc: 0.840525\ttrain's binary_logloss: 0.325313\n",
      "[1452]\ttrain's auc: 0.840527\ttrain's binary_logloss: 0.325311\n",
      "[1453]\ttrain's auc: 0.840529\ttrain's binary_logloss: 0.325307\n",
      "[1454]\ttrain's auc: 0.840534\ttrain's binary_logloss: 0.325302\n",
      "[1455]\ttrain's auc: 0.840531\ttrain's binary_logloss: 0.325305\n",
      "[1456]\ttrain's auc: 0.840534\ttrain's binary_logloss: 0.325303\n",
      "[1457]\ttrain's auc: 0.840534\ttrain's binary_logloss: 0.325303\n",
      "[1458]\ttrain's auc: 0.840543\ttrain's binary_logloss: 0.325297\n",
      "[1459]\ttrain's auc: 0.840551\ttrain's binary_logloss: 0.325289\n",
      "[1460]\ttrain's auc: 0.840551\ttrain's binary_logloss: 0.325289\n",
      "[1461]\ttrain's auc: 0.840554\ttrain's binary_logloss: 0.325286\n",
      "[1462]\ttrain's auc: 0.84056\ttrain's binary_logloss: 0.32528\n",
      "[1463]\ttrain's auc: 0.84056\ttrain's binary_logloss: 0.32528\n",
      "[1464]\ttrain's auc: 0.840568\ttrain's binary_logloss: 0.325274\n",
      "[1465]\ttrain's auc: 0.840569\ttrain's binary_logloss: 0.325272\n",
      "[1466]\ttrain's auc: 0.84057\ttrain's binary_logloss: 0.325271\n",
      "[1467]\ttrain's auc: 0.840576\ttrain's binary_logloss: 0.325266\n",
      "[1468]\ttrain's auc: 0.840576\ttrain's binary_logloss: 0.325266\n",
      "[1469]\ttrain's auc: 0.840589\ttrain's binary_logloss: 0.325256\n",
      "[1470]\ttrain's auc: 0.840593\ttrain's binary_logloss: 0.325251\n",
      "[1471]\ttrain's auc: 0.840596\ttrain's binary_logloss: 0.325249\n",
      "[1472]\ttrain's auc: 0.840598\ttrain's binary_logloss: 0.325249\n",
      "[1473]\ttrain's auc: 0.840597\ttrain's binary_logloss: 0.325249\n",
      "[1474]\ttrain's auc: 0.840595\ttrain's binary_logloss: 0.325251\n",
      "[1475]\ttrain's auc: 0.840592\ttrain's binary_logloss: 0.325253\n",
      "[1476]\ttrain's auc: 0.840603\ttrain's binary_logloss: 0.325242\n",
      "[1477]\ttrain's auc: 0.840604\ttrain's binary_logloss: 0.325241\n",
      "[1478]\ttrain's auc: 0.840608\ttrain's binary_logloss: 0.325238\n",
      "[1479]\ttrain's auc: 0.840608\ttrain's binary_logloss: 0.325239\n",
      "[1480]\ttrain's auc: 0.840616\ttrain's binary_logloss: 0.325233\n",
      "[1481]\ttrain's auc: 0.84062\ttrain's binary_logloss: 0.32523\n",
      "[1482]\ttrain's auc: 0.840622\ttrain's binary_logloss: 0.325227\n",
      "[1483]\ttrain's auc: 0.840622\ttrain's binary_logloss: 0.325227\n",
      "[1484]\ttrain's auc: 0.840626\ttrain's binary_logloss: 0.325223\n",
      "[1485]\ttrain's auc: 0.840628\ttrain's binary_logloss: 0.325222\n",
      "[1486]\ttrain's auc: 0.840632\ttrain's binary_logloss: 0.32522\n",
      "[1487]\ttrain's auc: 0.840632\ttrain's binary_logloss: 0.325219\n",
      "[1488]\ttrain's auc: 0.840632\ttrain's binary_logloss: 0.32522\n",
      "[1489]\ttrain's auc: 0.840651\ttrain's binary_logloss: 0.325195\n",
      "[1490]\ttrain's auc: 0.840656\ttrain's binary_logloss: 0.325192\n",
      "[1491]\ttrain's auc: 0.840658\ttrain's binary_logloss: 0.32519\n",
      "[1492]\ttrain's auc: 0.840661\ttrain's binary_logloss: 0.325187\n",
      "[1493]\ttrain's auc: 0.840661\ttrain's binary_logloss: 0.325186\n",
      "[1494]\ttrain's auc: 0.840662\ttrain's binary_logloss: 0.325184\n",
      "[1495]\ttrain's auc: 0.840672\ttrain's binary_logloss: 0.325176\n",
      "[1496]\ttrain's auc: 0.840671\ttrain's binary_logloss: 0.325176\n",
      "[1497]\ttrain's auc: 0.840671\ttrain's binary_logloss: 0.325177\n",
      "[1498]\ttrain's auc: 0.840672\ttrain's binary_logloss: 0.325174\n",
      "[1499]\ttrain's auc: 0.840679\ttrain's binary_logloss: 0.32517\n",
      "[1500]\ttrain's auc: 0.840681\ttrain's binary_logloss: 0.325168\n",
      "[1501]\ttrain's auc: 0.8407\ttrain's binary_logloss: 0.325156\n",
      "[1502]\ttrain's auc: 0.840704\ttrain's binary_logloss: 0.325152\n",
      "[1503]\ttrain's auc: 0.840708\ttrain's binary_logloss: 0.325148\n",
      "[1504]\ttrain's auc: 0.840713\ttrain's binary_logloss: 0.325143\n",
      "[1505]\ttrain's auc: 0.840713\ttrain's binary_logloss: 0.325143\n",
      "[1506]\ttrain's auc: 0.84072\ttrain's binary_logloss: 0.325137\n",
      "[1507]\ttrain's auc: 0.840723\ttrain's binary_logloss: 0.325134\n",
      "[1508]\ttrain's auc: 0.840729\ttrain's binary_logloss: 0.325127\n",
      "[1509]\ttrain's auc: 0.840748\ttrain's binary_logloss: 0.325114\n",
      "[1510]\ttrain's auc: 0.840755\ttrain's binary_logloss: 0.32511\n",
      "[1511]\ttrain's auc: 0.840759\ttrain's binary_logloss: 0.325107\n",
      "[1512]\ttrain's auc: 0.840767\ttrain's binary_logloss: 0.3251\n",
      "[1513]\ttrain's auc: 0.840774\ttrain's binary_logloss: 0.325095\n",
      "[1514]\ttrain's auc: 0.840778\ttrain's binary_logloss: 0.325092\n",
      "[1515]\ttrain's auc: 0.840785\ttrain's binary_logloss: 0.325088\n",
      "[1516]\ttrain's auc: 0.840789\ttrain's binary_logloss: 0.325085\n",
      "[1517]\ttrain's auc: 0.840796\ttrain's binary_logloss: 0.325078\n",
      "[1518]\ttrain's auc: 0.840799\ttrain's binary_logloss: 0.325074\n",
      "[1519]\ttrain's auc: 0.840804\ttrain's binary_logloss: 0.325069\n",
      "[1520]\ttrain's auc: 0.840816\ttrain's binary_logloss: 0.325052\n",
      "[1521]\ttrain's auc: 0.840822\ttrain's binary_logloss: 0.325049\n",
      "[1522]\ttrain's auc: 0.840825\ttrain's binary_logloss: 0.325044\n",
      "[1523]\ttrain's auc: 0.840843\ttrain's binary_logloss: 0.32503\n",
      "[1524]\ttrain's auc: 0.840863\ttrain's binary_logloss: 0.325013\n",
      "[1525]\ttrain's auc: 0.840866\ttrain's binary_logloss: 0.325011\n",
      "[1526]\ttrain's auc: 0.840861\ttrain's binary_logloss: 0.325013\n",
      "[1527]\ttrain's auc: 0.84086\ttrain's binary_logloss: 0.325014\n",
      "[1528]\ttrain's auc: 0.840866\ttrain's binary_logloss: 0.325011\n",
      "[1529]\ttrain's auc: 0.840873\ttrain's binary_logloss: 0.325004\n",
      "[1530]\ttrain's auc: 0.840875\ttrain's binary_logloss: 0.325003\n",
      "[1531]\ttrain's auc: 0.840878\ttrain's binary_logloss: 0.325001\n",
      "[1532]\ttrain's auc: 0.840886\ttrain's binary_logloss: 0.324995\n",
      "[1533]\ttrain's auc: 0.840886\ttrain's binary_logloss: 0.324997\n",
      "[1534]\ttrain's auc: 0.840882\ttrain's binary_logloss: 0.324999\n",
      "[1535]\ttrain's auc: 0.840884\ttrain's binary_logloss: 0.324997\n",
      "[1536]\ttrain's auc: 0.840883\ttrain's binary_logloss: 0.324998\n",
      "[1537]\ttrain's auc: 0.840887\ttrain's binary_logloss: 0.324995\n",
      "[1538]\ttrain's auc: 0.840892\ttrain's binary_logloss: 0.324991\n",
      "[1539]\ttrain's auc: 0.840891\ttrain's binary_logloss: 0.324991\n",
      "[1540]\ttrain's auc: 0.840898\ttrain's binary_logloss: 0.324987\n",
      "[1541]\ttrain's auc: 0.840897\ttrain's binary_logloss: 0.324988\n",
      "[1542]\ttrain's auc: 0.840894\ttrain's binary_logloss: 0.32499\n",
      "[1543]\ttrain's auc: 0.840904\ttrain's binary_logloss: 0.324983\n",
      "[1544]\ttrain's auc: 0.840902\ttrain's binary_logloss: 0.324983\n",
      "[1545]\ttrain's auc: 0.840903\ttrain's binary_logloss: 0.324982\n",
      "[1546]\ttrain's auc: 0.840902\ttrain's binary_logloss: 0.324983\n",
      "[1547]\ttrain's auc: 0.840903\ttrain's binary_logloss: 0.324981\n",
      "[1548]\ttrain's auc: 0.840905\ttrain's binary_logloss: 0.32498\n",
      "[1549]\ttrain's auc: 0.840902\ttrain's binary_logloss: 0.324982\n",
      "[1550]\ttrain's auc: 0.840903\ttrain's binary_logloss: 0.324981\n",
      "[1551]\ttrain's auc: 0.840907\ttrain's binary_logloss: 0.324978\n",
      "[1552]\ttrain's auc: 0.840916\ttrain's binary_logloss: 0.324971\n",
      "[1553]\ttrain's auc: 0.840918\ttrain's binary_logloss: 0.324969\n",
      "[1554]\ttrain's auc: 0.84092\ttrain's binary_logloss: 0.324967\n",
      "[1555]\ttrain's auc: 0.840932\ttrain's binary_logloss: 0.324959\n",
      "[1556]\ttrain's auc: 0.840933\ttrain's binary_logloss: 0.324958\n",
      "[1557]\ttrain's auc: 0.84094\ttrain's binary_logloss: 0.324953\n",
      "[1558]\ttrain's auc: 0.840968\ttrain's binary_logloss: 0.324934\n",
      "[1559]\ttrain's auc: 0.840969\ttrain's binary_logloss: 0.324933\n",
      "[1560]\ttrain's auc: 0.840971\ttrain's binary_logloss: 0.324932\n",
      "[1561]\ttrain's auc: 0.84097\ttrain's binary_logloss: 0.324934\n",
      "[1562]\ttrain's auc: 0.840969\ttrain's binary_logloss: 0.324934\n",
      "[1563]\ttrain's auc: 0.840969\ttrain's binary_logloss: 0.324932\n",
      "[1564]\ttrain's auc: 0.840966\ttrain's binary_logloss: 0.324934\n",
      "[1565]\ttrain's auc: 0.840972\ttrain's binary_logloss: 0.324928\n",
      "[1566]\ttrain's auc: 0.840972\ttrain's binary_logloss: 0.324927\n",
      "[1567]\ttrain's auc: 0.840976\ttrain's binary_logloss: 0.324922\n",
      "[1568]\ttrain's auc: 0.840978\ttrain's binary_logloss: 0.324918\n",
      "[1569]\ttrain's auc: 0.840978\ttrain's binary_logloss: 0.324919\n",
      "[1570]\ttrain's auc: 0.840982\ttrain's binary_logloss: 0.324916\n",
      "[1571]\ttrain's auc: 0.840982\ttrain's binary_logloss: 0.324915\n",
      "[1572]\ttrain's auc: 0.840986\ttrain's binary_logloss: 0.324913\n",
      "[1573]\ttrain's auc: 0.840994\ttrain's binary_logloss: 0.324906\n",
      "[1574]\ttrain's auc: 0.841\ttrain's binary_logloss: 0.324901\n",
      "[1575]\ttrain's auc: 0.840999\ttrain's binary_logloss: 0.324902\n",
      "[1576]\ttrain's auc: 0.841005\ttrain's binary_logloss: 0.324898\n",
      "[1577]\ttrain's auc: 0.841005\ttrain's binary_logloss: 0.324898\n",
      "[1578]\ttrain's auc: 0.841003\ttrain's binary_logloss: 0.324899\n",
      "[1579]\ttrain's auc: 0.841004\ttrain's binary_logloss: 0.324898\n",
      "[1580]\ttrain's auc: 0.841003\ttrain's binary_logloss: 0.324899\n",
      "[1581]\ttrain's auc: 0.841006\ttrain's binary_logloss: 0.324897\n",
      "[1582]\ttrain's auc: 0.84101\ttrain's binary_logloss: 0.324893\n",
      "[1583]\ttrain's auc: 0.841015\ttrain's binary_logloss: 0.324889\n",
      "[1584]\ttrain's auc: 0.841031\ttrain's binary_logloss: 0.324878\n",
      "[1585]\ttrain's auc: 0.841042\ttrain's binary_logloss: 0.324865\n",
      "[1586]\ttrain's auc: 0.841054\ttrain's binary_logloss: 0.324858\n",
      "[1587]\ttrain's auc: 0.841055\ttrain's binary_logloss: 0.324857\n",
      "[1588]\ttrain's auc: 0.84107\ttrain's binary_logloss: 0.324844\n",
      "[1589]\ttrain's auc: 0.841076\ttrain's binary_logloss: 0.324837\n",
      "[1590]\ttrain's auc: 0.841074\ttrain's binary_logloss: 0.324838\n",
      "[1591]\ttrain's auc: 0.841075\ttrain's binary_logloss: 0.324837\n",
      "[1592]\ttrain's auc: 0.841082\ttrain's binary_logloss: 0.324831\n",
      "[1593]\ttrain's auc: 0.841082\ttrain's binary_logloss: 0.324831\n",
      "[1594]\ttrain's auc: 0.841085\ttrain's binary_logloss: 0.324829\n",
      "[1595]\ttrain's auc: 0.841086\ttrain's binary_logloss: 0.324828\n",
      "[1596]\ttrain's auc: 0.841085\ttrain's binary_logloss: 0.32483\n",
      "[1597]\ttrain's auc: 0.841089\ttrain's binary_logloss: 0.324826\n",
      "[1598]\ttrain's auc: 0.84109\ttrain's binary_logloss: 0.324825\n",
      "[1599]\ttrain's auc: 0.841091\ttrain's binary_logloss: 0.324823\n",
      "[1600]\ttrain's auc: 0.841089\ttrain's binary_logloss: 0.324825\n",
      "[1601]\ttrain's auc: 0.841091\ttrain's binary_logloss: 0.324822\n",
      "[1602]\ttrain's auc: 0.841091\ttrain's binary_logloss: 0.324822\n",
      "[1603]\ttrain's auc: 0.841092\ttrain's binary_logloss: 0.324821\n",
      "[1604]\ttrain's auc: 0.841091\ttrain's binary_logloss: 0.324819\n",
      "[1605]\ttrain's auc: 0.841094\ttrain's binary_logloss: 0.324816\n",
      "[1606]\ttrain's auc: 0.841095\ttrain's binary_logloss: 0.324815\n",
      "[1607]\ttrain's auc: 0.841094\ttrain's binary_logloss: 0.324814\n",
      "[1608]\ttrain's auc: 0.841099\ttrain's binary_logloss: 0.32481\n",
      "[1609]\ttrain's auc: 0.841104\ttrain's binary_logloss: 0.324807\n",
      "[1610]\ttrain's auc: 0.84112\ttrain's binary_logloss: 0.324791\n",
      "[1611]\ttrain's auc: 0.841136\ttrain's binary_logloss: 0.324778\n",
      "[1612]\ttrain's auc: 0.841139\ttrain's binary_logloss: 0.324776\n",
      "[1613]\ttrain's auc: 0.841135\ttrain's binary_logloss: 0.324778\n",
      "[1614]\ttrain's auc: 0.84114\ttrain's binary_logloss: 0.324774\n",
      "[1615]\ttrain's auc: 0.841142\ttrain's binary_logloss: 0.324772\n",
      "[1616]\ttrain's auc: 0.841163\ttrain's binary_logloss: 0.324751\n",
      "[1617]\ttrain's auc: 0.841173\ttrain's binary_logloss: 0.324744\n",
      "[1618]\ttrain's auc: 0.841181\ttrain's binary_logloss: 0.324738\n",
      "[1619]\ttrain's auc: 0.841189\ttrain's binary_logloss: 0.324732\n",
      "[1620]\ttrain's auc: 0.841198\ttrain's binary_logloss: 0.324723\n",
      "[1621]\ttrain's auc: 0.841203\ttrain's binary_logloss: 0.324719\n",
      "[1622]\ttrain's auc: 0.841206\ttrain's binary_logloss: 0.324718\n",
      "[1623]\ttrain's auc: 0.841203\ttrain's binary_logloss: 0.324719\n",
      "[1624]\ttrain's auc: 0.841211\ttrain's binary_logloss: 0.324714\n",
      "[1625]\ttrain's auc: 0.841211\ttrain's binary_logloss: 0.324715\n",
      "[1626]\ttrain's auc: 0.841214\ttrain's binary_logloss: 0.324714\n",
      "[1627]\ttrain's auc: 0.841214\ttrain's binary_logloss: 0.324714\n",
      "[1628]\ttrain's auc: 0.841231\ttrain's binary_logloss: 0.324703\n",
      "[1629]\ttrain's auc: 0.841236\ttrain's binary_logloss: 0.324699\n",
      "[1630]\ttrain's auc: 0.841237\ttrain's binary_logloss: 0.324698\n",
      "[1631]\ttrain's auc: 0.841238\ttrain's binary_logloss: 0.324697\n",
      "[1632]\ttrain's auc: 0.841237\ttrain's binary_logloss: 0.324697\n",
      "[1633]\ttrain's auc: 0.841239\ttrain's binary_logloss: 0.324697\n",
      "[1634]\ttrain's auc: 0.841246\ttrain's binary_logloss: 0.324691\n",
      "[1635]\ttrain's auc: 0.841244\ttrain's binary_logloss: 0.324693\n",
      "[1636]\ttrain's auc: 0.841247\ttrain's binary_logloss: 0.32469\n",
      "[1637]\ttrain's auc: 0.841251\ttrain's binary_logloss: 0.324687\n",
      "[1638]\ttrain's auc: 0.84125\ttrain's binary_logloss: 0.324687\n",
      "[1639]\ttrain's auc: 0.841256\ttrain's binary_logloss: 0.324683\n",
      "[1640]\ttrain's auc: 0.841255\ttrain's binary_logloss: 0.324684\n",
      "[1641]\ttrain's auc: 0.841254\ttrain's binary_logloss: 0.324684\n",
      "[1642]\ttrain's auc: 0.841252\ttrain's binary_logloss: 0.324685\n",
      "[1643]\ttrain's auc: 0.841253\ttrain's binary_logloss: 0.324681\n",
      "[1644]\ttrain's auc: 0.841258\ttrain's binary_logloss: 0.324677\n",
      "[1645]\ttrain's auc: 0.841269\ttrain's binary_logloss: 0.324668\n",
      "[1646]\ttrain's auc: 0.841266\ttrain's binary_logloss: 0.324669\n",
      "[1647]\ttrain's auc: 0.841269\ttrain's binary_logloss: 0.324667\n",
      "[1648]\ttrain's auc: 0.841268\ttrain's binary_logloss: 0.324668\n",
      "[1649]\ttrain's auc: 0.841268\ttrain's binary_logloss: 0.324669\n",
      "[1650]\ttrain's auc: 0.841268\ttrain's binary_logloss: 0.32467\n",
      "[1651]\ttrain's auc: 0.841268\ttrain's binary_logloss: 0.32467\n",
      "[1652]\ttrain's auc: 0.841268\ttrain's binary_logloss: 0.324671\n",
      "[1653]\ttrain's auc: 0.841267\ttrain's binary_logloss: 0.324671\n",
      "[1654]\ttrain's auc: 0.841266\ttrain's binary_logloss: 0.324673\n",
      "[1655]\ttrain's auc: 0.841269\ttrain's binary_logloss: 0.32467\n",
      "[1656]\ttrain's auc: 0.841272\ttrain's binary_logloss: 0.324668\n",
      "[1657]\ttrain's auc: 0.841279\ttrain's binary_logloss: 0.324661\n",
      "[1658]\ttrain's auc: 0.841282\ttrain's binary_logloss: 0.324658\n",
      "[1659]\ttrain's auc: 0.84128\ttrain's binary_logloss: 0.32466\n",
      "[1660]\ttrain's auc: 0.841279\ttrain's binary_logloss: 0.324661\n",
      "[1661]\ttrain's auc: 0.841289\ttrain's binary_logloss: 0.324654\n",
      "[1662]\ttrain's auc: 0.841292\ttrain's binary_logloss: 0.324652\n",
      "[1663]\ttrain's auc: 0.84129\ttrain's binary_logloss: 0.324653\n",
      "[1664]\ttrain's auc: 0.84129\ttrain's binary_logloss: 0.324653\n",
      "[1665]\ttrain's auc: 0.841287\ttrain's binary_logloss: 0.324654\n",
      "[1666]\ttrain's auc: 0.841293\ttrain's binary_logloss: 0.324646\n",
      "[1667]\ttrain's auc: 0.841294\ttrain's binary_logloss: 0.324646\n",
      "[1668]\ttrain's auc: 0.841293\ttrain's binary_logloss: 0.324645\n",
      "[1669]\ttrain's auc: 0.841293\ttrain's binary_logloss: 0.324646\n",
      "[1670]\ttrain's auc: 0.841292\ttrain's binary_logloss: 0.324646\n",
      "[1671]\ttrain's auc: 0.841291\ttrain's binary_logloss: 0.324647\n",
      "[1672]\ttrain's auc: 0.84129\ttrain's binary_logloss: 0.324647\n",
      "[1673]\ttrain's auc: 0.841289\ttrain's binary_logloss: 0.324648\n",
      "[1674]\ttrain's auc: 0.841286\ttrain's binary_logloss: 0.32465\n",
      "[1675]\ttrain's auc: 0.841291\ttrain's binary_logloss: 0.324647\n",
      "[1676]\ttrain's auc: 0.841301\ttrain's binary_logloss: 0.324641\n",
      "[1677]\ttrain's auc: 0.841306\ttrain's binary_logloss: 0.324637\n",
      "[1678]\ttrain's auc: 0.841319\ttrain's binary_logloss: 0.324627\n",
      "[1679]\ttrain's auc: 0.841323\ttrain's binary_logloss: 0.324622\n",
      "[1680]\ttrain's auc: 0.841325\ttrain's binary_logloss: 0.324621\n",
      "[1681]\ttrain's auc: 0.841323\ttrain's binary_logloss: 0.324623\n",
      "[1682]\ttrain's auc: 0.841331\ttrain's binary_logloss: 0.324616\n",
      "[1683]\ttrain's auc: 0.841334\ttrain's binary_logloss: 0.324614\n",
      "[1684]\ttrain's auc: 0.841338\ttrain's binary_logloss: 0.324611\n",
      "[1685]\ttrain's auc: 0.841341\ttrain's binary_logloss: 0.32461\n",
      "[1686]\ttrain's auc: 0.841341\ttrain's binary_logloss: 0.32461\n",
      "[1687]\ttrain's auc: 0.841338\ttrain's binary_logloss: 0.324611\n",
      "[1688]\ttrain's auc: 0.841344\ttrain's binary_logloss: 0.324606\n",
      "[1689]\ttrain's auc: 0.841348\ttrain's binary_logloss: 0.324603\n",
      "[1690]\ttrain's auc: 0.841347\ttrain's binary_logloss: 0.324603\n",
      "[1691]\ttrain's auc: 0.841351\ttrain's binary_logloss: 0.324599\n",
      "[1692]\ttrain's auc: 0.841354\ttrain's binary_logloss: 0.324598\n",
      "[1693]\ttrain's auc: 0.841367\ttrain's binary_logloss: 0.324589\n",
      "[1694]\ttrain's auc: 0.841374\ttrain's binary_logloss: 0.324583\n",
      "[1695]\ttrain's auc: 0.841375\ttrain's binary_logloss: 0.324582\n",
      "[1696]\ttrain's auc: 0.841383\ttrain's binary_logloss: 0.324577\n",
      "[1697]\ttrain's auc: 0.841387\ttrain's binary_logloss: 0.324575\n",
      "[1698]\ttrain's auc: 0.84139\ttrain's binary_logloss: 0.324573\n",
      "[1699]\ttrain's auc: 0.84139\ttrain's binary_logloss: 0.324573\n",
      "[1700]\ttrain's auc: 0.841399\ttrain's binary_logloss: 0.324567\n",
      "[1701]\ttrain's auc: 0.841404\ttrain's binary_logloss: 0.324562\n",
      "[1702]\ttrain's auc: 0.841412\ttrain's binary_logloss: 0.324557\n",
      "[1703]\ttrain's auc: 0.841413\ttrain's binary_logloss: 0.324558\n",
      "[1704]\ttrain's auc: 0.841419\ttrain's binary_logloss: 0.324554\n",
      "[1705]\ttrain's auc: 0.84142\ttrain's binary_logloss: 0.324552\n",
      "[1706]\ttrain's auc: 0.841422\ttrain's binary_logloss: 0.324551\n",
      "[1707]\ttrain's auc: 0.841427\ttrain's binary_logloss: 0.324546\n",
      "[1708]\ttrain's auc: 0.841428\ttrain's binary_logloss: 0.324546\n",
      "[1709]\ttrain's auc: 0.841429\ttrain's binary_logloss: 0.324544\n",
      "[1710]\ttrain's auc: 0.84143\ttrain's binary_logloss: 0.324544\n",
      "[1711]\ttrain's auc: 0.84143\ttrain's binary_logloss: 0.324545\n",
      "[1712]\ttrain's auc: 0.841428\ttrain's binary_logloss: 0.324547\n",
      "[1713]\ttrain's auc: 0.84143\ttrain's binary_logloss: 0.324544\n",
      "[1714]\ttrain's auc: 0.841432\ttrain's binary_logloss: 0.324543\n",
      "[1715]\ttrain's auc: 0.841435\ttrain's binary_logloss: 0.324541\n",
      "[1716]\ttrain's auc: 0.841433\ttrain's binary_logloss: 0.324543\n",
      "[1717]\ttrain's auc: 0.841427\ttrain's binary_logloss: 0.324548\n",
      "[1718]\ttrain's auc: 0.841434\ttrain's binary_logloss: 0.324542\n",
      "[1719]\ttrain's auc: 0.841437\ttrain's binary_logloss: 0.32454\n",
      "[1720]\ttrain's auc: 0.841442\ttrain's binary_logloss: 0.324537\n",
      "[1721]\ttrain's auc: 0.841443\ttrain's binary_logloss: 0.324536\n",
      "[1722]\ttrain's auc: 0.841441\ttrain's binary_logloss: 0.324538\n",
      "[1723]\ttrain's auc: 0.841443\ttrain's binary_logloss: 0.324537\n",
      "[1724]\ttrain's auc: 0.841444\ttrain's binary_logloss: 0.324537\n",
      "[1725]\ttrain's auc: 0.841448\ttrain's binary_logloss: 0.324533\n",
      "[1726]\ttrain's auc: 0.841452\ttrain's binary_logloss: 0.324528\n",
      "[1727]\ttrain's auc: 0.841453\ttrain's binary_logloss: 0.324529\n",
      "[1728]\ttrain's auc: 0.841452\ttrain's binary_logloss: 0.324529\n",
      "[1729]\ttrain's auc: 0.841459\ttrain's binary_logloss: 0.324525\n",
      "[1730]\ttrain's auc: 0.841464\ttrain's binary_logloss: 0.32452\n",
      "[1731]\ttrain's auc: 0.841463\ttrain's binary_logloss: 0.324521\n",
      "[1732]\ttrain's auc: 0.841464\ttrain's binary_logloss: 0.32452\n",
      "[1733]\ttrain's auc: 0.841465\ttrain's binary_logloss: 0.324519\n",
      "[1734]\ttrain's auc: 0.841464\ttrain's binary_logloss: 0.324519\n",
      "[1735]\ttrain's auc: 0.841462\ttrain's binary_logloss: 0.324521\n",
      "[1736]\ttrain's auc: 0.841464\ttrain's binary_logloss: 0.32452\n",
      "[1737]\ttrain's auc: 0.841464\ttrain's binary_logloss: 0.32452\n",
      "[1738]\ttrain's auc: 0.841464\ttrain's binary_logloss: 0.324519\n",
      "[1739]\ttrain's auc: 0.841465\ttrain's binary_logloss: 0.324517\n",
      "[1740]\ttrain's auc: 0.841461\ttrain's binary_logloss: 0.324521\n",
      "[1741]\ttrain's auc: 0.841466\ttrain's binary_logloss: 0.324517\n",
      "[1742]\ttrain's auc: 0.84146\ttrain's binary_logloss: 0.324521\n",
      "[1743]\ttrain's auc: 0.841467\ttrain's binary_logloss: 0.324516\n",
      "[1744]\ttrain's auc: 0.841467\ttrain's binary_logloss: 0.324516\n",
      "[1745]\ttrain's auc: 0.841467\ttrain's binary_logloss: 0.324516\n",
      "[1746]\ttrain's auc: 0.84147\ttrain's binary_logloss: 0.324513\n",
      "[1747]\ttrain's auc: 0.84147\ttrain's binary_logloss: 0.324511\n",
      "[1748]\ttrain's auc: 0.841483\ttrain's binary_logloss: 0.324502\n",
      "[1749]\ttrain's auc: 0.841486\ttrain's binary_logloss: 0.324497\n",
      "[1750]\ttrain's auc: 0.841485\ttrain's binary_logloss: 0.324498\n",
      "[1751]\ttrain's auc: 0.841484\ttrain's binary_logloss: 0.324498\n",
      "[1752]\ttrain's auc: 0.841483\ttrain's binary_logloss: 0.3245\n",
      "[1753]\ttrain's auc: 0.841482\ttrain's binary_logloss: 0.324498\n",
      "[1754]\ttrain's auc: 0.841484\ttrain's binary_logloss: 0.324497\n",
      "[1755]\ttrain's auc: 0.841487\ttrain's binary_logloss: 0.324494\n",
      "[1756]\ttrain's auc: 0.841501\ttrain's binary_logloss: 0.324484\n",
      "[1757]\ttrain's auc: 0.841505\ttrain's binary_logloss: 0.324481\n",
      "[1758]\ttrain's auc: 0.841507\ttrain's binary_logloss: 0.32448\n",
      "[1759]\ttrain's auc: 0.841515\ttrain's binary_logloss: 0.324471\n",
      "[1760]\ttrain's auc: 0.841514\ttrain's binary_logloss: 0.324472\n",
      "[1761]\ttrain's auc: 0.841516\ttrain's binary_logloss: 0.324471\n",
      "[1762]\ttrain's auc: 0.841515\ttrain's binary_logloss: 0.324472\n",
      "[1763]\ttrain's auc: 0.84152\ttrain's binary_logloss: 0.324467\n",
      "[1764]\ttrain's auc: 0.841525\ttrain's binary_logloss: 0.324461\n",
      "[1765]\ttrain's auc: 0.841525\ttrain's binary_logloss: 0.324461\n",
      "[1766]\ttrain's auc: 0.84153\ttrain's binary_logloss: 0.324456\n",
      "[1767]\ttrain's auc: 0.841531\ttrain's binary_logloss: 0.324456\n",
      "[1768]\ttrain's auc: 0.841531\ttrain's binary_logloss: 0.324456\n",
      "[1769]\ttrain's auc: 0.841532\ttrain's binary_logloss: 0.324455\n",
      "[1770]\ttrain's auc: 0.841536\ttrain's binary_logloss: 0.324453\n",
      "[1771]\ttrain's auc: 0.841535\ttrain's binary_logloss: 0.324454\n",
      "[1772]\ttrain's auc: 0.841536\ttrain's binary_logloss: 0.324452\n",
      "[1773]\ttrain's auc: 0.841537\ttrain's binary_logloss: 0.324452\n",
      "[1774]\ttrain's auc: 0.841541\ttrain's binary_logloss: 0.324449\n",
      "[1775]\ttrain's auc: 0.84156\ttrain's binary_logloss: 0.324433\n",
      "[1776]\ttrain's auc: 0.841563\ttrain's binary_logloss: 0.324431\n",
      "[1777]\ttrain's auc: 0.841566\ttrain's binary_logloss: 0.324428\n",
      "[1778]\ttrain's auc: 0.841567\ttrain's binary_logloss: 0.324428\n",
      "[1779]\ttrain's auc: 0.841566\ttrain's binary_logloss: 0.324429\n",
      "[1780]\ttrain's auc: 0.841564\ttrain's binary_logloss: 0.324431\n",
      "[1781]\ttrain's auc: 0.841565\ttrain's binary_logloss: 0.324431\n",
      "[1782]\ttrain's auc: 0.841557\ttrain's binary_logloss: 0.324436\n",
      "[1783]\ttrain's auc: 0.841558\ttrain's binary_logloss: 0.324435\n",
      "[1784]\ttrain's auc: 0.841555\ttrain's binary_logloss: 0.324439\n",
      "[1785]\ttrain's auc: 0.841555\ttrain's binary_logloss: 0.324438\n",
      "[1786]\ttrain's auc: 0.84156\ttrain's binary_logloss: 0.324435\n",
      "[1787]\ttrain's auc: 0.84156\ttrain's binary_logloss: 0.324435\n",
      "[1788]\ttrain's auc: 0.841568\ttrain's binary_logloss: 0.32443\n",
      "[1789]\ttrain's auc: 0.841572\ttrain's binary_logloss: 0.324426\n",
      "[1790]\ttrain's auc: 0.841574\ttrain's binary_logloss: 0.324424\n",
      "[1791]\ttrain's auc: 0.841577\ttrain's binary_logloss: 0.324423\n",
      "[1792]\ttrain's auc: 0.841577\ttrain's binary_logloss: 0.324422\n",
      "[1793]\ttrain's auc: 0.841576\ttrain's binary_logloss: 0.324423\n",
      "[1794]\ttrain's auc: 0.841575\ttrain's binary_logloss: 0.324424\n",
      "[1795]\ttrain's auc: 0.84157\ttrain's binary_logloss: 0.324426\n",
      "[1796]\ttrain's auc: 0.841575\ttrain's binary_logloss: 0.324423\n",
      "[1797]\ttrain's auc: 0.841574\ttrain's binary_logloss: 0.324422\n",
      "[1798]\ttrain's auc: 0.841574\ttrain's binary_logloss: 0.324423\n",
      "[1799]\ttrain's auc: 0.841577\ttrain's binary_logloss: 0.324421\n",
      "[1800]\ttrain's auc: 0.841577\ttrain's binary_logloss: 0.324421\n",
      "[1801]\ttrain's auc: 0.841581\ttrain's binary_logloss: 0.324418\n",
      "[1802]\ttrain's auc: 0.841583\ttrain's binary_logloss: 0.324418\n",
      "[1803]\ttrain's auc: 0.841583\ttrain's binary_logloss: 0.324417\n",
      "[1804]\ttrain's auc: 0.841588\ttrain's binary_logloss: 0.324413\n",
      "[1805]\ttrain's auc: 0.841588\ttrain's binary_logloss: 0.324413\n",
      "[1806]\ttrain's auc: 0.8416\ttrain's binary_logloss: 0.324405\n",
      "[1807]\ttrain's auc: 0.841607\ttrain's binary_logloss: 0.324399\n",
      "[1808]\ttrain's auc: 0.841604\ttrain's binary_logloss: 0.324402\n",
      "[1809]\ttrain's auc: 0.84161\ttrain's binary_logloss: 0.324399\n",
      "[1810]\ttrain's auc: 0.841612\ttrain's binary_logloss: 0.324397\n",
      "[1811]\ttrain's auc: 0.841637\ttrain's binary_logloss: 0.324372\n",
      "[1812]\ttrain's auc: 0.841641\ttrain's binary_logloss: 0.32437\n",
      "[1813]\ttrain's auc: 0.841649\ttrain's binary_logloss: 0.324364\n",
      "[1814]\ttrain's auc: 0.841653\ttrain's binary_logloss: 0.324362\n",
      "[1815]\ttrain's auc: 0.841653\ttrain's binary_logloss: 0.324361\n",
      "[1816]\ttrain's auc: 0.841647\ttrain's binary_logloss: 0.324365\n",
      "[1817]\ttrain's auc: 0.841648\ttrain's binary_logloss: 0.324364\n",
      "[1818]\ttrain's auc: 0.841648\ttrain's binary_logloss: 0.324365\n",
      "[1819]\ttrain's auc: 0.841649\ttrain's binary_logloss: 0.324365\n",
      "[1820]\ttrain's auc: 0.841649\ttrain's binary_logloss: 0.324365\n",
      "[1821]\ttrain's auc: 0.841649\ttrain's binary_logloss: 0.324365\n",
      "[1822]\ttrain's auc: 0.84165\ttrain's binary_logloss: 0.324364\n",
      "[1823]\ttrain's auc: 0.841647\ttrain's binary_logloss: 0.324365\n",
      "[1824]\ttrain's auc: 0.841645\ttrain's binary_logloss: 0.324366\n",
      "[1825]\ttrain's auc: 0.841642\ttrain's binary_logloss: 0.324369\n",
      "[1826]\ttrain's auc: 0.841643\ttrain's binary_logloss: 0.324367\n",
      "[1827]\ttrain's auc: 0.841646\ttrain's binary_logloss: 0.324365\n",
      "[1828]\ttrain's auc: 0.841653\ttrain's binary_logloss: 0.324359\n",
      "[1829]\ttrain's auc: 0.841654\ttrain's binary_logloss: 0.324357\n",
      "[1830]\ttrain's auc: 0.841652\ttrain's binary_logloss: 0.324359\n",
      "[1831]\ttrain's auc: 0.841652\ttrain's binary_logloss: 0.324356\n",
      "[1832]\ttrain's auc: 0.841655\ttrain's binary_logloss: 0.324354\n",
      "[1833]\ttrain's auc: 0.841655\ttrain's binary_logloss: 0.324354\n",
      "[1834]\ttrain's auc: 0.841661\ttrain's binary_logloss: 0.324349\n",
      "[1835]\ttrain's auc: 0.841657\ttrain's binary_logloss: 0.32435\n",
      "[1836]\ttrain's auc: 0.841663\ttrain's binary_logloss: 0.324346\n",
      "[1837]\ttrain's auc: 0.841661\ttrain's binary_logloss: 0.324348\n",
      "[1838]\ttrain's auc: 0.841657\ttrain's binary_logloss: 0.324351\n",
      "[1839]\ttrain's auc: 0.841658\ttrain's binary_logloss: 0.324351\n",
      "[1840]\ttrain's auc: 0.84166\ttrain's binary_logloss: 0.324349\n",
      "[1841]\ttrain's auc: 0.841664\ttrain's binary_logloss: 0.324345\n",
      "[1842]\ttrain's auc: 0.841666\ttrain's binary_logloss: 0.324343\n",
      "[1843]\ttrain's auc: 0.841665\ttrain's binary_logloss: 0.324343\n",
      "[1844]\ttrain's auc: 0.841666\ttrain's binary_logloss: 0.324343\n",
      "[1845]\ttrain's auc: 0.841665\ttrain's binary_logloss: 0.324343\n",
      "[1846]\ttrain's auc: 0.841663\ttrain's binary_logloss: 0.324344\n",
      "[1847]\ttrain's auc: 0.841659\ttrain's binary_logloss: 0.324346\n",
      "[1848]\ttrain's auc: 0.841659\ttrain's binary_logloss: 0.324346\n",
      "[1849]\ttrain's auc: 0.841658\ttrain's binary_logloss: 0.324346\n",
      "[1850]\ttrain's auc: 0.841656\ttrain's binary_logloss: 0.324346\n",
      "[1851]\ttrain's auc: 0.841664\ttrain's binary_logloss: 0.32434\n",
      "[1852]\ttrain's auc: 0.841664\ttrain's binary_logloss: 0.324339\n",
      "[1853]\ttrain's auc: 0.841665\ttrain's binary_logloss: 0.324338\n",
      "[1854]\ttrain's auc: 0.841672\ttrain's binary_logloss: 0.324332\n",
      "[1855]\ttrain's auc: 0.841678\ttrain's binary_logloss: 0.324327\n",
      "[1856]\ttrain's auc: 0.841677\ttrain's binary_logloss: 0.324328\n",
      "[1857]\ttrain's auc: 0.841677\ttrain's binary_logloss: 0.324329\n",
      "[1858]\ttrain's auc: 0.841683\ttrain's binary_logloss: 0.324327\n",
      "[1859]\ttrain's auc: 0.841686\ttrain's binary_logloss: 0.324323\n",
      "[1860]\ttrain's auc: 0.841699\ttrain's binary_logloss: 0.324315\n",
      "[1861]\ttrain's auc: 0.8417\ttrain's binary_logloss: 0.324313\n",
      "[1862]\ttrain's auc: 0.841701\ttrain's binary_logloss: 0.324312\n",
      "[1863]\ttrain's auc: 0.841704\ttrain's binary_logloss: 0.324311\n",
      "[1864]\ttrain's auc: 0.841701\ttrain's binary_logloss: 0.324313\n",
      "[1865]\ttrain's auc: 0.841714\ttrain's binary_logloss: 0.3243\n",
      "[1866]\ttrain's auc: 0.841711\ttrain's binary_logloss: 0.324302\n",
      "[1867]\ttrain's auc: 0.841714\ttrain's binary_logloss: 0.324299\n",
      "[1868]\ttrain's auc: 0.841714\ttrain's binary_logloss: 0.324298\n",
      "[1869]\ttrain's auc: 0.841716\ttrain's binary_logloss: 0.324297\n",
      "[1870]\ttrain's auc: 0.841719\ttrain's binary_logloss: 0.324294\n",
      "[1871]\ttrain's auc: 0.841726\ttrain's binary_logloss: 0.324289\n",
      "[1872]\ttrain's auc: 0.841724\ttrain's binary_logloss: 0.324291\n",
      "[1873]\ttrain's auc: 0.841732\ttrain's binary_logloss: 0.324284\n",
      "[1874]\ttrain's auc: 0.84173\ttrain's binary_logloss: 0.324285\n",
      "[1875]\ttrain's auc: 0.841728\ttrain's binary_logloss: 0.324286\n",
      "[1876]\ttrain's auc: 0.841731\ttrain's binary_logloss: 0.324285\n",
      "[1877]\ttrain's auc: 0.841733\ttrain's binary_logloss: 0.324283\n",
      "[1878]\ttrain's auc: 0.841736\ttrain's binary_logloss: 0.32428\n",
      "[1879]\ttrain's auc: 0.841742\ttrain's binary_logloss: 0.324276\n",
      "[1880]\ttrain's auc: 0.841743\ttrain's binary_logloss: 0.324276\n",
      "[1881]\ttrain's auc: 0.841749\ttrain's binary_logloss: 0.324269\n",
      "[1882]\ttrain's auc: 0.841752\ttrain's binary_logloss: 0.324265\n",
      "[1883]\ttrain's auc: 0.841753\ttrain's binary_logloss: 0.324263\n",
      "[1884]\ttrain's auc: 0.841754\ttrain's binary_logloss: 0.324262\n",
      "[1885]\ttrain's auc: 0.841754\ttrain's binary_logloss: 0.324262\n",
      "[1886]\ttrain's auc: 0.841755\ttrain's binary_logloss: 0.324261\n",
      "[1887]\ttrain's auc: 0.841759\ttrain's binary_logloss: 0.324259\n",
      "[1888]\ttrain's auc: 0.841766\ttrain's binary_logloss: 0.324253\n",
      "[1889]\ttrain's auc: 0.841766\ttrain's binary_logloss: 0.324254\n",
      "[1890]\ttrain's auc: 0.841775\ttrain's binary_logloss: 0.324247\n",
      "[1891]\ttrain's auc: 0.841778\ttrain's binary_logloss: 0.324245\n",
      "[1892]\ttrain's auc: 0.841782\ttrain's binary_logloss: 0.324243\n",
      "[1893]\ttrain's auc: 0.84178\ttrain's binary_logloss: 0.324245\n",
      "[1894]\ttrain's auc: 0.841781\ttrain's binary_logloss: 0.324246\n",
      "[1895]\ttrain's auc: 0.841784\ttrain's binary_logloss: 0.324243\n",
      "[1896]\ttrain's auc: 0.841787\ttrain's binary_logloss: 0.324241\n",
      "[1897]\ttrain's auc: 0.841786\ttrain's binary_logloss: 0.324241\n",
      "[1898]\ttrain's auc: 0.841789\ttrain's binary_logloss: 0.324239\n",
      "[1899]\ttrain's auc: 0.841792\ttrain's binary_logloss: 0.324236\n",
      "[1900]\ttrain's auc: 0.841798\ttrain's binary_logloss: 0.324231\n",
      "[1901]\ttrain's auc: 0.841794\ttrain's binary_logloss: 0.324234\n",
      "[1902]\ttrain's auc: 0.84179\ttrain's binary_logloss: 0.324236\n",
      "[1903]\ttrain's auc: 0.841789\ttrain's binary_logloss: 0.324237\n",
      "[1904]\ttrain's auc: 0.841789\ttrain's binary_logloss: 0.324236\n",
      "[1905]\ttrain's auc: 0.841787\ttrain's binary_logloss: 0.324238\n",
      "[1906]\ttrain's auc: 0.841787\ttrain's binary_logloss: 0.324237\n",
      "[1907]\ttrain's auc: 0.841791\ttrain's binary_logloss: 0.324233\n",
      "[1908]\ttrain's auc: 0.841791\ttrain's binary_logloss: 0.324232\n",
      "[1909]\ttrain's auc: 0.84179\ttrain's binary_logloss: 0.324234\n",
      "[1910]\ttrain's auc: 0.84179\ttrain's binary_logloss: 0.324232\n",
      "[1911]\ttrain's auc: 0.841794\ttrain's binary_logloss: 0.324229\n",
      "[1912]\ttrain's auc: 0.841799\ttrain's binary_logloss: 0.324225\n",
      "[1913]\ttrain's auc: 0.841804\ttrain's binary_logloss: 0.324222\n",
      "[1914]\ttrain's auc: 0.841806\ttrain's binary_logloss: 0.32422\n",
      "[1915]\ttrain's auc: 0.841813\ttrain's binary_logloss: 0.324215\n",
      "[1916]\ttrain's auc: 0.841811\ttrain's binary_logloss: 0.324215\n",
      "[1917]\ttrain's auc: 0.841813\ttrain's binary_logloss: 0.324213\n",
      "[1918]\ttrain's auc: 0.841818\ttrain's binary_logloss: 0.324207\n",
      "[1919]\ttrain's auc: 0.841818\ttrain's binary_logloss: 0.324207\n",
      "[1920]\ttrain's auc: 0.841819\ttrain's binary_logloss: 0.324205\n",
      "[1921]\ttrain's auc: 0.841826\ttrain's binary_logloss: 0.324201\n",
      "[1922]\ttrain's auc: 0.841825\ttrain's binary_logloss: 0.324202\n",
      "[1923]\ttrain's auc: 0.841829\ttrain's binary_logloss: 0.324198\n",
      "[1924]\ttrain's auc: 0.84183\ttrain's binary_logloss: 0.324197\n",
      "[1925]\ttrain's auc: 0.841835\ttrain's binary_logloss: 0.324193\n",
      "[1926]\ttrain's auc: 0.841836\ttrain's binary_logloss: 0.324192\n",
      "[1927]\ttrain's auc: 0.841835\ttrain's binary_logloss: 0.324192\n",
      "[1928]\ttrain's auc: 0.841837\ttrain's binary_logloss: 0.324191\n",
      "[1929]\ttrain's auc: 0.841844\ttrain's binary_logloss: 0.324185\n",
      "[1930]\ttrain's auc: 0.84185\ttrain's binary_logloss: 0.324181\n",
      "[1931]\ttrain's auc: 0.841856\ttrain's binary_logloss: 0.324176\n",
      "[1932]\ttrain's auc: 0.841866\ttrain's binary_logloss: 0.324169\n",
      "[1933]\ttrain's auc: 0.841869\ttrain's binary_logloss: 0.324166\n",
      "[1934]\ttrain's auc: 0.841874\ttrain's binary_logloss: 0.324161\n",
      "[1935]\ttrain's auc: 0.841886\ttrain's binary_logloss: 0.324152\n",
      "[1936]\ttrain's auc: 0.841891\ttrain's binary_logloss: 0.324149\n",
      "[1937]\ttrain's auc: 0.841895\ttrain's binary_logloss: 0.324146\n",
      "[1938]\ttrain's auc: 0.841895\ttrain's binary_logloss: 0.324147\n",
      "[1939]\ttrain's auc: 0.841893\ttrain's binary_logloss: 0.324146\n",
      "[1940]\ttrain's auc: 0.841896\ttrain's binary_logloss: 0.324144\n",
      "[1941]\ttrain's auc: 0.841903\ttrain's binary_logloss: 0.324139\n",
      "[1942]\ttrain's auc: 0.841904\ttrain's binary_logloss: 0.324138\n",
      "[1943]\ttrain's auc: 0.841907\ttrain's binary_logloss: 0.324136\n",
      "[1944]\ttrain's auc: 0.841909\ttrain's binary_logloss: 0.324133\n",
      "[1945]\ttrain's auc: 0.841918\ttrain's binary_logloss: 0.324127\n",
      "[1946]\ttrain's auc: 0.84192\ttrain's binary_logloss: 0.324125\n",
      "[1947]\ttrain's auc: 0.841922\ttrain's binary_logloss: 0.324124\n",
      "[1948]\ttrain's auc: 0.841928\ttrain's binary_logloss: 0.324119\n",
      "[1949]\ttrain's auc: 0.841927\ttrain's binary_logloss: 0.324119\n",
      "[1950]\ttrain's auc: 0.841928\ttrain's binary_logloss: 0.324117\n",
      "[1951]\ttrain's auc: 0.841936\ttrain's binary_logloss: 0.324111\n",
      "[1952]\ttrain's auc: 0.841941\ttrain's binary_logloss: 0.324107\n",
      "[1953]\ttrain's auc: 0.841945\ttrain's binary_logloss: 0.324105\n",
      "[1954]\ttrain's auc: 0.841949\ttrain's binary_logloss: 0.324101\n",
      "[1955]\ttrain's auc: 0.84195\ttrain's binary_logloss: 0.3241\n",
      "[1956]\ttrain's auc: 0.84195\ttrain's binary_logloss: 0.3241\n",
      "[1957]\ttrain's auc: 0.841952\ttrain's binary_logloss: 0.324097\n",
      "[1958]\ttrain's auc: 0.841956\ttrain's binary_logloss: 0.324095\n",
      "[1959]\ttrain's auc: 0.841954\ttrain's binary_logloss: 0.324097\n",
      "[1960]\ttrain's auc: 0.841958\ttrain's binary_logloss: 0.324092\n",
      "[1961]\ttrain's auc: 0.841955\ttrain's binary_logloss: 0.324095\n",
      "[1962]\ttrain's auc: 0.841952\ttrain's binary_logloss: 0.324097\n",
      "[1963]\ttrain's auc: 0.841954\ttrain's binary_logloss: 0.324093\n",
      "[1964]\ttrain's auc: 0.841956\ttrain's binary_logloss: 0.324092\n",
      "[1965]\ttrain's auc: 0.841956\ttrain's binary_logloss: 0.324092\n",
      "[1966]\ttrain's auc: 0.841953\ttrain's binary_logloss: 0.324093\n",
      "[1967]\ttrain's auc: 0.841951\ttrain's binary_logloss: 0.324095\n",
      "[1968]\ttrain's auc: 0.841953\ttrain's binary_logloss: 0.324094\n",
      "[1969]\ttrain's auc: 0.841956\ttrain's binary_logloss: 0.324091\n",
      "[1970]\ttrain's auc: 0.84196\ttrain's binary_logloss: 0.324089\n",
      "[1971]\ttrain's auc: 0.841971\ttrain's binary_logloss: 0.324081\n",
      "[1972]\ttrain's auc: 0.841971\ttrain's binary_logloss: 0.324081\n",
      "[1973]\ttrain's auc: 0.841981\ttrain's binary_logloss: 0.324074\n",
      "[1974]\ttrain's auc: 0.841982\ttrain's binary_logloss: 0.324073\n",
      "[1975]\ttrain's auc: 0.841987\ttrain's binary_logloss: 0.324069\n",
      "[1976]\ttrain's auc: 0.841996\ttrain's binary_logloss: 0.324063\n",
      "[1977]\ttrain's auc: 0.842002\ttrain's binary_logloss: 0.324058\n",
      "[1978]\ttrain's auc: 0.842012\ttrain's binary_logloss: 0.324051\n",
      "[1979]\ttrain's auc: 0.842029\ttrain's binary_logloss: 0.324035\n",
      "[1980]\ttrain's auc: 0.842056\ttrain's binary_logloss: 0.324011\n",
      "[1981]\ttrain's auc: 0.842056\ttrain's binary_logloss: 0.32401\n",
      "[1982]\ttrain's auc: 0.842058\ttrain's binary_logloss: 0.324008\n",
      "[1983]\ttrain's auc: 0.842062\ttrain's binary_logloss: 0.324004\n",
      "[1984]\ttrain's auc: 0.842063\ttrain's binary_logloss: 0.324003\n",
      "[1985]\ttrain's auc: 0.842067\ttrain's binary_logloss: 0.323997\n",
      "[1986]\ttrain's auc: 0.842074\ttrain's binary_logloss: 0.323991\n",
      "[1987]\ttrain's auc: 0.842072\ttrain's binary_logloss: 0.323992\n",
      "[1988]\ttrain's auc: 0.842071\ttrain's binary_logloss: 0.323993\n",
      "[1989]\ttrain's auc: 0.842069\ttrain's binary_logloss: 0.323994\n",
      "[1990]\ttrain's auc: 0.842072\ttrain's binary_logloss: 0.323992\n",
      "[1991]\ttrain's auc: 0.84207\ttrain's binary_logloss: 0.323994\n",
      "[1992]\ttrain's auc: 0.842073\ttrain's binary_logloss: 0.323992\n",
      "[1993]\ttrain's auc: 0.842077\ttrain's binary_logloss: 0.323989\n",
      "[1994]\ttrain's auc: 0.842076\ttrain's binary_logloss: 0.32399\n",
      "[1995]\ttrain's auc: 0.842082\ttrain's binary_logloss: 0.323985\n",
      "[1996]\ttrain's auc: 0.842083\ttrain's binary_logloss: 0.323983\n",
      "[1997]\ttrain's auc: 0.842092\ttrain's binary_logloss: 0.323977\n",
      "[1998]\ttrain's auc: 0.842092\ttrain's binary_logloss: 0.323976\n",
      "[1999]\ttrain's auc: 0.842104\ttrain's binary_logloss: 0.323964\n",
      "[2000]\ttrain's auc: 0.842105\ttrain's binary_logloss: 0.323965\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's auc: 0.842105\ttrain's binary_logloss: 0.323965\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6eeaa561d53c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print('fold %d round %d : score: %.6f | mean score %.6f' % (index+1, model_lgb.best_iteration_, score, np.mean(scores)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'auc'"
     ]
    }
   ],
   "source": [
    "#y_pred = 0\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for index, (tr_idx, va_idx) in enumerate(kfold.split(X_train, y_train)):\n",
    "#for index in range(1):\n",
    "    print('*' * 30)\n",
    "    \n",
    "    X_train1, y_train1, X_valid1, y_valid1 = X_train[tr_idx], y_train[tr_idx], X_train[va_idx], y_train[va_idx]\n",
    "    \n",
    "    if not has_saved:\n",
    "#         model_lgb = LGBMClassifier(boosting_type='gbdt', num_leaves=64, learning_rate=0.05, n_estimators=1500,\n",
    "#                                max_bin=425, subsample_for_bin=50000, objective='binary', min_split_gain=0,\n",
    "#                                min_child_weight=5, min_child_samples=10, subsample=0.8, subsample_freq=1,\n",
    "#                                colsample_bytree=1, reg_alpha=3, reg_lambda=5, seed=1000, n_jobs=-1, silent=True)\n",
    "        model_lgb = LGBMClassifier(n_estimators=2000, n_jobs=-1, objective='binary', seed=1000, silent=True)\n",
    "        # 建议使用CV的方式训练预测。\n",
    "        model_lgb.fit(X_train1, y_train1, \n",
    "             eval_names=['train','eval'],\n",
    "             eval_metric=['logloss','auc'],\n",
    "             eval_set=[(X_valid1, y_valid1)], #(X_train1, y_train1),\n",
    "             early_stopping_rounds=50)\n",
    "    else:\n",
    "        with open('model.mdl', 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "    \n",
    "    score = model_lgb.best_score_['eval']['auc']\n",
    "    scores.append(score)\n",
    "    #print('fold %d round %d : score: %.6f | mean score %.6f' % (index+1, model_lgb.best_iteration_, score, np.mean(scores))) \n",
    "   \n",
    "    y_pred = model_lgb.predict_proba(X_test)[:,1]\n",
    "    np.savetxt('y_pred%d.txt'%(index+1),y_pred)\n",
    "    print('saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   column  importance\n",
      "74                   访问评率        3336\n",
      "135            问题id_count        3270\n",
      "134            用户id_count        2320\n",
      "77                问题关联回答数        2059\n",
      "9            用户上次回答时间-day        2037\n",
      "76               问题上次回答时间        1762\n",
      "80                问题平均举报数        1683\n",
      "127   max_interest_values        1484\n",
      "10          用户习惯回答时间-hour        1481\n",
      "125   most_interest_topic        1459\n",
      "131               编码前问题id        1336\n",
      "128  mean_interest_values        1277\n",
      "81                问题平均反对数        1259\n",
      "26            用户平均回答是否被推荐        1232\n",
      "148     邀请创建时间-hour_count        1200\n",
      "21               用户多分类特征e        1174\n",
      "40             用户总回答是否被推荐        1171\n",
      "129   std_interest_values        1138\n",
      "5     u_a_i_diffhour_mean        1138\n",
      "145        用户多分类特征c_count        1136\n",
      "152      问题创建时间-day_count        1128\n",
      "7      u_a_i_diffhour_sum        1099\n",
      "146        用户多分类特征d_count        1049\n",
      "18               用户多分类特征b        1047\n",
      "20               用户多分类特征d        1046\n",
      "149     问题创建时间-hour_count        1034\n",
      "130               编码前用户id        1031\n",
      "133        邀请创建时间-weekday        1005\n",
      "79            问题创建时间-hour        1001\n",
      "54            用户最大回答是否被推荐         976\n",
      "11               用户二分类特征a         850\n",
      "143        用户多分类特征a_count         835\n",
      "4      u_a_i_diffhour_max         787\n",
      "151  邀请创建时间-weekday_count         746\n",
      "6      u_a_i_diffhour_min         720\n",
      "1      u_a_i_diffday_mean         698\n",
      "65             用户最近回答数-3天         607\n",
      "124    num_interest_topic         590\n",
      "3       u_a_i_diffday_sum         585\n",
      "67             用户邀请_count         577\n",
      "50                用户最大举报数         490\n",
      "66             用户最近回答数-7天         459\n",
      "19               用户多分类特征c         457\n",
      "132        问题创建时间-weekday         451\n",
      "49                 用户总评论数         445\n",
      "78             问题创建时间-day         444\n",
      "0       u_a_i_diffday_max         419\n",
      "73                     盐值         404\n",
      "150  问题创建时间-weekday_count         372\n",
      "8                      性别         364\n",
      "137            访问评率_count         336\n",
      "72          用户问题的话题感兴趣重叠数         314\n",
      "75            邀请创建时间-hour         306\n",
      "44                 用户总收藏数         298\n",
      "144        用户多分类特征b_count         297\n",
      "126   min_interest_values         296\n",
      "64            用户最近回答数-14天         290\n",
      "17               用户多分类特征a         276\n",
      "35                用户平均评论数         243\n",
      "63                用户最大评论数         239\n",
      "45              用户总是否包含图片         212\n",
      "2       u_a_i_diffday_min         209\n",
      "36                 用户总举报数         199\n",
      "46              用户总是否包含视频         162\n",
      "38                 用户总取赞数         160\n",
      "15               用户二分类特征e         136\n",
      "12               用户二分类特征b         117\n",
      "22                用户平均举报数         113\n",
      "59             用户最大是否包含图片         112\n",
      "31             用户平均是否包含图片         100\n",
      "58                用户最大收藏数          98\n",
      "30                用户平均收藏数          91\n",
      "13               用户二分类特征c          89\n",
      "52                用户最大取赞数          80\n",
      "68                 用户邀请平均          68\n",
      "16                用户关联回答数          66\n",
      "37                 用户总反对数          61\n",
      "24                用户平均取赞数          57\n",
      "32             用户平均是否包含视频          50\n",
      "14               用户二分类特征d          39\n",
      "48                 用户总点赞数          32\n",
      "51                用户最大反对数          30\n",
      "141        用户二分类特征d_count          27\n",
      "139        用户二分类特征b_count          26\n",
      "47               用户总没有帮助数          23\n",
      "142        用户二分类特征e_count          23\n",
      "23                用户平均反对数          20\n",
      "140        用户二分类特征c_count          13\n",
      "34                用户平均点赞数           7\n",
      "43                 用户总感谢数           7\n",
      "62                用户最大点赞数           7\n",
      "33              用户平均没有帮助数           3\n",
      "136              性别_count           0\n",
      "121               问题最大评论数           0\n",
      "114           问题最大回答是否被标优           0\n",
      "115               问题最大感谢数           0\n",
      "116               问题最大收藏数           0\n",
      "117            问题最大是否包含图片           0\n",
      "118            问题最大是否包含视频           0\n",
      "119             问题最大没有帮助数           0\n",
      "120               问题最大点赞数           0\n",
      "147        用户多分类特征e_count           0\n",
      "122            问题最近一周回答比例           0\n",
      "123       num_atten_topic           0\n",
      "29                用户平均感谢数           0\n",
      "25               用户平均回答字数           0\n",
      "27          用户平均回答是否被收入圆桌           0\n",
      "28            用户平均回答是否被标优           0\n",
      "112           问题最大回答是否被推荐           0\n",
      "138        用户二分类特征a_count           0\n",
      "113         问题最大回答是否被收入圆桌           0\n",
      "100            问题总回答是否被标优           0\n",
      "111              问题最大回答字数           0\n",
      "89             问题平均是否包含图片           0\n",
      "86            问题平均回答是否被标优           0\n",
      "85          问题平均回答是否被收入圆桌           0\n",
      "84            问题平均回答是否被推荐           0\n",
      "83               问题平均回答字数           0\n",
      "82                问题平均取赞数           0\n",
      "39                用户总回答字数           0\n",
      "71           用户问题的话题关注重叠数           0\n",
      "70                 用户邀请求和           0\n",
      "69                 用户邀请方差           0\n",
      "41           用户总回答是否被收入圆桌           0\n",
      "42             用户总回答是否被标优           0\n",
      "61              用户最大没有帮助数           0\n",
      "60             用户最大是否包含视频           0\n",
      "57                用户最大感谢数           0\n",
      "56            用户最大回答是否被标优           0\n",
      "55          用户最大回答是否被收入圆桌           0\n",
      "53               用户最大回答字数           0\n",
      "88                问题平均收藏数           0\n",
      "90             问题平均是否包含视频           0\n",
      "110               问题最大取赞数           0\n",
      "91              问题平均没有帮助数           0\n",
      "109               问题最大反对数           0\n",
      "108               问题最大举报数           0\n",
      "107                问题总评论数           0\n",
      "106                问题总点赞数           0\n",
      "105              问题总没有帮助数           0\n",
      "104             问题总是否包含视频           0\n",
      "103             问题总是否包含图片           0\n",
      "102                问题总收藏数           0\n",
      "101                问题总感谢数           0\n",
      "99           问题总回答是否被收入圆桌           0\n",
      "98             问题总回答是否被推荐           0\n",
      "97                问题总回答字数           0\n",
      "96                 问题总取赞数           0\n",
      "95                 问题总反对数           0\n",
      "94                 问题总举报数           0\n",
      "93                问题平均评论数           0\n",
      "92                问题平均点赞数           0\n",
      "87                问题平均感谢数           0\n"
     ]
    }
   ],
   "source": [
    "model_lgb.booster_.save_model('model.txt')\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(pd.DataFrame({\n",
    "    'column': [x for x in data_for_train1.columns.values if x not in ['邀请创建时间-day','用户id','问题id','是否回答']],\n",
    "    'importance': model_lgb.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score = 0\n",
    "for i in range(5):\n",
    "    pred = pd.read_csv('y_pred%d.txt'%(i+1), header=None, sep='\\t')\n",
    "    pred_score += pred/5\n",
    "\n",
    "print(pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '../data'\n",
    "# y_pred = pd.read_csv('y_pred1.txt', header=None, sep='\\t')\n",
    "\n",
    "result = pd.read_csv(os.path.join(data_path, 'invite_info_evaluate_1_0926.txt'), header=None, sep='\\t')\n",
    "result['pred_score']=pred_score\n",
    "\n",
    "result.to_csv('result.txt',index=False, header=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
