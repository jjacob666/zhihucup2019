{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 user_answer 特征处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_path = '../../../data'\n",
    "answer_info = pd.read_csv(os.path.join(data_path, 'answer_info_0926.txt'), header=None, sep='\\t')\n",
    "#train1 = pd.read_csv(os.path.join(data_path, 'invite_info_0926.txt'), header=None, sep='\\t')\n",
    "\n",
    "#train1.columns = ['问题id', '用户id', '邀请创建时间','是否回答']\n",
    "answer_info.columns = ['回答id', '问题id', '用户id', '回答创建时间', '回答内容的单字编码序列', '回答内容的切词编码序列', '回答是否被标优', '回答是否被推荐', '回答是否被收入圆桌', '是否包含图片', '是否包含视频', '回答字数', '点赞数', '取赞数', '评论数', '收藏数', '感谢数', '举报数', '没有帮助数', '反对数']\n",
    "\n",
    "drop_feat = ['回答内容的单字编码序列','回答内容的切词编码序列']\n",
    "answer_info  = answer_info.drop(drop_feat, axis=1)\n",
    "\n",
    "#user_answer_info = pd.merge(train1, answer_info, how='left', on='用户id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_info['回答创建时间-hour'] = answer_info['回答创建时间'].apply(lambda x:x.split('-')[1].split('H')[1]).astype(int)\n",
    "answer_info['回答创建时间-day'] = answer_info['回答创建时间'].apply(lambda x:x.split('-')[0].split('D')[1]).astype(int)\n",
    "answer_info['回答创建时间-wkday'] = answer_info['回答创建时间-day']%7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_info['回答创建时间-day'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 减少内存占用\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(os.path.join(data_path, 'invite_info_0926.txt'), header=None, sep='\\t')\n",
    "train1.columns = ['问题id', '用户id', '邀请创建时间','是否回答']\n",
    "train1['邀请创建时间-day'] = train1['邀请创建时间'].apply(lambda x:x.split('-')[0].split('D')[1])\n",
    "train1['邀请创建时间-hour'] = train1['邀请创建时间'].apply(lambda x:x.split('-')[1].split('H')[1])\n",
    "\n",
    "answer_info = pd.merge(answer_info, train1, how='left', on=['用户id','问题id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_info.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_info = answer_info.fillna({'是否回答':1, '邀请创建时间-day':-100,'邀请创建时间-hour':-100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_info['邀请创建时间-hour'] = answer_info['邀请创建时间-hour'].astype(int)\n",
    "answer_info['邀请创建时间-day'] = answer_info['邀请创建时间-day'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t3 = answer_info\n",
    "# t3 = answer_info.groupby('用户id')['邀请创建时间-hour'].agg('value_counts').to_frame()\n",
    "# t3.columns = ['u_i_hr_count']\n",
    "# t3 = t3.reset_index()\n",
    "# answer_info = pd.merge(answer_info, t3, on=['用户id','邀请创建时间-hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_features(answer_info, train_end, etype):\n",
    "    \n",
    "    if etype=='val':\n",
    "        days = 21\n",
    "    else:\n",
    "        days = 14\n",
    "    \n",
    "    answer_info['u_a_last_daytime'] = answer_info['用户id'].map(answer_info['回答创建时间-day'].groupby(answer_info['用户id']).max()) #为每个特征，匹配上其每个值对应到的 该值出现的次数\n",
    "\n",
    "########## 在baseline里已写  ##########\n",
    "#     feat_cols = ['点赞数', '取赞数', '评论数', '收藏数', '感谢数', '举报数', '没有帮助数', '反对数','回答是否被标优', '回答是否被推荐', '回答是否被收入圆桌', '是否包含图片', '是否包含视频', '回答字数']\n",
    "#     for feat in feat_cols:\n",
    "#         answer_info['用户总'+feat+'_last3week'] = answer_info['用户id'].map(answer_info[feat].groupby(answer_info['用户id']).sum())\n",
    "#         answer_info['用户平均'+feat+'_last3week'] = answer_info['用户id'].map(answer_info[feat].groupby(answer_info['用户id']).mean()).astype(int)\n",
    "#         answer_info['用户最大'+feat+'_last3week'] = answer_info['用户id'].map(answer_info[feat].groupby(answer_info['用户id']).max())\n",
    "#     print(\"feat_cols stastics features loaded.\")\n",
    "#     print(answer_info.info())\n",
    "    \n",
    "#     for feat in feat_cols:\n",
    "#         answer_info['用户总'+feat+'_last3day'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-3][feat].groupby(answer_info['用户id']).sum())\n",
    "#         answer_info['用户平均'+feat+'_last3day'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-3][feat].groupby(answer_info['用户id']).mean())\n",
    "#         answer_info['用户最大'+feat+'_last3day'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-3][feat].groupby(answer_info['用户id']).max())\n",
    "#     print(\"feat_cols stastics features loaded.\")\n",
    "#     print(answer_info.info())\n",
    "\n",
    "#     for feat in feat_cols:\n",
    "#         answer_info['用户总'+feat+'_last2week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-14][feat].groupby(answer_info['用户id']).sum())\n",
    "#         answer_info['用户平均'+feat+'_last2week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-14][feat].groupby(answer_info['用户id']).mean())\n",
    "#         answer_info['用户最大'+feat+'_last2week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-14][feat].groupby(answer_info['用户id']).max())\n",
    "#     print(\"feat_cols stastics features loaded.\")\n",
    "#     print(answer_info.info())    \n",
    "    \n",
    "#     for feat in feat_cols:\n",
    "#         answer_info['用户总'+feat+'_last1week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-7][feat].groupby(answer_info['用户id']).sum())\n",
    "#         answer_info['用户平均'+feat+'_last1week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-7][feat].groupby(answer_info['用户id']).mean())\n",
    "#         answer_info['用户最大'+feat+'_last1week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-7][feat].groupby(answer_info['用户id']).max())\n",
    "#     print(\"feat_cols stastics features loaded.\")\n",
    "#     print(answer_info.info())    \n",
    "        \n",
    "    answer_info['u_a_num'] = answer_info['用户id'].map(answer_info['回答id'].groupby(answer_info['用户id']).nunique())\n",
    "    print(\"用户关联回答数 laoded\")\n",
    "#    print(answer_info.info())\n",
    "    \n",
    "#     t1 = answer_info.groupby('用户id')['是否回答'].agg(['mean', 'sum', 'std', 'count']).reset_index()  \n",
    "#     t1.columns = ['用户id', 'u_i_mean', 'u_i_sum', 'u_i_std', 'u_i_count']\n",
    "#     t1 = t1.fillna({'用户邀请方差':-1})\n",
    "#     t1.loc[:, '用户邀请方差'] += 1\n",
    "#     answer_info = pd.merge(answer_info, t1, on='用户id', how='left')\n",
    "#     del t1\n",
    "#     print(\"user label features loaded.\")\n",
    "#     print(answer_info.info())\n",
    "    \n",
    "    answer_info['u_ai_diff_hour'] = answer_info['回答创建时间-hour'] - answer_info['邀请创建时间-hour']\n",
    "    answer_info.loc[answer_info['u_ai_diff_hour']>=100, 'u_ai_diff_hour'] = 30\n",
    "    answer_info.loc[:, 'u_ai_diff_hour'] += 24\n",
    "    t2 = answer_info.loc[answer_info['u_ai_diff_hour']<54, :]\n",
    "    t2 = t2.groupby('用户id')['u_ai_diff_hour'].agg(['mean', 'sum', 'max', 'min']).reset_index()  \n",
    "    t2.columns = ['用户id', 'u_a_i_diffhour_mean', 'u_a_i_diffhour_sum', 'u_a_i_diffhour_max', 'u_a_i_diffhour_min']\n",
    "    answer_info = pd.merge(answer_info, t2, on='用户id', how='left')\n",
    "    del t2\n",
    "    print(\"u_a_i_diff_hour feature loaded.\")\n",
    "#    print(answer_info.info())\n",
    "    \n",
    "    answer_info['u_ai_diff_day'] = answer_info['回答创建时间-day'] - answer_info['邀请创建时间-day']\n",
    "    answer_info.loc[answer_info['u_ai_diff_day']>=3900, 'u_ai_diff_day'] = 100\n",
    "    t3 = answer_info.loc[answer_info['u_ai_diff_day']<100, :]\n",
    "    t3 = t3.groupby('用户id')['u_ai_diff_day'].agg(['mean', 'sum', 'max', 'min']).reset_index()  \n",
    "    t3.columns = ['用户id', 'u_a_i_diffday_mean', 'u_a_i_diffday_sum', 'u_a_i_diffday_max', 'u_a_i_diffday_min']\n",
    "    answer_info = pd.merge(answer_info, t3, on='用户id', how='left')\n",
    "    del t3\n",
    "    print(\"u_a_i_diff_day feature loaded.\")\n",
    "#    print(answer_info.info())\n",
    "    \n",
    "    answer_info['u_a_mean_hour'] = answer_info['用户id'].map(answer_info['回答创建时间-hour'].groupby(answer_info['用户id']).agg('mean'))\n",
    "    answer_info['u_a_mean_hour_last3day'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-3]['回答创建时间-hour'].groupby(answer_info['用户id']).agg('mean'))\n",
    "    answer_info['u_a_mean_hour_last1week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-7]['回答创建时间-hour'].groupby(answer_info['用户id']).agg('mean'))\n",
    "\n",
    "    answer_info['u_a_mean_hour_last2week'] = answer_info['用户id'].map(answer_info[answer_info['邀请创建时间-day']>train_end-days]['回答创建时间-hour'].groupby(answer_info['用户id']).agg('mean')) \n",
    "    \n",
    "    t4 = answer_info.groupby('用户id')['回答创建时间-hour'].agg(lambda x: np.mean(pd.Series.mode(x))).reset_index()\n",
    "    t4.columns = ['用户id', 'u_a_most_hour']\n",
    "    t4['u_a_most_hour'] = t4['u_a_most_hour'].astype(int)\n",
    "    answer_info = pd.merge(answer_info, t4, on='用户id', how='left')\n",
    "    del t4\n",
    "    print(\"用户习惯回答时间-hour loaded.\")\n",
    "#    print(answer_info.info())\n",
    "    \n",
    "    t5 = answer_info[answer_info['邀请创建时间-day']>train_end-3].groupby('用户id')['回答创建时间-hour'].agg(lambda x: np.mean(pd.Series.mode(x))).reset_index()\n",
    "    t5.columns = ['用户id', 'u_a_most_hour_last3day']\n",
    "    t5['u_a_most_hour_last3day'] = t5['u_a_most_hour_last3day'].astype(int)\n",
    "    answer_info = pd.merge(answer_info, t5, on='用户id', how='left')\n",
    "    del t5\n",
    "    print(\"用户习惯回答时间-hour_last3day loaded.\")\n",
    "#    print(answer_info.info())    \n",
    "    \n",
    "    t5 = answer_info[answer_info['邀请创建时间-day']>train_end-7].groupby('用户id')['回答创建时间-hour'].agg(lambda x: np.mean(pd.Series.mode(x))).reset_index()\n",
    "    t5.columns = ['用户id', 'u_a_most_hour_last1week']\n",
    "    t5['u_a_most_hour_last1week'] = t5['u_a_most_hour_last1week'].astype(int)\n",
    "    answer_info = pd.merge(answer_info, t5, on='用户id', how='left')\n",
    "    del t5\n",
    "    print(\"用户习惯回答时间-hour_last1week loaded.\")\n",
    "#    print(answer_info.info())    \n",
    "    \n",
    "    t5 = answer_info[answer_info['邀请创建时间-day']>train_end-days].groupby('用户id')['回答创建时间-hour'].agg(lambda x: np.mean(pd.Series.mode(x))).reset_index()\n",
    "    t5.columns = ['用户id', 'u_a_most_hour_last2week']\n",
    "    t5['u_a_most_hour_last2week'] = t5['u_a_most_hour_last2week'].astype(int)\n",
    "    answer_info = pd.merge(answer_info, t5, on='用户id', how='left')\n",
    "    del t5\n",
    "    print(\"用户习惯回答时间-hour_last2week loaded.\")\n",
    "#    print(answer_info.info())    \n",
    "    \n",
    "    t5 = answer_info.groupby('用户id')['回答创建时间-wkday'].agg(lambda x: np.mean(pd.Series.mode(x))).reset_index()\n",
    "    t5.columns = ['用户id', 'u_a_most_wkday']\n",
    "    t5['u_a_most_wkday'] = t5['u_a_most_wkday'].astype(int)\n",
    "    answer_info = pd.merge(answer_info, t5, on='用户id', how='left')\n",
    "    del t5\n",
    "    print(\"用户习惯回答时间-wkday loaded.\")\n",
    "#    print(answer_info.info())    \n",
    "   \n",
    "    t1 = answer_info[answer_info['邀请创建时间-day']>train_end-3]\n",
    "    t1['u_a_num_last3'] = t1['用户id'].map(t1['回答id'].groupby(t1['用户id']).nunique())\n",
    "    t1 = t1[['用户id','u_a_num_last3']].drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    answer_info = pd.merge(answer_info, t1, on='用户id', how='left')\n",
    "#    print(answer_info.info())\n",
    "    del t1\n",
    "    \n",
    "    t1 = answer_info[answer_info['邀请创建时间-day']>train_end-7]\n",
    "    t1['u_a_num_last7'] = t1['用户id'].map(t1['回答id'].groupby(t1['用户id']).nunique())\n",
    "    t1 = t1[['用户id','u_a_num_last7']].drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    answer_info = pd.merge(answer_info, t1, on='用户id', how='left')\n",
    "    del t1\n",
    "    \n",
    "    t1 = answer_info[answer_info['邀请创建时间-day']>train_end-days]\n",
    "    t1['u_a_num_last14'] = t1['用户id'].map(t1['回答id'].groupby(t1['用户id']).nunique())\n",
    "    t1 = t1[['用户id','u_a_num_last14']].drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    answer_info = pd.merge(answer_info, t1, on='用户id', how='left')\n",
    "    del t1\n",
    "    \n",
    "    print(\"用户最近回答数loaded.\")\n",
    "#    print(answer_info.info())\n",
    "\n",
    "    #answer_info['用户回答时间-hour_count'] = answer_info[['用户id','回答创建时间-hour']].map(answer_info['回答创建时间-hour'].groupby(answer_info['用户id']).value_counts())\n",
    "    #print(answer_info['回答是否被标优'].groupby(answer_info['用户id'].sum()))\n",
    "    \n",
    "    drop_feat = ['回答创建时间-wkday', '邀请创建时间-day', '邀请创建时间-hour','u_ai_diff_day','u_ai_diff_hour','邀请创建时间','是否回答', '问题id','回答id','回答创建时间','回答是否被标优','回答是否被推荐','回答是否被收入圆桌','点赞数','评论数','收藏数','感谢数','回答创建时间-hour','回答创建时间-day','举报数', '没有帮助数', '反对数','回答是否被标优', '回答是否被推荐', '回答是否被收入圆桌', '是否包含图片', '是否包含视频', '回答字数','取赞数']\n",
    "    answer_info  = answer_info.drop(drop_feat, axis=1)\n",
    "    print(\"feature droped\")\n",
    "    answer_info.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "#     drop_feats = ['用户总点赞数_last3day', '用户平均点赞数_last3day', '用户最大点赞数_last3day', '用户总取赞数_last3day', '用户平均取赞数_last3day', '用户最大取赞数_last3day', '用户总评论数_last3day', '用户平均评论数_last3day', '用户最大评论数_last3day', '用户总收藏数_last3day', '用户平均收藏数_last3day', '用户最大收藏数_last3day', '用户总感谢数_last3day', '用户平均感谢数_last3day', '用户最大感谢数_last3day', '用户总举报数_last3day', '用户平均举报数_last3day', '用户最大举报数_last3day', '用户总没有帮助数_last3day', '用户平均没有帮助数_last3day', '用户最大没有帮助数_last3day', '用户总反对数_last3day', '用户平均反对数_last3day', '用户最大反对数_last3day', '用户总回答是否被标优_last3day', '用户平均回答是否被标优_last3day', '用户最大回答是否被标优_last3day', '用户总回答是否被推荐_last3day', '用户平均回答是否被推荐_last3day', '用户最大回答是否被推荐_last3day', '用户总回答是否被收入圆桌_last3day', '用户平均回答是否被收入圆桌_last3day', '用户最大回答是否被收入圆桌_last3day', '用户总是否包含图片_last3day', '用户平均是否包含图片_last3day', '用户最大是否包含图片_last3day', '用户总是否包含视频_last3day', '用户平均是否包含视频_last3day', '用户最大是否包含视频_last3day', '用户总回答字数_last3day', '用户平均回答字数_last3day', '用户最大回答字数_last3day', '用户平均回答时间-hour']\n",
    "#     train_for_save  = train_for_save.drop(drop_feats, axis=1)\n",
    "\n",
    "    answer_info = reduce_mem_usage(answer_info)\n",
    "    print(answer_info.info())\n",
    "\n",
    "    return answer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_start = 3807\n",
    "train_end = 3860\n",
    "val_start = train_start + 7\n",
    "val_end = train_end + 7\n",
    "\n",
    "train_for_save = answer_info[answer_info['邀请创建时间-day']>=train_start][answer_info['邀请创建时间-day']<=train_end]\n",
    "train_for_save = extract_user_features(train_for_save, train_end ,'train')\n",
    "\n",
    "val_for_save = answer_info[answer_info['邀请创建时间-day']>=val_start][answer_info['邀请创建时间-day']<=val_end]\n",
    "val_for_save = extract_user_features(val_for_save, val_end, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(answer_info.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(val_for_save.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_for_save.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_for_save['用户id'].nunique())\n",
    "print(val_for_save['用户id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_for_save.info())\n",
    "print(val_for_save.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_save = train_for_save.fillna(-1)\n",
    "val_for_save = val_for_save.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_save.to_hdf('user_answer_train.h5',key='data')\n",
    "val_for_save.to_hdf('user_answer_val.h5',key='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割线-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "info = pd.read_hdf('user_answer.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_for_save['用户id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info1 = info[:1000].sort_values(by='用户上次回答时间-day', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info2 = info1[info1[:1000]['用户上次回答时间-day']<3861]\n",
    "print(info2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
